
@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2020-09-01},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning}
}

@article{fey_fast_2019,
	title = {Fast {Graph} {Representation} {Learning} with {PyTorch} {Geometric}},
	url = {http://arxiv.org/abs/1903.02428},
	abstract = {We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.},
	urldate = {2020-09-01},
	journal = {arXiv:1903.02428 [cs, stat]},
	author = {Fey, Matthias and Lenssen, Jan Eric},
	month = apr,
	year = {2019},
	note = {arXiv: 1903.02428},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{k_perceptnet_2019,
	title = {{PerceptNet}: {Learning} {Perceptual} {Similarity} of {Haptic} {Textures} in {Presence} of {Unorderable} {Triplets}},
	shorttitle = {{PerceptNet}},
	url = {http://arxiv.org/abs/1905.03302},
	abstract = {In order to design haptic icons or build a haptic vocabulary, we require a set of easily distinguishable haptic signals to avoid perceptual ambiguity, which in turn requires a way to accurately estimate the perceptual (dis)similarity of such signals. In this work, we present a novel method to learn such a perceptual metric based on data from human studies. Our method is based on a deep neural network that projects signals to an embedding space where the natural Euclidean distance accurately models the degree of dissimilarity between two signals. The network is trained only on non-numerical comparisons of triplets of signals, using a novel triplet loss that considers both types of triplets that are easy to order (inequality constraints), as well as those that are unorderable/ambiguous (equality constraints). Unlike prior MDS-based non-parametric approaches, our method can be trained on a partial set of comparisons and can embed new haptic signals without retraining the model from scratch. Extensive experimental evaluations show that our method is significantly more effective at modeling perceptual dissimilarity than alternatives.},
	urldate = {2020-09-01},
	journal = {arXiv:1905.03302 [cs, stat]},
	author = {K, Priyadarshini and Chaudhuri, Siddhartha and Chaudhuri, Subhasis},
	month = may,
	year = {2019},
	note = {arXiv: 1905.03302},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@inproceedings{balntas_learning_2016,
	address = {York, UK},
	title = {Learning local feature descriptors with triplets and shallow convolutional neural networks},
	isbn = {978-1-901725-59-9},
	url = {http://www.bmva.org/bmvc/2016/papers/paper119/index.html},
	doi = {10.5244/C.30.119},
	language = {en},
	urldate = {2020-09-01},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2016},
	publisher = {British Machine Vision Association},
	author = {Balntas, Vassileios and Riba, Edgar and Ponsa, Daniel and Mikolajczyk, Krystian},
	year = {2016},
	pages = {119.1--119.11}
}

@article{kipf_semi-supervised_2017,
	title = {Semi-{Supervised} {Classification} with {Graph} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1609.02907},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
	urldate = {2020-09-01},
	journal = {arXiv:1609.02907 [cs, stat]},
	author = {Kipf, Thomas N. and Welling, Max},
	month = feb,
	year = {2017},
	note = {arXiv: 1609.02907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{kipf_semi-supervised_2017-1,
	title = {{SEMI}-{SUPERVISED} {CLASSIFICATION} {WITH} {GRAPH} {CONVOLUTIONAL} {NETWORKS}},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efﬁcient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized ﬁrst-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a signiﬁcant margin.},
	language = {en},
	author = {Kipf, Thomas N and Welling, Max},
	year = {2017},
	pages = {14}
}

@inproceedings{campello_density-based_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Density-{Based} {Clustering} {Based} on {Hierarchical} {Density} {Estimates}},
	isbn = {978-3-642-37456-2},
	doi = {10.1007/978-3-642-37456-2_14},
	abstract = {We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a “flat” partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Sander, Joerg},
	editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
	year = {2013},
	keywords = {Cluster Tree, Core Object, Density Threshold, Hierarchical Cluster Method, Minimum Span Tree},
	pages = {160--172}
}

@article{mcinnes_accelerated_2017,
	title = {Accelerated {Hierarchical} {Density} {Clustering}},
	url = {http://arxiv.org/abs/1705.07321},
	doi = {10.1109/ICDMW.2017.12},
	abstract = {We present an accelerated algorithm for hierarchical density based clustering. Our new algorithm improves upon HDBSCAN*, which itself provided a significant qualitative improvement over the popular DBSCAN algorithm. The accelerated HDBSCAN* algorithm provides comparable performance to DBSCAN, while supporting variable density clusters, and eliminating the need for the difficult to tune distance scale parameter. This makes accelerated HDBSCAN* the default choice for density based clustering. Library available at: https://github.com/scikit-learn-contrib/hdbscan},
	urldate = {2020-08-31},
	journal = {2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
	author = {McInnes, Leland and Healy, John},
	month = nov,
	year = {2017},
	note = {arXiv: 1705.07321},
	keywords = {Statistics - Machine Learning},
	pages = {33--42}
}

@article{mcinnes_umap_2018,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	shorttitle = {{UMAP}},
	url = {http://arxiv.org/abs/1802.03426},
	abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	urldate = {2020-08-31},
	journal = {arXiv:1802.03426 [cs, stat]},
	author = {McInnes, Leland and Healy, John and Melville, James},
	month = dec,
	year = {2018},
	note = {arXiv: 1802.03426},
	keywords = {Computer Science - Computational Geometry, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{traag_louvain_2019,
	title = {From {Louvain} to {Leiden}: guaranteeing well-connected communities},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	shorttitle = {From {Louvain} to {Leiden}},
	url = {https://www.nature.com/articles/s41598-019-41695-z},
	doi = {10.1038/s41598-019-41695-z},
	abstract = {Community detection is often used to understand the structure of large and complex networks. One of the most popular algorithms for uncovering community structure is the so-called Louvain algorithm. We show that this algorithm has a major defect that largely went unnoticed until now: the Louvain algorithm may yield arbitrarily badly connected communities. In the worst case, communities may even be disconnected, especially when running the algorithm iteratively. In our experimental analysis, we observe that up to 25\% of the communities are badly connected and up to 16\% are disconnected. To address this problem, we introduce the Leiden algorithm. We prove that the Leiden algorithm yields communities that are guaranteed to be connected. In addition, we prove that, when the Leiden algorithm is applied iteratively, it converges to a partition in which all subsets of all communities are locally optimally assigned. Furthermore, by relying on a fast local move approach, the Leiden algorithm runs faster than the Louvain algorithm. We demonstrate the performance of the Leiden algorithm for several benchmark and real-world networks. We find that the Leiden algorithm is faster than the Louvain algorithm and uncovers better partitions, in addition to providing explicit guarantees.},
	language = {en},
	number = {1},
	urldate = {2020-08-18},
	journal = {Scientific Reports},
	author = {Traag, V. A. and Waltman, L. and van Eck, N. J.},
	month = mar,
	year = {2019},
	pages = {5233}
}

@incollection{jiao_comparative_2018,
	title = {A {Comparative} {Study} of {Phoneme}- and {Word}-{Based} {Learning} of {English} {Words} {Presented} to the {Skin}},
	isbn = {978-3-319-93398-6},
	abstract = {Past research has demonstrated that speech communication on the skin is entirely achievable. However, there is still no definitive conclusion on the best training method that minimizes the time it takes for users to reach a prescribed performance level with a speech communication device. The present study reports the design and testing of two learning approaches with a system that translates English phonemes to haptic stimulation patterns (haptic symbols). With the phoneme-based learning approach, users learned the haptic symbols associated with the phonemes before attempting to acquire words made up of the phonemes. With the word-based approach, users learned words on day one. Two experiments were conducted with the two learning approaches, each employing twelve participants who spent 100 min each learning 100 English words made up of 39 phonemes. Results in terms of the total number of words learned show that performance levels vary greatly among the individuals tested (with the best learners in both methods achieving word-recognition scores {\textgreater} 90\%-correct on a 100-word vocabulary), both approaches are feasible for successful acquisition of word through the skin, and the phoneme-based approach provides a more consistent path for learning across users in a shorter period of time.},
	author = {Jiao, Yang and Severgnini, Frederico and Martinez, Juan and Jung, Jaehong and Tan, Hong and Reed, Charlotte and Wilson, E. and Lau, Frances and Israr, Ali and Turcott, Robert and Klumb, Keith and Abnousi, Freddy},
	month = jun,
	year = {2018},
	doi = {10.1007/978-3-319-93399-3_53},
	pages = {623--635}
}

@incollection{jiao_comparative_2018-1,
	title = {A {Comparative} {Study} of {Phoneme}- and {Word}-{Based} {Learning} of {English} {Words} {Presented} to the {Skin}},
	isbn = {978-3-319-93398-6},
	abstract = {Past research has demonstrated that speech communication on the skin is entirely achievable. However, there is still no definitive conclusion on the best training method that minimizes the time it takes for users to reach a prescribed performance level with a speech communication device. The present study reports the design and testing of two learning approaches with a system that translates English phonemes to haptic stimulation patterns (haptic symbols). With the phoneme-based learning approach, users learned the haptic symbols associated with the phonemes before attempting to acquire words made up of the phonemes. With the word-based approach, users learned words on day one. Two experiments were conducted with the two learning approaches, each employing twelve participants who spent 100 min each learning 100 English words made up of 39 phonemes. Results in terms of the total number of words learned show that performance levels vary greatly among the individuals tested (with the best learners in both methods achieving word-recognition scores {\textgreater} 90\%-correct on a 100-word vocabulary), both approaches are feasible for successful acquisition of word through the skin, and the phoneme-based approach provides a more consistent path for learning across users in a shorter period of time.},
	author = {Jiao, Yang and Severgnini, Frederico and Martinez, Juan and Jung, Jaehong and Tan, Hong and Reed, Charlotte and Wilson, E. and Lau, Frances and Israr, Ali and Turcott, Robert and Klumb, Keith and Abnousi, Freddy},
	month = jun,
	year = {2018},
	doi = {10.1007/978-3-319-93399-3_53},
	pages = {623--635}
}

@inproceedings{vargas_haptic_2019,
	title = {Haptic {Speech} {Communication} {Using} {Stimuli} {Evocative} of {Phoneme} {Production}},
	doi = {10.1109/WHC.2019.8816145},
	author = {Vargas, Mauricio and Weill-Duflos, Antoine and Cooperstock, Jeremy},
	month = jul,
	year = {2019},
	pages = {610--615}
}

@article{brooks_acquisition_1985,
	title = {Acquisition of a 250-word vocabulary through a tactile vocoder},
	volume = {77},
	doi = {10.1121/1.392000},
	abstract = {In a previous experiment [P. L. Scilley, "Evaluation of a vibrotactile auditory prosthetic device for the profoundly deaf," unpublished Masters thesis, Queen's University, Kingston, Canada (1980)] two normal subjects learned to identify 70 and 150 words, respectively, using the Queen's Tactile Vocoder. In the present experiment, the most advanced subject continued word learning until a tactile vocabulary of 250 words was acquired. At this point randomized tests were given to obtain an indication of final performance level. From these data conditional probabilities of correct response for each stimulus word and significant confusions were obtained, which provides insight into the advantages and present limitations of the tactile vocoder.},
	journal = {The Journal of the Acoustical Society of America},
	author = {Brooks, P and Frost, Barrie and Mason, J and Chung, K},
	month = may,
	year = {1985},
	pages = {1576--9}
}

@inproceedings{zhao_coding_2018,
	address = {New York, NY, USA},
	series = {{CHI} '18},
	title = {Coding {Tactile} {Symbols} for {Phonemic} {Communication}},
	isbn = {978-1-4503-5620-6},
	url = {https://doi.org/10.1145/3173574.3173966},
	doi = {10.1145/3173574.3173966},
	abstract = {We present a study to examine one's learning and processing capacity of broadband tactile information, such as that derived from speech. In Study 1, we tested a user's capability to recognize tactile locations and movements on the forearm in the presence of masking stimuli and determined 9 distinguishable tactile symbols. We associated these symbols to 9 phonemes using two approaches, random and articulation associations. Study 2 showed that novice participants can learn both associations. However, performance for retention, construction of words and knowledge transfer to recognize unlearned words was better with articulation association. In study 3, we trained novel participants to directly recognize words before learning phonemes. Our results show that novel users can retain and generalize the knowledge to recognize new words faster when they were directly train on words. Finally, Study 4 examined optimal presentation rate for the tactile symbols without compromising learning and recognition rate.},
	urldate = {2020-08-08},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Siyan and Israr, Ali and Lau, Frances and Abnousi, Freddy},
	month = apr,
	year = {2018},
	keywords = {haptic interfaces, haptic language, touch},
	pages = {1--13}
}

@article{tan_acquisition_2020,
	title = {Acquisition of 500 {English} {Words} through a {TActile} {Phonemic} {Sleeve} ({TAPS})},
	volume = {PP},
	doi = {10.1109/TOH.2020.2973135},
	abstract = {Recently, a phonemic-based tactile speech communication system was developed with the goal to transmit speech through the skin for people with hearing impairments and those whose auditory and visual channels are overloaded or compromised. The display, called the TActile Phonemic Sleeve (TAPS), consisted of a 4-by-6 tactor array worn on the dorsal and volar surfaces of the forearm. Earlier work showed that people were able to learn the haptic symbols for 39 English phonemes and reach a mean phoneme recognition rate of 86\% correct within one to four hours of training. The current research evaluated the acquisition of up to 500 words using TAPS. A total of 51 participants were trained and tested in three studies with increasing number of phonemes and vocabulary sizes. Individual achievements varied, but the results clearly demonstrate the potential of transmitting any English word using TAPS within a reasonable period of learning. Future work will include increasing the speech transmission rate with TAPS by improving the phonemic codes and reducing the inter-phoneme intervals, addressing the reception of words and sentences composed of strings of tactile phonemes, and assessing the performance of TAPS as a speech communication system for people with severe hearing impairments.},
	journal = {IEEE Transactions on Haptics},
	author = {Tan, Hong and Reed, Charlotte and Jiao, Yang and Perez, Zachary and Wilson, E. and Jung, Jaehong and Martinez, Juan and Severgnini, Frederico},
	month = feb,
	year = {2020},
	pages = {1--1}
}

@article{carroll_analysis_1970,
	title = {Analysis of individual differences in multidimensional scaling via an n-way generalization of “{Eckart}-{Young}” decomposition},
	volume = {35},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02310791},
	doi = {10.1007/BF02310791},
	abstract = {An individual differences model for multidimensional scaling is outlined in which individuals are assumed differentially to weight the several dimensions of a common “psychological space”. A corresponding method of analyzing similarities data is proposed, involving a generalization of “Eckart-Young analysis” to decomposition of three-way (or higher-way) tables. In the present case this decomposition is applied to a derived three-way table of scalar products between stimuli for individuals. This analysis yields a stimulus by dimensions coordinate matrix and a subjects by dimensions matrix of weights. This method is illustrated with data on auditory stimuli and on perception of nations.},
	language = {en},
	number = {3},
	urldate = {2020-08-07},
	journal = {Psychometrika},
	author = {Carroll, J. Douglas and Chang, Jih-Jie},
	month = sep,
	year = {1970},
	pages = {283--319}
}

@article{ashby_similarity_2007,
	title = {Similarity measures},
	volume = {2},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Similarity_measures},
	doi = {10.4249/scholarpedia.4116},
	language = {en},
	number = {12},
	urldate = {2020-08-07},
	journal = {Scholarpedia},
	author = {Ashby, F. and Ennis, Daniel},
	year = {2007},
	pages = {4116}
}

@misc{erp_distilling_2003,
	title = {Distilling the underlying dimensions of tactile melodies},
	url = {http://resolver.tudelft.nl/uuid:fdf5e466-059c-4164-99af-a3352f755c7c},
	abstract = {We created 59 tactile melodies by transforming pieces of music from the auditory domain to the vibrotactile domain. Sixteen observers judged these tactile melodies on a set of 16 characteristics such as 'melodious', 'bombastic', and 'alarming'. By using advanced multivariate statistical methods, we distilled two main underlying dimensions of the tactile melodies. We interpreted these dimensions as intrusiveness and tempo. The results are important to understand the perception of tactile melodies and to support the creation of better distinguishable and recognizable tactile signals for single point tactile displays such as in mobile phones and computer mice.},
	language = {en},
	urldate = {2020-08-06},
	author = {Erp, J. B. F. van and Spapé, M. M. A. and {TNO Technische Menskunde}},
	month = jan,
	year = {2003},
	keywords = {Perception, tactile displays}
}

@article{farrington_seven_2011,
	title = {Seven plus or minus two},
	volume = {23},
	copyright = {Copyright © 2011 International Society for Performance Improvement},
	issn = {1937-8327},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/piq.20099},
	doi = {10.1002/piq.20099},
	abstract = {For over 50 years, seven plus or minus two has been a commonly used guideline for gauging how many chunks of new information should be presented at one time in learning and performance situations. Often cited as the limit of working memory, this guideline was created as a result of misinterpreting an article by Miller (1956). More recent studies suggest that the limit for working memory is more like three, and sometimes four, with various factors influencing the capacity of an individual's working memory. Given too much novel information at one time, learners and performers can be derailed by cognitive overload. Instructional designers and performance consultants can adjust the presentation of new information to manage intrinsic, extraneous, and germane cognitive load. This column provides suggestions about how to reduce cognitive overload to improve learning and performance.},
	language = {en},
	number = {4},
	urldate = {2020-07-17},
	journal = {Performance Improvement Quarterly},
	author = {Farrington, Jeanne},
	year = {2011},
	pages = {113--116}
}

@article{king_logistic_2001,
	title = {Logistic {Regression} in {Rare} {Events} {Data}},
	language = {en},
	author = {King, Gary and Zeng, Langche},
	year = {2001},
	pages = {27}
}

@inproceedings{hoggan_pressages_2012,
	address = {Cambridge, Massachusetts, USA},
	title = {Pressages: augmenting phone calls with non-verbal messages},
	isbn = {978-1-4503-1580-7},
	shorttitle = {Pressages},
	url = {http://dl.acm.org/citation.cfm?doid=2380116.2380185},
	doi = {10.1145/2380116.2380185},
	abstract = {ForcePhone is a mobile synchronous haptic communication system. During phone calls, users can squeeze the side of the device and the pressure level is mapped to vibrations on the recipient’s device. The pressure/vibrotactile messages supported by ForcePhone are called pressages. Using a labbased study and a small field study, this paper addresses the following questions: how can haptic interpersonal communication be integrated into a standard mobile device? What is the most appropriate feedback design for pressages? What types of non-verbal cues can be represented by pressages? Do users make use of pressages during their conversations? The results of this research indicate that such a system has value as a communication channel in real-world settings with users expressing greetings, presence and emotions through pressages.},
	language = {en},
	urldate = {2020-07-17},
	booktitle = {Proceedings of the 25th annual {ACM} symposium on {User} interface software and technology - {UIST} '12},
	publisher = {ACM Press},
	author = {Hoggan, Eve and Stewart, Craig and Haverinen, Laura and Jacucci, Giulio and Lantz, Vuokko},
	year = {2012},
	pages = {555}
}

@inproceedings{kaaresoja_perception_2005,
	title = {Perception of short tactile pulses generated by a vibration motor in a mobile phone},
	isbn = {978-0-7695-2310-1},
	doi = {10.1109/WHC.2005.103},
	abstract = {This paper describes an experimental setup and results of user tests focusing on the perception of temporal characteristics of vibration of a mobile device. The experiment consisted of six vibration stimuli of different length. We asked the subjects to score the subjective perception level in a five point Lickert scale. The results suggest that the optimal duration of the control signal should be between 50 and 200 ms in this specific case. Longer durations were perceived as being irritating.},
	author = {Kaaresoja, Topi and Linjama, Jukka},
	month = apr,
	year = {2005},
	pages = {471--472}
}

@article{jones_tactile_2008,
	title = {Tactile {Displays}: {Guidance} for {Their} {Design} and {Application}:},
	shorttitle = {Tactile {Displays}},
	url = {https://journals.sagepub.com/doi/10.1518/001872008X250638},
	doi = {10.1518/001872008X250638},
	abstract = {Objective: This article provides an overview of tactile displays. Its goal is to assist human factors practitioners in deciding when and how to employ the sense...},
	language = {en},
	urldate = {2020-07-08},
	journal = {Human Factors},
	author = {Jones, Lynette A. and Sarter, Nadine B.},
	month = feb,
	year = {2008}
}

@book{nukarinen_assisting_2019,
	title = {Assisting {Navigation} and {Object} {Selection} with {Vibrotactile} {Cues}},
	copyright = {This publication is copyrighted. You may download, display and print it for Your own personal use. Commercial use is prohibited.},
	isbn = {978-952-03-1005-9},
	url = {https://trepo.tuni.fi/handle/10024/105219},
	abstract = {Our lives have been drastically altered by information technology in the last 
decades, leading to evolutionary mismatches between human traits and the 
modern environment. One particular mismatch occurs when visually 
demanding information technology overloads the perceptual, cognitive or 
motor capabilities of the human nervous system. This information overload 
could be partly alleviated by complementing visual interaction with haptics. 
 
The primary aim of this thesis was to investigate how to assist movement 
control with vibrotactile cues. Vibrotactile cues refer to technologymediated 
vibrotactile signals that notify users of perceptual events, propose 
users to make decisions, and give users feedback from actions. To explore 
vibrotactile cues, we carried out five experiments in two contexts of 
movement control: navigation and object selection. The goal was to find 
ways to reduce information load in these tasks, thus helping users to 
accomplish the tasks more effectively. We employed measurements such as 
reaction times, error rates, and task completion times. We also used 
subjective rating scales, short interviews, and free-form participant 
comments to assess the vibrotactile assisted interactive systems. 
 
The findings of this thesis can be summarized as follows. First, if the context 
of movement control allows the use of both feedback and feedforward cues, 
feedback cues are a reasonable first option. Second, when using vibrotactile 
feedforward cues, using low-level abstractions and supporting the 
interaction with other modalities can keep the information load as low as 
possible. Third, the temple area is a feasible actuation location for 
vibrotactile cues in movement control, including navigation cues and object 
selection cues with head turns. However, the usability of the area depends 
on contextual factors such as spatial congruency, the actuation device, and 
the pace of the interaction task.},
	language = {en},
	urldate = {2020-07-08},
	publisher = {Tampereen yliopisto},
	author = {Nukarinen, Tomi},
	year = {2019}
}

@article{geldard_adventures_1957,
	title = {Adventures in tactile literacy},
	volume = {12},
	issn = {1935-990X(Electronic),0003-066X(Print)},
	doi = {10.1037/h0040416},
	abstract = {"The human integument has been the object of precious little research effort on the part of psychologists. The reasons are not easy to ascertain… ." The integument is discussed as a receiving surface for several different forms of energy—mechanical, thermal, electrical, and chemical. The discriminative capacities of the skin are considered with regard to the transmission of messages cutaneously, particularly mechanically. 3 primary and independent dimensions of vibratory cutaneous stimulation are indicated: amplitude, duration, and locus. The value of a vibratory language is discussed. A summary of a film "Vibratory Communication Experiments, University of Virginia, 1956" is presented. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {American Psychologist},
	author = {Geldard, Frank A.},
	year = {1957},
	keywords = {Language, Literacy, Psychologists},
	pages = {115--124}
}

@article{li_hybrid-mst_2018,
	title = {Hybrid-{MST}: {A} {Hybrid} {Active} {Sampling} {Strategy} for {Pairwise} {Preference} {Aggregation}},
	shorttitle = {Hybrid-{MST}},
	url = {http://arxiv.org/abs/1810.08851},
	abstract = {In this paper we present a hybrid active sampling strategy for pairwise preference aggregation, which aims at recovering the underlying rating of the test candidates from sparse and noisy pairwise labelling. Our method employs Bayesian optimization framework and Bradley-Terry model to construct the utility function, then to obtain the Expected Information Gain (EIG) of each pair. For computational efficiency, Gaussian-Hermite quadrature is used for estimation of EIG. In this work, a hybrid active sampling strategy is proposed, either using Global Maximum (GM) EIG sampling or Minimum Spanning Tree (MST) sampling in each trial, which is determined by the test budget. The proposed method has been validated on both simulated and real-world datasets, where it shows higher preference aggregation ability than the state-of-the-art methods.},
	urldate = {2020-07-06},
	journal = {arXiv:1810.08851 [cs, stat]},
	author = {Li, Jing and Mantiuk, Rafal K. and Wang, Junle and Ling, Suiyi and Callet, Patrick Le},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.08851},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{noauthor_foundations_1954,
	title = {The foundations of statistics. {By} {Leonard} {J}. {Savage}, {John} {Wiley} \& {Sons}, {Inc}., 1954, 294 pp},
	volume = {1},
	issn = {1931-9193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800010316},
	doi = {10.1002/nav.3800010316},
	language = {en},
	number = {3},
	urldate = {2020-07-06},
	journal = {Naval Research Logistics Quarterly},
	year = {1954},
	pages = {236--236}
}

@article{wickelmaier_matlab_2004,
	title = {A {Matlab} function to estimate choice model parameters from paired-comparison data},
	volume = {36},
	issn = {1532-5970},
	url = {https://doi.org/10.3758/BF03195547},
	doi = {10.3758/BF03195547},
	abstract = {Tversky (1972) has proposed a family of models for paired-comparison data that generalize the Bradley—Terry—Luce (BTL) model and can, therefore, apply to a diversity of situations in which the BTL model is doomed to fail. In this article, we present a Matlab function that makes it easy to specify any of these general models (EBA, Pretree, or BTL) and to estimate their parameters. The program eliminates the time-consuming task of constructing the likelihood function by hand for every single model. The usage of the program is illustratedby several examples. Features of the algorithm are outlined. The purpose of this article is to facilitate the use of probabilistic choice models in the analysis of data resulting from paired comparisons.},
	language = {en},
	number = {1},
	urldate = {2020-07-06},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Wickelmaier, Florian and Schmid, Christian},
	month = feb,
	year = {2004},
	pages = {29--40}
}

@article{handley_comparative_2001,
	title = {Comparative {Analysis} of {Bradley}-{Terry} and {Thurstone}-{Mosteller} {Paired} {Comparison} {Models} for {Image} {Quality} {Assessment}},
	abstract = {In image quality assessment, preference for various image processing algorithms or treatments is often determined using paired comparisons. In this experimental design, pairs of images processed by different algorithms or “treatments” are presented to a judge. The preferred treatment is selected and a tally is kept of the number of times each treatment is preferred to another. It is possible to estimate an interval scale for treatments in a hypothetical psychological space using this method.},
	language = {en},
	author = {Handley, John C},
	year = {2001},
	pages = {5}
}

@article{dotson_probit_2018,
	title = {A {Probit} {Model} with {Structured} {Covariance} for {Similarity} {Effects} and {Source} of {Volume} {Calculations}},
	volume = {55},
	issn = {0022-2437},
	url = {https://doi.org/10.1509/jmr.13.0240},
	doi = {10.1509/jmr.13.0240},
	abstract = {Distributional assumptions for random utility models play an important role in relating observed product attributes to choice probabilities. Choice probabilities derived with independent errors have the property of independence of irrelevant alternatives, which often does not match observed substitution behavior and leads to inaccurate calculations of source of volume when new entrants are introduced. In this article, the authors parameterize the covariance matrix for a probit model so that similar brands in the preference space have higher correlation than dissimilar brands, resulting in higher rates of substitution. They find across multiple data sets that similarity based on overall utility, not just attributes, defines products as similar with heightened rates of substitution. The proposed model results in better in-sample and predictive fits to the data and more realistic measures of substitution for a new product introduction.},
	language = {en},
	number = {1},
	urldate = {2020-07-06},
	journal = {Journal of Marketing Research},
	author = {Dotson, Jeffrey P. and Howell, John R. and Brazell, Jeff D. and Otter, Thomas and Lenk, Peter J. and MacEachern, Steve and Allenby, Greg M.},
	month = feb,
	year = {2018},
	pages = {35--47}
}

@inproceedings{pescara_genvibe_2020,
	address = {Kaiserslautern Germany},
	title = {{GenVibe}: {Exploration} of {Interactive} {Generation} of {Personal} {Vibrotactile} {Patterns}},
	isbn = {978-1-4503-7603-7},
	shorttitle = {{GenVibe}},
	url = {https://dl.acm.org/doi/10.1145/3384657.3384794},
	doi = {10.1145/3384657.3384794},
	abstract = {Research about vibrotactile patterns is traditionally conducted with patterns handcrafted by experts which are then subsequently evaluated in general user studies. The current empirical approach to designing vibrotactile patterns mostly utilizes expert decisions and is notably not adapted to individual differences in the perception of vibration. This work describes GenVibe: a novel approach to designing vibrotactile patterns by examining the automatic generation of personal patterns. GenVibe adjusts patterns to the perception of an individual through the utilization of interactive generative models. An algorithm is described and tested with a dummy smartphone made from off-the-shelf electronic components. Afterward, a user study with 11 participants evaluates the outcome of GenVibe. Results show a significant increase in accuracy from 73.6\% to 84.0\% and a higher confidence ratings by the users.},
	language = {en},
	urldate = {2020-06-13},
	booktitle = {Proceedings of the {Augmented} {Humans} {International} {Conference}},
	publisher = {ACM},
	author = {Pescara, Erik and Dreschner, Florian and Marky, Karola and Kunze, Kai and Beigl, Michael},
	month = mar,
	year = {2020},
	pages = {1--9}
}

@misc{noauthor_demers_marc_master_thesis_nodate,
	title = {Demers\_Marc\_master\_thesis},
	url = {https://www.overleaf.com/project/5dc4332f45291100013d52f2},
	abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2020-06-02}
}

@article{xing_distance_2002,
	title = {Distance metric learning, with application to clustering with side-information},
	abstract = {Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many “plausible” ways, and if a clustering algorithm such as K-means initially fails to ﬁnd one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufﬁciently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider “similar.” For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in ¢¤£ , learns a distance metric over ¢¥£ that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efﬁcient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to signiﬁcantly improve clustering performance.},
	language = {en},
	author = {Xing, Eric P and Ng, Andrew Y and Jordan, Michael I and Russell, Stuart},
	year = {2002},
	pages = {8}
}

@article{guo-dong_guo_learning_2002,
	title = {Learning similarity measure for natural image retrieval with relevance feedback},
	volume = {13},
	issn = {1941-0093},
	doi = {10.1109/TNN.2002.1021882},
	abstract = {A new scheme of learning similarity measure is proposed for content-based image retrieval (CBIR). It learns a boundary that separates the images in the database into two clusters. Images inside the boundary are ranked by their Euclidean distances to the query. The scheme is called constrained similarity measure (CSM), which not only takes into consideration the perceptual similarity between images, but also significantly improves the retrieval performance of the Euclidean distance measure. Two techniques, support vector machine (SVM) and AdaBoost from machine learning, are utilized to learn the boundary. They are compared to see their differences in boundary learning. The positive and negative examples used to learn the boundary are provided by the user with relevance feedback. The CSM metric is evaluated in a large database of 10009 natural images with an accurate ground truth. Experimental results demonstrate the usefulness and effectiveness of the proposed similarity measure for image retrieval.},
	number = {4},
	journal = {IEEE Transactions on Neural Networks},
	author = {Guo-Dong Guo and Jain, A.K. and Wei-Ying Ma and Hong-Jiang Zhang},
	month = jul,
	year = {2002},
	keywords = {AdaBoost, CBIR, CSM, Content based retrieval, Euclidean distance, Euclidean distance measure, Feedback, Humans, Image databases, Image retrieval, Indexing, Information retrieval, Machine learning, SVM, Support vector machines, constrained similarity measure, content-based image retrieval, content-based retrieval, image retrieval, image separation, machine learning, natural image retrieval, pattern clustering, relevance feedback, similarity measure learning, support vector machine},
	pages = {811--820}
}

@article{carroll_analysis_1970-1,
	title = {Analysis of individual differences in multidimensional scaling via an n-way generalization of “{Eckart}-{Young}” decomposition},
	volume = {35},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02310791},
	doi = {10.1007/BF02310791},
	abstract = {An individual differences model for multidimensional scaling is outlined in which individuals are assumed differentially to weight the several dimensions of a common “psychological space”. A corresponding method of analyzing similarities data is proposed, involving a generalization of “Eckart-Young analysis” to decomposition of three-way (or higher-way) tables. In the present case this decomposition is applied to a derived three-way table of scalar products between stimuli for individuals. This analysis yields a stimulus by dimensions coordinate matrix and a subjects by dimensions matrix of weights. This method is illustrated with data on auditory stimuli and on perception of nations.},
	language = {en},
	number = {3},
	urldate = {2020-06-02},
	journal = {Psychometrika},
	author = {Carroll, J. Douglas and Chang, Jih-Jie},
	month = sep,
	year = {1970},
	pages = {283--319}
}

@article{ennis_thurstone-shepard_1993,
	title = {Thurstone-{Shepard} {Similarity} {Models} as {Special} {Cases} of {Moment} {Generating} {Functions}},
	volume = {37},
	issn = {0022-2496},
	url = {http://www.sciencedirect.com/science/article/pii/S0022249683710059},
	doi = {10.1006/jmps.1993.1005},
	abstract = {Certain probabilistic multivariate similarity models are shown to be special cases of moment generating functions. These models, introduced in Ennis, Palen, and Mullen (1988, Journal of Mathematical Psychology,32, 449-465), are based on Thurstonian (1927, Psychological Review,34, 273-286), ideas about the distribution of momentary psychological magnitudes and Shepard's (1957, Psychometrika,22, 325-345; 1987, Science,237, 1317-1323), proposals about the form of the similarity function. Two cases are discussed: (a) The Euclidean/Gaussian case, which is a special case of the moment generating function of a quadratic form; and (b) the city-block/exponential decay case, which is a special case of the moment generating function of the sum of folded normal random variables. In both cases, computationally simple mathematical expressions are given.},
	language = {en},
	number = {1},
	urldate = {2020-06-02},
	journal = {Journal of Mathematical Psychology},
	author = {Ennis, Daniel M. and Johnson, Norman L.},
	month = mar,
	year = {1993},
	pages = {104--110}
}

@book{young_multidimensional_1987,
	address = {Hillsdale, N.J.},
	title = {Multidimensional scaling: history, theory, and applications},
	isbn = {978-0-89859-663-2},
	shorttitle = {Multidimensional scaling},
	abstract = {This presentation of the fundamentals of multidimensional scaling illustrates the applicability of MDS to a wide variety of disciplines. The first two sections provide ground work in the history and theory of MDS. The final section applies MDS techniques to such diverse fields as physics, marketing, and political science.},
	language = {English},
	publisher = {L. Erlbaum Associates},
	author = {Young, Forrest W and Hamer, Robert M},
	year = {1987},
	note = {OCLC: 13792004}
}

@article{goldstone_role_1994,
	title = {The role of similarity in categorization: providing a groundwork},
	volume = {52},
	issn = {0010-0277},
	shorttitle = {The role of similarity in categorization},
	doi = {10.1016/0010-0277(94)90065-5},
	abstract = {The relation between similarity and categorization has recently come under scrutiny from several sectors. The issue provides an important inroad to questions about the contributions of high-level thought and lower-level perception in the development of people's concepts. Many psychological models base categorization on similarity, assuming that things belong in the same category because of their similarity. Empirical and in-principle arguments have recently raised objections to this connection, on the grounds that similarity is too unconstrained to provide an explanation of categorization, and similarity is not sufficiently sophisticated to ground most categories. Although these objections have merit, a reassessment of evidence indicates that similarity can be sufficiently constrained and sophisticated to provide at least a partial account of many categories. Principles are discussed for incorporating similarity into theories of category formation.},
	language = {eng},
	number = {2},
	journal = {Cognition},
	author = {Goldstone, R. L.},
	month = aug,
	year = {1994},
	pmid = {7924201},
	keywords = {Cognition, Concept Formation, Humans},
	pages = {125--157}
}

@article{osherson_category-based_1990,
	title = {Category-based induction},
	volume = {97},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/0033-295X.97.2.185},
	abstract = {An argument is categorical if its premises and conclusion are of the form All members of C have property P, where C is a natural category like FALCON or BIRD, and P remains the same across premises and conclusion. An example is Grizzly bears love onions. Therefore, all bears love onions. Such an argument is psychologically strong to the extent that belief in its premises engenders belief in its conclusion. A subclass of categorical arguments is examined, and the following hypothesis is advanced: The strength of a categorical argument increases with (a) the degree to which the premise categories are similar to the conclusion category and (b) the degree to which the premise categories are similar to members of the lowest level category that includes both the premise and the conclusion categories. A model based on this hypothesis accounts for 13 qualitative phenomena and the quantitative results of several experiments. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Review},
	author = {Osherson, Daniel N. and Smith, Edward E. and Wilkie, Ormond and López, Alejandro and Shafir, Eldar},
	year = {1990},
	keywords = {Classification (Cognitive Process), Inductive Deductive Reasoning, Models},
	pages = {185--200}
}

@article{hampton_similarity-based_1998,
	title = {Similarity-{Based} {Categorization} and {Fuzziness} of {Natural} {Categories}},
	volume = {65},
	doi = {10.1016/S0010-0277(97)00042-5},
	abstract = {The adequacy of similarity to prototype as an account of categorization in natural concepts was assessed by analyzing the monotonicity of the relation between typicality of an item in a category and the probability of a positive categorization response using data from McCloskey and Glucksberg (1978). The analysis revealed a strong underlying similarity-based threshold curve, with systematic deviations. Further data collection showed that deviations from the curve could be attributed to the effects of unfamiliarity and non-categorical associations on typicality judgments, as well as differences between the perceptual appearance of an item (which tended to boost typicality) and its underlying nature (which tended to boost categorization). The results are discussed in terms of the different presuppositions and task constraints involved in rating typicality as opposed to performing a categorization.},
	journal = {Cognition},
	author = {Hampton, James},
	month = feb,
	year = {1998},
	pages = {137--65}
}

@article{goldstone_role_1994-1,
	title = {The role of similarity in categorization: providing a groundwork},
	volume = {52},
	issn = {0010-0277},
	shorttitle = {The role of similarity in categorization},
	doi = {10.1016/0010-0277(94)90065-5},
	abstract = {The relation between similarity and categorization has recently come under scrutiny from several sectors. The issue provides an important inroad to questions about the contributions of high-level thought and lower-level perception in the development of people's concepts. Many psychological models base categorization on similarity, assuming that things belong in the same category because of their similarity. Empirical and in-principle arguments have recently raised objections to this connection, on the grounds that similarity is too unconstrained to provide an explanation of categorization, and similarity is not sufficiently sophisticated to ground most categories. Although these objections have merit, a reassessment of evidence indicates that similarity can be sufficiently constrained and sophisticated to provide at least a partial account of many categories. Principles are discussed for incorporating similarity into theories of category formation.},
	language = {eng},
	number = {2},
	journal = {Cognition},
	author = {Goldstone, R. L.},
	month = aug,
	year = {1994},
	pmid = {7924201},
	keywords = {Cognition, Concept Formation, Humans},
	pages = {125--157}
}

@article{goldstone_role_1994-2,
	title = {The role of similarity in categorization: providing a groundwork},
	volume = {52},
	issn = {00100277},
	shorttitle = {The role of similarity in categorization},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0010027794900655},
	doi = {10.1016/0010-0277(94)90065-5},
	abstract = {The relation between similarity and categorization has recently come under scrutiny from several sectors. The issue provides an important inroad to questions about the contributions of high-level thought and lower-level perception in the development of people’s concepts. Many psychological models base categorization on similarity, assuming that things belong in the same category because of their similarity. Empirical and in-principle arguments have recently raised objections to this connection, on the grounds that similarity is too unconstrained to provide an explanation of categorization, and similarity is not sufficiently sophisticated to ground most categories. Although these objections have merit, a reassessment of evidence indicates that similarity can be sufficiently constrained and sophisticated to provide at least a partial account of many categories. Principles are discussed for incorporating similarity into theories of category formation.},
	language = {en},
	number = {2},
	urldate = {2020-06-02},
	journal = {Cognition},
	author = {Goldstone, Robert L.},
	month = aug,
	year = {1994},
	pages = {125--157}
}

@misc{noauthor_demers_marc_master_thesis_nodate-1,
	title = {Demers\_Marc\_master\_thesis},
	url = {https://www.overleaf.com/project/5dc4332f45291100013d52f2},
	abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2020-06-01}
}

@book{seifi_personalizing_2019,
	address = {Cham},
	series = {Springer {Series} on {Touch} and {Haptic} {Systems}},
	title = {Personalizing {Haptics}: {From} {Individuals}' {Sense}-{Making} {Schemas} to {End}-{User} {Haptic} {Tools}},
	isbn = {978-3-030-11378-0 978-3-030-11379-7},
	shorttitle = {Personalizing {Haptics}},
	url = {http://link.springer.com/10.1007/978-3-030-11379-7},
	language = {en},
	urldate = {2020-05-31},
	publisher = {Springer International Publishing},
	author = {Seifi, Hasti},
	year = {2019},
	doi = {10.1007/978-3-030-11379-7}
}

@article{ashby_similarity_2007-1,
	title = {Similarity measures},
	volume = {2},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Similarity_measures},
	doi = {10.4249/scholarpedia.4116},
	language = {en},
	number = {12},
	urldate = {2020-05-28},
	journal = {Scholarpedia},
	author = {Ashby, F. and Ennis, Daniel},
	year = {2007},
	pages = {4116}
}
@inproceedings{park_perceptual_2011,
	title = {Perceptual space of amplitude-modulated vibrotactile stimuli},
	doi = {10.1109/WHC.2011.5945462},
	abstract = {Amplitude-modulated vibrotactile stimuli have been broadly used for tactile perception and rendering research. However, understandings of the perceptual relations between amplitude-modulated vibrations are not comprehensive yet. In this paper, we present a perceptual analysis on the identifying characteristics of amplitude-modulated vibrations and their perceptual relations. We estimated the perceptual dissimilarities among one carrier and seven amplitude-modulated sinusoidal vibrations (150-Hz carrier frequency; seven modulation frequencies in 1-80 Hz) in a psychophysical experiment. The dissimilarity scores were inspected using multi-dimensional scaling to obtain an appropriate perceptual space. The optimal perceptual space was two-dimensional, where the vibration points exhibited a circular formation. The analysis showed that the pulse-like low-frequency sensation of an amplitude-modulated vibration increased for very low modulation frequencies (1-10 Hz), then decreased for higher modulation frequencies (10-80 Hz), and eventually converged to the smooth vibrational sensation of the 150-Hz carrier signal. It also suggested that the envelope waveform is primary information for the discrimination of amplitude-modulated signals, instead of their spectral energy distributions. These findings can contribute to the design of perceptually salient and distinctive vibrotactile signals using amplitude modulation.},
	booktitle = {2011 {IEEE} {World} {Haptics} {Conference}},
	author = {Park, Gunhyuk and Choi, Seungmoon},
	month = jun,
	year = {2011},
	keywords = {Actuators, Amplitude modulation, Frequency modulation, H.1.2 [Models and Principles]: User/Machines Systems—Human Information Processing, H.5.2 [Information Interfaces and Presentation]: User Interfaces—Haptic I/O, Resonant frequency, Time frequency analysis, Vibrations, amplitude modulated vibrotactile stimuli, amplitude modulation, bioelectric phenomena, frequency 150 Hz, frequency modulation, haptic interfaces, neurophysiology, perceptual analysis, perceptual space, psychology, psychophysical esperiment, rendering, rendering (computer graphics), tactile perception, vibrations, vibrotactile signals},
	pages = {59--64}
}

@article{gaisert_similarity_2011,
	title = {Similarity and categorization: {From} vision to touch},
	volume = {138},
	issn = {0001-6918},
	shorttitle = {Similarity and categorization},
	url = {http://www.sciencedirect.com/science/article/pii/S0001691811001302},
	doi = {10.1016/j.actpsy.2011.06.007},
	abstract = {Even though human perceptual development relies on combining multiple modalities, most categorization studies so far have focused on the visual modality. To better understand the mechanisms underlying multisensory categorization, we analyzed visual and haptic perceptual spaces and compared them with human categorization behavior. As stimuli we used a three-dimensional object space of complex, parametrically-defined objects. First, we gathered similarity ratings for all objects and analyzed the perceptual spaces of both modalities using multidimensional scaling analysis. Next, we performed three different categorization tasks which are representative of every-day learning scenarios: in a fully unconstrained task, objects were freely categorized, in a semi-constrained task, exactly three groups had to be created, whereas in a constrained task, participants received three prototype objects and had to assign all other objects accordingly. We found that the haptic modality was on par with the visual modality both in recovering the topology of the physical space and in solving the categorization tasks. We also found that within-category similarity was consistently higher than across-category similarity for all categorization tasks and thus show how perceptual spaces based on similarity can explain visual and haptic object categorization. Our results suggest that both modalities employ similar processes in forming categories of complex objects.},
	language = {en},
	number = {1},
	urldate = {2020-05-28},
	journal = {Acta Psychologica},
	author = {Gaißert, Nina and Bülthoff, Heinrich H. and Wallraven, Christian},
	month = sep,
	year = {2011},
	keywords = {Categorization, Haptics, Multisensory perception, Perceptual spaces, Similarity, Vision},
	pages = {219--230}
}

@article{cooke_object_2006,
	title = {Object feature validation using visual and haptic similarity ratings},
	volume = {3},
	issn = {1544-3558},
	url = {https://doi.org/10.1145/1166087.1166093},
	doi = {10.1145/1166087.1166093},
	abstract = {The perceived similarity between objects may well vary according to the sensory modality/modalities in which they are experienced, an important consideration for the design of multimodal interfaces. In this study, we present a similarity-based method for comparing the perceptual importance of object properties in touch and in vision and show how the method can also be used to validate computational measures of object properties. Using either vision or touch, human subjects judged the similarity between novel, 3D objects which varied parametrically in shape and texture. Similarities were also computed using a set of state-of-the art 2D and 3D computational measures. Two resolutions of 2D and 3D object data were used for these computations in order to test for scale dependencies. Multidimensional scaling (MDS) was then performed on all similarity data, yielding maps of the stimuli in both perceptual and computational spaces, as well as the relative weight of shape and texture dimensions. For this object set, we found that visual subjects accorded more importance to shape than texture, while haptic subjects weighted them roughly evenly. Fit errors between human and computational maps were then calculated to assess each feature's perceptual validity. Shape-biased features provided good overall fits to the human visual data; however, no single feature yielded a good overall fit to the haptic data, in which we observed large individual differences. This work demonstrates how MDS techniques can be used to evaluate computational object features using the criterion of perceptual similarity. It also demonstrates a way of assessing how the perceptual validity of a feature varies as a function of parameters such as the target modality and the resolution of object data. Potential applications of this method for the design of unimodal and multimodal human---machine interfaces are discussed.},
	number = {3},
	urldate = {2020-05-28},
	journal = {ACM Transactions on Applied Perception},
	author = {Cooke, Theresa and Kannengiesser, Sebastian and Wallraven, Christian and Bülthoff, Heinrich H.},
	month = jul,
	year = {2006},
	keywords = {Similarity, features, haptic, multidimensional scaling, perception, shape, texture, touch, validation, vision},
	pages = {239--261}
}

@article{jehan_event-synchronous_2004,
	title = {{EVENT}-{SYNCHRONOUS} {MUSIC} {ANALYSIS} / {SYNTHESIS}},
	abstract = {This work presents a novel framework for music synthesis, based on the perceptual structure analysis of pre-existing musical signals, for example taken from a personal MP3 database. We raise the important issue of grounding music analysis on perception, and propose a bottom-up approach to music analysis, as well as modeling, and synthesis. A model of segmentation for polyphonic signals is described, and is qualitatively validated through several artifact-free music resynthesis experiments, e.g., reversing the ordering of sound events (notes), without reversing their waveforms. Then, a compact “timbre” structure analysis, and a method for song description in the form of an “audio DNA” sequence is presented. Finally, we propose novel applications, such as music cross-synthesis, or time-domain audio compression, enabled through simple sound similarity measures, and clustering.},
	language = {en},
	author = {Jehan, Tristan},
	year = {2004},
	pages = {6}
}

@inproceedings{silva_simple_2016,
	title = {{SiMPle}: {Assessing} {Music} {Similarity} {Using} {Subsequences} {Joins}},
	shorttitle = {{SiMPle}},
	abstract = {Most algorithms for music information retrieval are based on the analysis of the similarity between feature sets extracted from the raw audio. A common approach to assessing similarities within or between recordings is by creating similarity matrices. However, this approach requires quadratic space for each comparison and typically requires a costly post-processing of the matrix. In this work, we propose a simple and efficient representation based on a subsequence similarity join, which may be used in several music information retrieval tasks. We apply our method to the cover song recognition problem and demonstrate that it is superior to state-of-the-art algorithms. In addition, we demonstrate how the proposed representation can be exploited for multiple applications in music processing.},
	booktitle = {{ISMIR}},
	author = {Silva, Diego Furtado and Yeh, Chin-Chia Michael and Batista, Gustavo E. A. P. A. and Keogh, Eamonn J.},
	year = {2016}
}

@article{cooper_automatic_2002,
	title = {Automatic {Music} {Summarization} via {Similarity} {Analysis}},
	abstract = {We present methods for automatically producing summary excerpts or thumbnails of music. To find the most representative excerpt, we maximize the average segment similarity to the entire work. After window-based audio parameterization, a quantitative similarity measure is calculated between every pair of windows, and the results are embedded in a 2-D similarity matrix. Summing the similarity matrix over the support of a segment results in a measure of how similar that segment is to the whole. This can be maximized to find the segment that best represents the entire work. We discuss variations on the method, and present experimental results for orchestral music, popular songs, and jazz. These results demonstrate that the method finds significantly representative excerpts, using very few assumptions about the source audio.},
	author = {Cooper, Matthew and Foote, Jonathan},
	month = aug,
	year = {2002}
}

@inproceedings{foote_beat_2001,
	address = {Tokyo, Japan},
	title = {The beat spectrum: a new approach to rhythm analysis},
	isbn = {978-0-7695-1198-6},
	shorttitle = {The beat spectrum},
	url = {http://ieeexplore.ieee.org/document/1237863/},
	doi = {10.1109/ICME.2001.1237863},
	abstract = {We introduce the beat spectrum, a new method of automatically characterizing the rhythm and tempo of music and audio. The beat spectrum is a measure of acoustic self-similarity as a function of time lag. Highly structured or repetitive music will have strong beat spectrum peaks at the repetition times. This reveals both tempo and the relative strength of particular beats, and therefore can distinguish between different kinds of rhythms at the same tempo. We also introduce the beat spectrogram which graphically illustrates rhythm variation over time. Unlike previous approaches to tempo analysis, the beat spectrum does not depend on particular attributes such as energy or frequency, and thus will work for any music or audio in any genre. We present tempo estimation results which are accurate to within 1\% for a variety of musical genres. This approach has a variety of applications, including music retrieval by similarity and automatically generating music videos.},
	language = {en},
	urldate = {2020-05-28},
	booktitle = {{IEEE} {International} {Conference} on {Multimedia} and {Expo}, 2001. {ICME} 2001.},
	publisher = {IEEE},
	author = {Foote, J. and Uchihashi, S.},
	year = {2001},
	pages = {881--884}
}

@article{singh_graph_nodate,
	title = {Graph {Based} {Computational} {Model} for {Computing} {Semantic} {Similarity}},
	abstract = {Finding semantic similarity between two natural language entities considered a challenging task in the ﬁeld of natural language processing. Accuracy of presently existing semantic similarity computational methods is still very far from what humans would perceive. In this paper, we present a new approach of measuring semantic similarity/distance between concepts/words by considering all senses instead of using one most common sense of concepts in WordNet hierarchy. Our proposed approach considers not only the semantic distance between two concepts/words but also considers feature information of WordNet graph. When tested on benchmark data set of words pair similarity ratings, the proposed approach performs better than other semantic similarity computational models for ambiguous words/concepts (which has more than one sense). Proposed approach gives the highest correlation coefﬁcient value with human similarity judgments based benchmark data set.},
	language = {en},
	author = {Singh, Jagendra and Saini, Mayank and Siddiqi, Sifatullah},
	pages = {8}
}

@article{hsieh_graph-based_2008,
	title = {Graph-based representation for similarity retrieval of symbolic images},
	volume = {65},
	issn = {0169-023X},
	url = {http://www.sciencedirect.com/science/article/pii/S0169023X07002212},
	doi = {10.1016/j.datak.2007.12.004},
	abstract = {Image retrieval from an image database by the image objects and their spatial relationships has emerged as an important research subject in these decades. To retrieve images similar to a given query image, retrieval methods must assess the similarity degree between a database image and the query image by the extracted features with acceptable efficiency and effectiveness. This paper proposes a graph-based model SRG (spatial relation graph) to represent the semantic information of the contained objects and their spatial relationships in an image with no file annotation. In an SRG graph, the image objects are symbolized by the predefined class names as vertices and the spatial relations between object pairs are represented as arcs. The proposed model assesses the similarity degree between two images by calculating the maximum common subgraph of two corresponding SRG’s through intersection, which has quadratic time complexity owing to the characteristics of SRG. Its efficiency remains quadratic regardless of the duplication rate of the object symbols. The extended model SRGT is also proposed, with the same time complexity, for the applications that need to consider the topological relations among objects. A synthetic symbolic image database and an existing image dataset are used in the conducted experiments to verify the performance of the proposed models. The experimental results show that the proposed models have compatible retrieval quality with remarkable efficiency improvements compared with three well-known methods LCS\_Clique, SIMR, and 2D Be-string, where LCS\_Clique utilizes the number of objects in the maximum common subimage as its similarity function, SIMR uses accumulation-based similarity function of similar object pairs, and 2D Be-string calculates the similarity of 2D patterns by the linear combination of two 1D similarities.},
	language = {en},
	number = {3},
	urldate = {2020-05-28},
	journal = {Data \& Knowledge Engineering},
	author = {Hsieh, Shu-Ming and Hsu, Chiun-Chieh},
	month = jun,
	year = {2008},
	keywords = {Graph algorithms, Image database, Image retrieval, Maximum common subgraph, Similarity function},
	pages = {401--418}
}

@article{perraudin_inpainting_2018,
	title = {Inpainting of {Long} {Audio} {Segments} {With} {Similarity} {Graphs}},
	volume = {26},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2018.2809864},
	abstract = {We present a novel method for the compensation of long duration data loss in audio signals, in particular music. The concealment of such signal defects is based on a graph that encodes signal structure in terms of time-persistent spectral similarity. A suitable candidate segment for the substitution of the lost content is proposed by an intuitive optimization scheme and smoothly inserted into the gap, i.e., the lost or distorted signal region. Extensive listening tests show that the proposed algorithm provides highly promising results when applied to a variety of real-world music signals.},
	number = {6},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Perraudin, Nathanaël and Holighaus, Nicki and Majdak, Piotr and Balazs, Peter},
	month = jun,
	year = {2018},
	keywords = {Audio imputation, Distortion, Multiple signal classification, Music, Redundancy, Speech, Time-frequency analysis, audio inpainting, audio restoration, audio signal processing, audio signals, audio similarity graphs, candidate segment, concealment, concealment of data loss, distorted signal region, extensive listening tests, graph theory, intuitive optimization scheme, long audio segments inpainting, long duration data loss compensation, lost content, lost signal region, music, music recovery, optimisation, real-world music signals, signal defects, signal structure, similarity graphs, time-persistent spectral similarity},
	pages = {1083--1094}
}

@inproceedings{mumford_mathematical_1991,
	title = {Mathematical theories of shape: do they model perception?},
	volume = {1570},
	shorttitle = {Mathematical theories of shape},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/1570/0000/Mathematical-theories-of-shape-do-they-model-perception/10.1117/12.49981.short},
	doi = {10.1117/12.49981},
	abstract = {The mathematics of shape has a long history in the fields of differential geometry and topology. But does this theory of shape address the central problem of vision: finding the best data structure plus algorithm for storing a shape and later recognizing the same and similar shapes. Several criteria may be used to evaluate this: does the data structure capture our intuitive idea of 'similarity'? does it allow reconstruction of typical shapes to compare with new input? One direction in which mathematics and vision have converged is toward multiscale analyses of visual signals and shapes. In other respects, however, the recognition process in animals shows features that still defy mathematical modeling.},
	urldate = {2020-05-28},
	booktitle = {Geometric {Methods} in {Computer} {Vision}},
	publisher = {International Society for Optics and Photonics},
	author = {Mumford, David},
	month = sep,
	year = {1991},
	pages = {2--10}
}

@article{li_graph_2019,
	title = {Graph {Matching} {Networks} for {Learning} the {Similarity} of {Graph} {Structured} {Objects}},
	url = {http://arxiv.org/abs/1904.12787},
	abstract = {This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.},
	urldate = {2020-05-28},
	journal = {arXiv:1904.12787 [cs, stat]},
	author = {Li, Yujia and Gu, Chenjie and Dullien, Thomas and Vinyals, Oriol and Kohli, Pushmeet},
	month = may,
	year = {2019},
	note = {arXiv: 1904.12787},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{yuan_graph_2019,
	title = {Graph kernel based link prediction for signed social networks},
	volume = {46},
	issn = {1566-2535},
	url = {http://www.sciencedirect.com/science/article/pii/S1566253517303019},
	doi = {10.1016/j.inffus.2018.04.004},
	abstract = {By revealing potential relationships between users, link prediction has long been considered as a fundamental research issue in singed social networks. The key of link prediction is to measure the similarity between users. Existing works use connections between target users or their common neighbors to measure user similarity. Rich information available for link prediction is missing since use similarity is widely influenced by many users via social connections. We therefore propose a novel graph kernel based link prediction method, which predicts links by comparing user similarity via signed social network’s structural information: we first generate a set of subgraphs with different strength of social relations for each user, then calculate the graph kernel similarities between subgraphs, in which Bhattacharyya kernel is used to measure the similarity of the k-dimensional Gaussian distributions related to each k-order Krylov subspace generated for each subgraph, and finally train SVM classifier with user similarity information to predict links. Experiments held on real application datasets show that our proposed method has good link prediction performances on both positive and negative link prediction. Our method has significantly higher link prediction accuracy and F1-score than existing works.},
	language = {en},
	urldate = {2020-05-28},
	journal = {Information Fusion},
	author = {Yuan, Weiwei and He, Kangya and Guan, Donghai and Zhou, Li and Li, Chenliang},
	month = mar,
	year = {2019},
	keywords = {Graph kernel, Link prediction, Sign prediction, Signed social network},
	pages = {1--10}
}

@inproceedings{yang_semantic_2019,
	title = {Semantic {Similarity} {Computation} in {Knowledge} {Graphs}: {Comparisons} and {Improvements}},
	shorttitle = {Semantic {Similarity} {Computation} in {Knowledge} {Graphs}},
	doi = {10.1109/ICDEW.2019.000-5},
	abstract = {Computing semantic similarity between concepts is a fundamental task in natural language processing and has a large variety of applications. In this paper, first of all, we will review and analyze existing semantic similarity computation methods in knowledge graphs. Through the analysis of these methods, we find that existing works mainly focus on the context features of concepts which indicate the position or the frequency of the concepts in the knowledge graphs, such as the depth of terms, information content of the terms, or the distance between terms, while a fundamental part to describe the meaning of the concept, the synsets of concepts, are neglected for a long term. Thus, in this paper, we propose a new method to compute the similarity of concepts based on their extended synsets. Moreover, we propose a general hybrid framework, which can combine our new similarity measure based on extended synsets with any of existing context feature based semantic similarities to evaluate the concepts more accurately. We conducted experiments on five well-known datasets for semantic similarity evaluation, and the experimental results show that our general framework can improve most of existing methods significantly.},
	booktitle = {2019 {IEEE} 35th {International} {Conference} on {Data} {Engineering} {Workshops} ({ICDEW})},
	author = {Yang, Chaoqun and Zhu, Yuanyuan and Zhong, Ming and Li, Rongrong},
	month = apr,
	year = {2019},
	note = {ISSN: 2473-3490},
	keywords = {Frequency measurement, Integrated circuits, Motion pictures, Natural language processing, Semantics, Task analysis, Taxonomy, context features, information retrieval, knowledge graph, knowledge graphs, natural language processing, ontologies (artificial intelligence), semantic Web, semantic similarity, semantic similarity computation methods, semantic similarity evaluation, similarity measure, synonym, text analysis},
	pages = {249--252}
}

@inproceedings{rafiq_graph_2019,
	title = {A {Graph} {Theory} {Based} {Method} to {Extract} {Social} {Structure} in the {Society}: {First} {International} {Conference}, {INTAP} 2018, {Bahawalpur}, {Pakistan}, {October} 23-25, 2018, {Revised} {Selected} {Papers}},
	shorttitle = {A {Graph} {Theory} {Based} {Method} to {Extract} {Social} {Structure} in the {Society}},
	abstract = {Huge amount of data is being produced by online social interaction among people. This data can be represented by graphs where nodes represent individuals and the connecting edges depicts their interaction. In this research we analyze a social network of individuals to understand social structure among them. Online interaction has become integral part of life nowadays, large amount of research is available in analyzing these social interactions. However, previous research in this area lacks in identifying social structure among people using email data and graph theory based techniques. In this regard, a model for analyzing social structure of the community is presented in this research. An algorithm is designed to extract social structure of the community named Socio Rank. We crawled a large real world email interaction data in this research and extensive graph theory based experiments are performed to cluster the graph among different communities. Subsequently, widespread analysis was performed to study the hierarchy of social structure in the society. The experiments revealed multiple clusters in the group related to individuals fulfilling different roles in the community. We correlated the connection properties of individual nodes with the behavior of people in the society. Graph based Harel-Koren layout technique and Girvan-Newman clustering algorithm was used for the analysis of the underlying extracted communities. A hierarchical social classification was identified among individuals in the community. Our work of social structure extraction on a controlled community can be correlated with the society at large.},
	author = {Rafiq, Wajid},
	month = mar,
	year = {2019}
}

@book{bajwa_intelligent_2019,
	title = {Intelligent {Technologies} and {Applications}: {First} {International} {Conference}, {INTAP} 2018, {Bahawalpur}, {Pakistan}, {October} 23-25, 2018, {Revised} {Selected} {Papers}},
	isbn = {9789811360527},
	shorttitle = {Intelligent {Technologies} and {Applications}},
	abstract = {This book constitutes the refereed proceedings of the First International Conference on Intelligent Technologies and Applications, INTAP 2018, held in Bahawalpur, Pakistan, in October 2018.The 68 revised full papers and 6 revised short papers presented were carefully reviewed and selected from 251 submissions. The papers of this volume are organized in topical sections on AI and health; sentiment analysis; intelligent applications; social media analytics; business intelligence;Natural Language Processing; information extraction; machine learning; smart systems; semantic web; decision support systems; image analysis; automated software engineering.},
	language = {en},
	publisher = {Springer},
	author = {Bajwa, Imran Sarwar and Kamareddine, Fairouz and Costa, Anna},
	month = mar,
	year = {2019},
	keywords = {Computers / Computer Graphics, Computers / Information Technology, Computers / Natural Language Processing, Computers / Networking / General, Computers / Networking / Hardware, Computers / Optical Data Processing, Computers / Security / General, Computers / Software Development \& Engineering / General, Computers / Speech \& Audio Processing, Computers / System Administration / Storage \& Retrieval}
}

@article{theoharatos_multivariate_2006,
	series = {Similarity-based {Pattern} {Recognition}},
	title = {Multivariate image similarity in the compressed domain using statistical graph matching},
	volume = {39},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320306001622},
	doi = {10.1016/j.patcog.2006.04.015},
	abstract = {We address the problem of image similarity in the compressed domain, using a multivariate statistical test for comparing color distributions. Our approach is based on the multivariate Wald–Wolfowitz test, a nonparametric test that assesses the commonality between two different sets of multivariate observations. Using some pre-selected feature attributes, the similarity measure provides a comprehensive estimate of the match between different images based on graph theory and the notion of minimal spanning tree (MST). Feature extraction is directly provided from the JPEG discrete cosine transform (DCT) domain, without involving full decompression or inverse DCT. Based on the zig-zag scheme, a novel selection technique is introduced that guarantees image's enhanced invariance to geometric transformations. To demonstrate the performance of the proposed method, the application on a diverse collection of images has been systematically studied in a query-by-example image retrieval task. Experimental results show that a powerful measure of similarity between compressed images can emerge from the statistical comparison of their pattern representations.},
	language = {en},
	number = {10},
	urldate = {2020-05-28},
	journal = {Pattern Recognition},
	author = {Theoharatos, Ch. and Pothos, V. K. and Laskaris, N. A. and Economou, G. and Fotopoulos, S.},
	month = oct,
	year = {2006},
	keywords = {Discrete cosine transform (DCT), Graph matching, Image retrieval, Image similarity, JPEG image compression, Minimal spanning tree (MST), Multivariate statistics, Similarity measures},
	pages = {1892--1904}
}

@book{knees_music_2016,
	address = {Berlin Heidelberg},
	series = {The {Information} {Retrieval} {Series}},
	title = {Music {Similarity} and {Retrieval}: {An} {Introduction} to {Audio}- and {Web}-based {Strategies}},
	isbn = {978-3-662-49720-3},
	shorttitle = {Music {Similarity} and {Retrieval}},
	url = {https://www.springer.com/gp/book/9783662497203},
	abstract = {This book provides a summary of the manifold audio- and web-based approaches to music information retrieval (MIR) research. In contrast to other books dealing solely with music signal processing, it addresses additional cultural and listener-centric aspects and thus provides a more holistic view. Consequently, the text includes methods operating on features extracted directly from the audio signal, as well as methods operating on features extracted from contextual information, either the cultural context of music as represented on the web or the user and usage context of music. Following the prevalent document-centered paradigm of information retrieval, the book addresses models of music similarity that extract computational features to describe an entity that represents music on any level (e.g., song, album, or artist), and methods to calculate the similarity between them. While this perspective and the representations discussed cannot describe all musical dimensions, they enable us to effectively find music of similar qualities by providing abstract summarizations of musical artifacts from different modalities. The text at hand provides a comprehensive and accessible introduction to the topics of music search, retrieval, and recommendation from an academic perspective. It will not only allow those new to the field to quickly access MIR from an information retrieval point of view but also raise awareness for the developments of the music domain within the greater IR community. In this regard, Part I deals with content-based MIR, in particular the extraction of features from the music signal and similarity calculation for content-based retrieval. Part II subsequently addresses MIR methods that make use of the digitally accessible cultural context of music. Part III addresses methods of collaborative filtering and user-aware and multi-modal retrieval, while Part IV explores current and future applications of music retrieval and recommendation.{\textgreater}},
	language = {en},
	urldate = {2020-05-28},
	publisher = {Springer-Verlag},
	author = {Knees, Peter and Schedl, Markus},
	year = {2016},
	doi = {10.1007/978-3-662-49722-7}
}

@article{schneider_haptic_2017,
	series = {Multisensory {Human}-{Computer} {Interaction}},
	title = {Haptic experience design: {What} hapticians do and where they need help},
	volume = {107},
	issn = {1071-5819},
	shorttitle = {Haptic experience design},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581917300605},
	doi = {10.1016/j.ijhcs.2017.04.004},
	abstract = {From simple vibrations to roles in complex multisensory systems, haptic technology is often a critical, expected component of user experience – one face of the rapid progression towards blended physical-digital interfaces. Haptic experience design, which is woven together with other multisensory design efforts, interfaces is now becoming part of many designers' jobs. We can expect it to present unique challenges, and yet we know almost nothing of what it looks like “in the wild” due to the field's relative youth, its technical complexity, the multisensory interactions between haptics, sight, and sound, and the difficulty of accessing practitioners in professional and proprietary environments. In this paper, we analyze interviews with six professional haptic designers to document and articulate haptic experience design by observing designers' goals and processes and finding themes at three levels of scope: the multisensory nature of haptic experiences, a map of the collaborative ecosystem, and the cultural context of haptics. Our findings are augmented by feedback obtained in a recent design workshop at an international haptics conference. We find that haptic designers follow a familiar design process, but face specific challenges when working with haptics. We capture and summarize these challenges, make concrete recommendations to conquer them, and present a vision for the future of haptic experience design.},
	language = {en},
	urldate = {2020-05-28},
	journal = {International Journal of Human-Computer Studies},
	author = {Schneider, Oliver and MacLean, Karon and Swindells, Colin and Booth, Kellogg},
	month = nov,
	year = {2017},
	keywords = {Design, Grounded theory, Haptics, Interview, User experience},
	pages = {5--21}
}

@article{seifi_how_2020,
	title = {How {Do} {Novice} {Hapticians} {Design}? {A} {Case} {Study} in {Creating} {Haptic} {Learning} {Environments}},
	issn = {2329-4051},
	shorttitle = {How {Do} {Novice} {Hapticians} {Design}?},
	doi = {10.1109/TOH.2020.2968903},
	abstract = {Access to haptic technology is on the rise, in smartphones, virtual reality gear, and open-source education kits. However, engineers and interaction designers are often inexperienced in designing with haptics, and rarely have tools and guidelines for creating multisensory experiences. To examine the impact of this deficit, we supplied a haptic design kit, custom software, and technical support to 9 teams (25 students) for an innovation challenge at a major haptics conference. Teams (predominantly undergraduate engineers with little haptics, interaction design, or education training) designed and built haptic environments to support learning of science topics. Qualitative analysis of surveys, interviews, team blogs, and expert assessments of teams' final demonstrations exposed three themes in these design efforts. 1) Novice teams tended to ignore many of ten design choices that experts navigate, such as explicitly choosing whether haptic and graphic feedback should reinforce versus complement one other. 2) Their design activities differed in timing and inclusion from ten observed in expert process. 3) We identified three success strategies in how teams devised useful and engaging interactions and interpretable multimodal experiences, and communicated about their designs. We compare novice and expert design needs and highlight where future haptic design tools and theory need to support novice practice and training.},
	journal = {IEEE Transactions on Haptics},
	author = {Seifi, Hasti and Chun, Matthew and Gallacher, Colin and Schneider, Oliver Stirling and MacLean, Karon E.},
	year = {2020},
	keywords = {API, Design tools, Education, Guidelines, Haptic interfaces, Hardware, Software, Tools, education, haptic design, haptician, multisensory interaction, novice designer},
	pages = {1--1}
}

@incollection{schneider_feelcraft_2015,
	address = {Tokyo},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {{FeelCraft}: {User}-{Crafted} {Tactile} {Content}},
	isbn = {978-4-431-55690-9},
	shorttitle = {{FeelCraft}},
	url = {https://doi.org/10.1007/978-4-431-55690-9_47},
	abstract = {Despite ongoing research into delivering haptic content, users still have no accessible way to add haptics to their experiences. Lack of haptic media infrastructure, few libraries of haptic content, and individual differences all provide barriers to creating mainstream haptics . In this paper, we present an architecture that supports generation of haptic content, haptic content repositories, and customization of haptic experiences. We introduce FeelCraft, a software plugin that monitors activities in media and associates them with expressive tactile patterns known as feel effects. The FeelCraft plugin allows end users to quickly generate haptic effects, associate them to events in the media, play them back for testing, save them, share them, and/or broadcast them to other users to feel the same haptic experience. The FeelCraft architecture supports both existing and future media content, and can be applied to a wide range of social, educational, and assistive applications.},
	language = {en},
	urldate = {2020-05-28},
	booktitle = {Haptic {Interaction}: {Perception}, {Devices} and {Applications}},
	publisher = {Springer Japan},
	author = {Schneider, Oliver and Zhao, Siyan and Israr, Ali},
	editor = {Kajimoto, Hiroyuki and Ando, Hideyuki and Kyung, Ki-Uk},
	year = {2015},
	doi = {10.1007/978-4-431-55690-9_47},
	keywords = {Feel effect, Haptic authoring, Haptic broadcasting, Haptic media},
	pages = {253--259}
}

@inproceedings{maclean_designing_2000,
	title = {Designing with haptic feedback},
	volume = {1},
	doi = {10.1109/ROBOT.2000.844146},
	abstract = {Haptic feedback is a design element for human-computer interfaces, and this paper discusses when and how it can be used to best effect in interactive applications. It begins with consideration of the unique attributes of the touch sense in physiological and psychological terms, and the nature of information and control that touching provides. It reviews where active touching helps, by setting forth the forms it may take and important parameters that describe it; and evaluates the specific benefits it offers to contemporary interface problems. It ends with a proposal for a simple interaction model that emphasizes holistic design principles, and highlights issues that arise in the process of creating specific haptic interfaces.},
	booktitle = {Proceedings 2000 {ICRA}. {Millennium} {Conference}. {IEEE} {International} {Conference} on {Robotics} and {Automation}. {Symposia} {Proceedings} ({Cat}. {No}.{00CH37065})},
	author = {MacLean, K.E.},
	month = apr,
	year = {2000},
	note = {ISSN: 1050-4729},
	keywords = {Feedback, Glass, Haptic interfaces, Milling machines, Moisture, Probes, Proposals, Psychology, Spatial resolution, Temperature sensors, force feedback, haptic feedback, haptic interfaces, human factors, human-computer interfaces, interactive applications},
	pages = {783--788 vol.1}
}

@book{hudin_when_2020,
	title = {When {Hearing} {Defers} to {Touch}},
	abstract = {Hearing is often believed to be more sensitive than touch. This assertion is based on a comparison of sensitivities to weak stimuli. The respective stimuli, however, are not easily comparable since hearing is gauged using acoustic pressure and touch using skin displacement. We show that under reasonable assumptions the auditory and tactile detection thresholds can be reconciled on a level playing field. The results indicate that the capacity of touch and hearing to detect weak stimuli varies according to the size of a sensed object as well as to the frequency of its oscillations. In particular, touch is found to be more effective than hearing at detecting small and slow objects.},
	author = {Hudin, Charles and Vincent, Hayward},
	month = apr,
	year = {2020}
}

@incollection{jameson_adaptive_2002,
	address = {USA},
	title = {Adaptive interfaces and agents},
	isbn = {978-0-8058-3838-1},
	urldate = {2020-04-27},
	booktitle = {The human-computer interaction handbook: fundamentals, evolving technologies and emerging applications},
	publisher = {L. Erlbaum Associates Inc.},
	author = {Jameson, Anthony},
	month = jan,
	year = {2002},
	pages = {305--330}
}

@misc{erp_application_2006,
	title = {Application of tactile displays in sports : where to, how and when to move},
	shorttitle = {Application of tactile displays in sports},
	url = {http://resolver.tudelft.nl/uuid:cd182144-e724-4448-badb-40196714827d},
	abstract = {In this paper we explore the possibilities of tactile displays in sports applications, and report an experiment that shows that a tactile feedback systems improves rowing efficiency compared to traditional feedback systems. Earlier papers have shown that localized vibrations provide intuitive cues for orientation and navigation, i.e. where to move to, and motion initiation, i.e. how to move. In the first part of the paper we will give examples for the spin-off of these applications of tactile displays to the sports domain, including tactical guidance for soccer players (where) and body posture feedback for speed skaters and cyclists (how). In part two we report a study that extends the where and how examples with coordinated movement patterns. These systems also provide cues on when to move. In a laboratory experiment we showed that motion feedback with a localized and timed tactile cue resulted in better performance than the current methods of motion feedback.},
	language = {en},
	urldate = {2020-04-27},
	author = {Erp, J. B. F. van and Saturday, I. and Jansen, C. and {TNO Defensie en Veiligheid}},
	month = jan,
	year = {2006},
	keywords = {Health, motion feedback, motor behavior, sport, tactile, tactile displays, training feedback systems}
}

@article{casey_general_2001,
	title = {General sound classification and similarity in {MPEG}-7},
	volume = {6},
	issn = {1469-8153, 1355-7718},
	url = {https://www.cambridge.org/core/journals/organised-sound/article/general-sound-classification-and-similarity-in-mpeg7/CA36219C978B29099D73054F30C85EA7},
	doi = {10.1017/S1355771801002126},
	abstract = {We introduce a system for generalised sound classification and similarity using a machine-learning framework. Applications of the system include automatic classification of environmental sounds, musical instruments, music genre and human speakers. In addition to classification, the system may also be used for computing similarity metrics between a target sound and other sounds in a database. We discuss the use of hidden Markov models for representing the temporal evolution of audio spectra and present results of testing the system on classification and retrieval tasks. The system has been incorporated into the MPEG-7 international standard for multimedia content description and is therefore publicly available in the form of a set of standardised interfaces and software reference tools for developers and researchers.},
	language = {en},
	number = {2},
	urldate = {2020-04-24},
	journal = {Organised Sound},
	author = {Casey, Michael},
	month = aug,
	year = {2001},
	pages = {153--164}
}

@article{ijsselsteijn_presence_2003,
	title = {Presence in the past : what can we learn from media history?},
	shorttitle = {Presence in the past},
	url = {https://research.tue.nl/en/publications/presence-in-the-past-what-can-we-learn-from-media-history},
	language = {English},
	urldate = {2020-04-23},
	journal = {Being there : concepts, effects and measurements of user presence in synthetic environments},
	author = {IJsselsteijn, W. A.},
	year = {2003},
	pages = {17--40}
}

@inproceedings{obrist_talking_2013,
	address = {Paris, France},
	series = {{CHI} '13},
	title = {Talking about tactile experiences},
	isbn = {978-1-4503-1899-0},
	url = {https://doi.org/10.1145/2470654.2466220},
	doi = {10.1145/2470654.2466220},
	abstract = {A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants' verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a human-experiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Obrist, Marianna and Seah, Sue Ann and Subramanian, Sriram},
	month = apr,
	year = {2013},
	keywords = {explicitation interview technique, human hand, human-experiential vocabulary, mechanoreceptors, non-contact haptic system, tactile experiences, ultrasound, user study},
	pages = {1659--1668}
}

@misc{noauthor_talking_nodate,
	title = {Talking about tactile experiences {\textbar} {Proceedings} of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/2470654.2466220},
	urldate = {2020-04-23}
}

@misc{noauthor_uniting_2009,
	title = {Uniting the {Tribes} of {Fluency} to {Form} a {Metacognitive} {Nation} - {Adam} {L}. {Alter}, {Daniel} {M}. {Oppenheimer}, 2009},
	url = {https://journals.sagepub.com/doi/10.1177/1088868309341564},
	urldate = {2020-04-23},
	year = {2009}
}

@inproceedings{schneider_improvising_2014,
	address = {Houston, TX, USA},
	title = {Improvising design with a {Haptic} {Instrument}},
	isbn = {978-1-4799-3131-6},
	url = {http://ieeexplore.ieee.org/document/6775476/},
	doi = {10.1109/HAPTICS.2014.6775476},
	abstract = {As the need to deploy informative, expressive haptic phenomena in consumer devices gains momentum, the inadequacy of current design tools is becoming more critically obstructive. Current tools do not support collaboration or serendipitous exploration. Collaboration is critical, but direct means of sharing haptic sensations are limited, and the absence of unifying conceptual models for working with haptic sensations further restricts communication between designers and stakeholders. This is especially troublesome for pleasurable, affectively targeted interactions that rely on subjective user experience. In this paper, we introduce an alternative design approach inspired by musical instruments – a new tool for real-time, collaborative manipulation of haptic sensations; and describe a ﬁrst example, mHIVE, a mobile Haptic Instrument for Vibrotactile Exploration. Our qualitative study shows that mHIVE supports exploration and communication but requires additional visualization and recording capabilities for tweaking designs, and expands previous work on haptic language.},
	language = {en},
	urldate = {2020-04-23},
	booktitle = {2014 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	publisher = {IEEE},
	author = {Schneider, Oliver S. and MacLean, Karon E.},
	month = feb,
	year = {2014},
	pages = {327--332}
}

@inproceedings{levesque_exploring_2012,
	title = {Exploring the design space of programmable friction for scrolling interactions},
	doi = {10.1109/HAPTIC.2012.6183765},
	abstract = {Scrolling interactions are an important aspect of the design of usable touchscreen interfaces, particularly for handheld devices that can only display a limited amount of information at once. Using a touchscreen capable of dynamically altering its surface friction, we explore the design space of haptically-augmented scrolling interactions and investigate programmable friction's ability to provide appropriate feedback in envisioned usage scenarios. We performed five user experiments to evaluate respectively the identifiability of a set of iconic detents, the countability of detents, the perception of detent density, the synchronization of tactile feedback to on-screen events, and the optimal friction pattern for a spring-like resistance. The results of these experiments provide valuable information that will inform the design of scrolling interactions that leverage programmable friction for an improved user experience.},
	booktitle = {2012 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	author = {Lévesque, Vincent and Oram, Louise and MacLean, Karon},
	month = mar,
	year = {2012},
	note = {ISSN: 2324-7355},
	keywords = {Friction, H.5.2 [Information Interfaces and Presentation]: User Interfaces—Haptic I/O, Interaction styles, Haptic interfaces, Navigation, Resistance, Tactile sensors, Vibrations, Visualization, detent density, friction, haptic interfaces, haptically-augmented scrolling interactions, iconic detents, on-screen events, optimal friction pattern, programmable friction design space, spring-like resistance, surface friction, tactile feedback, touch sensitive screens, usable touchscreen interfaces},
	pages = {23--30}
}

@article{findlater_design_2009,
	title = {Design {Space} and {Evaluation} {Challenges} of {Adaptive} {Graphical} {User} {Interfaces}},
	volume = {30},
	copyright = {Copyright (c)},
	issn = {2371-9621},
	url = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/2268},
	doi = {10.1609/aimag.v30i4.2268},
	abstract = {Adaptive graphical user interfaces (GUIs) have the potential to improve performance and user satisfaction by automatically tailoring the presentation of functionality to each individual user. In practice, however, many challenges exist and evaluation results of adaptive GUIs have been mixed. To guide researchers and designers in developing effective adaptive GUIs, we outline a design space and discuss three important aspects to consider when conducting user evaluations of these types of interfaces: the control and reporting of adaptive algorithm characteristics, the impact of task choice and user characteristics on the overall effectiveness of a design, and evaluation measures that are appropriate for adaptive interaction.},
	language = {en},
	number = {4},
	urldate = {2020-04-23},
	journal = {AI Magazine},
	author = {Findlater, Leah and Gajos, Krzysztof Z.},
	month = sep,
	year = {2009},
	keywords = {intelligent user interfaces, user evaluation},
	pages = {68--68}
}

@article{mitchell_dynamic_1989,
	title = {Dynamic versus static menus: an exploratory comparison},
	volume = {20},
	issn = {0736-6906},
	shorttitle = {Dynamic versus static menus},
	url = {https://doi.org/10.1145/67243.67247},
	doi = {10.1145/67243.67247},
	abstract = {Sixty-three subjects completed 24 tasks using a menu driven computer program. The menu items appeared in a fixed (static) order during 12 of the tasks. During the other 12 tasks the menu item order changed dynamically such that the most frequently selected items always appeared at the top of the menu. All the subjects tried both dynamic and static menus.The subjects that used adaptive dynamic menus for the first set of tasks were significantly slower than those who used static menus on the first set of tasks. Subjects' performance during the second set of tasks was not affected by menu style. Eighty-one percent of the subjects preferred working with static menus to working with dynamic menus.},
	number = {4},
	urldate = {2020-04-23},
	journal = {ACM SIGCHI Bulletin},
	author = {Mitchell, J. and Shneiderman, B.},
	month = apr,
	year = {1989},
	pages = {33--37}
}

@inproceedings{findlater_comparison_2004,
	address = {Vienna, Austria},
	series = {{CHI} '04},
	title = {A comparison of static, adaptive, and adaptable menus},
	isbn = {978-1-58113-702-6},
	url = {https://doi.org/10.1145/985692.985704},
	doi = {10.1145/985692.985704},
	abstract = {Software applications continue to grow in terms of the number of features they offer, making personalization increasingly important. Research has shown that most users prefer the control afforded by an adaptable approach to personalization rather than a system-controlled adaptive approach. No study, however, has compared the efficiency of the two approaches. In a controlled lab study with 27 subjects we compared the measured and perceived efficiency of three menu conditions: static, adaptable and adaptive. Each was implemented as a split menu, in which the top four items remained static, were adaptable by the subject, or adapted according to the subject's frequently and recently used items. The static menu was found to be significantly faster than the adaptive menu, and the adaptable menu was found to be significantly faster than the adaptive menu under certain conditions. The majority of users preferred the adaptable menu overall. Implications for interface design are discussed.},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Findlater, Leah and McGrenere, Joanna},
	month = apr,
	year = {2004},
	keywords = {adaptable interfaces, adaptive interfaces, customization, interaction techniques, menu design, user study},
	pages = {89--96}
}

@misc{noauthor_jameson_nodate,
	title = {Jameson, {A}.: {Adaptive} interfaces and agents. {Hum}.-{Comput}. {Interact}.: {Des}. {Issues} {Solut}. {Appl}.105, 105–130 (2009) - {Recherche} {Google}},
	url = {https://www.google.com/search?client=ubuntu&channel=fs&q=Jameson%2C+A.%3A+Adaptive+interfaces+and+agents.+Hum.-Comput.+Interact.%3A+Des.+Issues+Solut.+Appl.105%2C+105%E2%80%93130+%282009%29&ie=utf-8&oe=utf-8},
	urldate = {2020-04-23}
}

@inproceedings{gajos_exploring_2006,
	address = {Venezia, Italy},
	series = {{AVI} '06},
	title = {Exploring the design space for adaptive graphical user interfaces},
	isbn = {978-1-59593-353-9},
	url = {https://doi.org/10.1145/1133265.1133306},
	doi = {10.1145/1133265.1133306},
	abstract = {For decades, researchers have presented different adaptive user interfaces and discussed the pros and cons of adaptation on task performance and satisfaction. Little research, however, has been directed at isolating and understanding those aspects of adaptive interfaces which make some of them successful and others not. We have designed and implemented three adaptive graphical interfaces and evaluated them in two experiments along with a non-adaptive baseline. In this paper we synthesize our results with previous work and discuss how different design choices and interactions affect the success of adaptive graphical user interfaces.},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the working conference on {Advanced} visual interfaces},
	publisher = {Association for Computing Machinery},
	author = {Gajos, Krzysztof Z. and Czerwinski, Mary and Tan, Desney S. and Weld, Daniel S.},
	month = may,
	year = {2006},
	keywords = {adaptive interfaces, user study},
	pages = {201--208}
}

@inproceedings{israr_exploring_2015,
	address = {Seoul, Republic of Korea},
	series = {{CHI} {EA} '15},
	title = {Exploring {Embedded} {Haptics} for {Social} {Networking} and {Interactions}},
	isbn = {978-1-4503-3146-3},
	url = {https://doi.org/10.1145/2702613.2732814},
	doi = {10.1145/2702613.2732814},
	abstract = {Haptic feedback is frequently used for user interactions with mobile devices, wearables, and handheld controllers in virtual reality and entertainment settings. We explore the use of vibrotactile (VT) feedback for social and interpersonal communication on embedded systems, particularly in a mobile context. We propose an architecture that supports compact packet communication between devices and triggers expressive VT patterns in a typical messenger application. We present a communication API, haptic vocabularies, and an interface for receiving and authoring haptic messages. Finally, we conclude with an informal survey for using haptics in a social setting.},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Israr, Ali and Zhao, Siyan and Schneider, Oliver},
	month = apr,
	year = {2015},
	keywords = {handheld devices, haptics, mobile interaction, social network},
	pages = {1899--1904}
}

@inproceedings{tam_design_2013,
	address = {Paris, France},
	series = {{CHI} '13},
	title = {The design and field observation of a haptic notification system for timing awareness during oral presentations},
	isbn = {978-1-4503-1899-0},
	url = {https://doi.org/10.1145/2470654.2466223},
	doi = {10.1145/2470654.2466223},
	abstract = {To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user's awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker 'internal' control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Tam, Diane and MacLean, Karon E. and McGrenere, Joanna and Kuchenbecker, Katherine J.},
	month = apr,
	year = {2013},
	keywords = {field study, oral presentation, vibrotactile, wearable haptics},
	pages = {1689--1698}
}

@book{seifi_personalizing_2019,
	title = {Personalizing {Haptics}: {From} {Individuals}' {Sense}-{Making} {Schemas} to {End}-{User} {Haptic} {Tools}},
	isbn = {978-3-030-11379-7},
	shorttitle = {Personalizing {Haptics}},
	abstract = {This monograph presents a vision for haptic personalization tools and lays the foundations for achieving it. Effective haptic personalization requires a suite of tools unified by one underlying conceptual model that can easily be incorporated into users’ workflows with various applications. Toward this vision, the book introduces three mechanisms for haptic personalization and details development of two of them into: 1) an efficient interface for choosing from a large haptic library, and 2) three emotion controls for adjusting haptic signals. A series of quantitative experiments identifies five schemas (engineering, sensation, emotion, metaphor, and usage examples) for how end-users think and talk about haptic sensations and characterizes them as the underlying model for the personalization tools.  Personalizing Haptics highlights the need for scalable haptic evaluation methodologies and presents two methodologies for large-scale in-lab evaluation and online crowdsourcing of haptics. While the work focuses on vibrotactile signals as the most mature and accessible type of haptic feedback for end-users, the concepts and findings extend to other categories of haptics. Taking haptics to the crowds will require haptic design practices to go beyond the current one-size-fits-all approach to satisfy users’ diverse perceptual, functional, and hedonic needs reported in the literature. This book provides a starting point for students, researchers, and practitioners in academia or industry who aim to adapt their haptic and multisensory designs to the needs and preferences of a wide audience.},
	language = {en},
	publisher = {Springer},
	author = {Seifi, Hasti},
	month = jun,
	year = {2019},
	keywords = {Computers / Operating Systems / General, Computers / User Interfaces, Technology \& Engineering / Robotics}
}

@misc{noauthor_immersion_nodate,
	title = {Immersion {Releases} {Haptic} {Muse} {Effect} {Preview} {App} for {Android} {Game} {Developers}},
	url = {https://ir.immersion.com/news-releases/news-release-details/immersion-releases-haptic-muse-effect-preview-app-android-game},
	abstract = {The Investor Relations website contains information about Immersion Corporation's business for stockholders, potential investors, and financial analysts.},
	language = {en},
	urldate = {2020-04-23},
	journal = {Immersion Corporation}
}

@article{ng_vibro-monitor_2004,
	title = {Vibro-{Monitor}: {A} {Vibrotactile} display for {Physiological} {Data} {Monitoring}},
	abstract = {Vibro-Monitor is a new wearable vibrotactile display used to present physiological data to an anesthesiologist during a medical operation. In the current physiological data monitoring system, visual and sound cues are used to display a patient's information to clinicians. However, such system distracts clinicians from monitoring patients and cannot be used in an operating room environment that is constantly polluted by other noises.},
	language = {en},
	author = {Ng, Jessie Ying Chi and Man, Jo Chun Fai},
	year = {2004},
	pages = {8}
}

@article{alirezaee_did_2017,
	title = {Did {You} {Feel} {That}? {Developing} {Novel} {Multimodal} {Alarms} for {High} {Consequence} {Clinical} {Environments}},
	copyright = {This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.},
	shorttitle = {Did {You} {Feel} {That}?},
	url = {https://smartech.gatech.edu/handle/1853/58377},
	doi = {https://doi.org/10.21785/icad2017.066},
	abstract = {Hospitals are overwhelmingly filled with sounds produced by 
alarms and patient monitoring devices. Consequently, these 
sounds create a fatiguing and stressful environment for both patients 
and clinicians. As an attempt to attenuate the auditory sensory 
overload, we propose the use of a multimodal alarm system in 
operating rooms and intensive care units. Specifically, the system 
would utilize multisensory integration of the haptic and auditory 
channels. We hypothesize that combining these two channels in a 
synchronized fashion, the auditory threshold of perception of participants 
will be lowered, thus allowing for an overall reduction of 
volume in hospitals. The results obtained from pilot testing support 
this hypothesis. We conclude that further investigation of this 
method can prove useful in reducing the sound exposure level in 
hospitals as well as personalizing the perception and type of the 
alarm for clinicians.},
	language = {en},
	urldate = {2020-04-23},
	author = {Alirezaee, Parisa and Girgis, Roger and Kim, TaeYong and Schlesinger, Joseph J. and Cooperstock, Jeremy R.},
	month = jun,
	year = {2017}
}

@inproceedings{blum_improving_2015,
	address = {Charlotte, NC, USA},
	series = {{UIST} '15},
	title = {Improving {Haptic} {Feedback} on {Wearable} {Devices} through {Accelerometer} {Measurements}},
	isbn = {978-1-4503-3779-3},
	url = {https://doi.org/10.1145/2807442.2807474},
	doi = {10.1145/2807442.2807474},
	abstract = {Many variables have been shown to impact whether a vibration stimulus will be perceived. We present a user study that takes into account not only previously investigated predictors such as vibration intensity and duration along with the age of the person receiving the stimulus, but also the amount of motion, as measured by an accelerometer, at the site of vibration immediately preceding the stimulus. This is a more specific measure than in previous studies showing an effect on perception due to gross conditions such as walking. We show that a logistic regression model including prior acceleration is significantly better at predicting vibration perception than a model including only vibration intensity, duration and participant age. In addition to the overall regression, we discuss individual participant differences and measures of classification performance for real-world applications. Our expectation is that haptic interface designers will be able to use such results to design better vibrations that are perceivable under the user's current activity conditions, without being annoyingly loud or jarring, eventually approaching ``perceptually equivalent' feedback independent of motion.},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the 28th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} \& {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Blum, Jeffrey R. and Frissen, Ilja and Cooperstock, Jeremy R.},
	month = nov,
	year = {2015},
	keywords = {accelerometer, haptic vibration feedback, mobile sensing, wearable computing},
	pages = {31--36}
}
@article{erp_waypoint_2005,
	title = {Waypoint navigation with a vibrotactile waist belt},
	volume = {2},
	issn = {1544-3558},
	url = {https://doi.org/10.1145/1060581.1060585},
	doi = {10.1145/1060581.1060585},
	abstract = {Presenting waypoint navigation on a visual display is not suited for all situations. The present experiments investigate if it is feasible to present the navigation information on a tactile display. Important design issue of the display is how direction and distance information must be coded. Important usability issues are the resolution of the display and its usefulness in vibrating environments. In a pilot study with 12 pedestrians, different distance-coding schemes were compared. The schemes translated distance to vibration rhythm while the direction was translated into vibration location. The display consisted of eight tactors around the user's waist. The results show that mapping waypoint direction on the location of vibration is an effective coding scheme that requires no training, but that coding for distance does not improve performance compared to a control condition with no distance information. In Experiment 2, the usefulness of the tactile display was shown in two case studies with a helicopter and a fast boat.},
	number = {2},
	urldate = {2020-04-23},
	journal = {ACM Transactions on Applied Perception},
	author = {Erp, Jan B. F. Van and Veen, Hendrik A. H. C. Van and Jansen, Chris and Dobbins, Trevor},
	month = apr,
	year = {2005},
	keywords = {Vehicle control, navigation, vibrotactile displays, visually handicapped},
	pages = {106--117}
}

@article{hwang_perceptual_2010,
	title = {Perceptual space and adjective rating of sinusoidal vibrations perceived via mobile device},
	doi = {10.1109/HAPTIC.2010.5444692},
	abstract = {In the past five years, how to utilize the haptics technology in the mobile device to improve its limited user interface has emerged as an attractive research topic. In this paper, we report two kinds of perceptual data related to vibrotactile signals perceived through a mobile device held in the hand. In Experiment I, we estimated perceptual dissimilarities between sinusoidal vibrations with seven frequencies in 40–250 Hz and two amplitudes of 30 and 40 dB SL. Multi-dimensional scaling was then applied to the perceptual distances, and led to a two-dimensional perceptual space. In the perceptual space, the vibrations of the two amplitudes formed distinct groups. The two groups showed similar structures with respect to the frequency variation. In particular, two perceptual dimensions that spanned a low frequency range (40–100 Hz) and a high frequency range (100–250 Hz) were close to be orthogonal. In Experiment II, we evaluated the subjective qualities of sinusoidal vibrations with different frequencies via adjective rating. Thirteen adjective pairs were carefully selected, and rated for the sinusoidal vibrations played through the mobile device. The results were regressed to the perceptual space, revealing several adjective pairs that can largely account for the distributions of vibration points in the perceptual space, such as ‘dark-bright,’ ‘dull-clear,’ ‘slow-fast,’ ‘vague-distinct,’ ‘thick-thin,’ and ‘heavy-light.’ The findings of this paper can help understand the perceptual characteristics and subjective impressions of mobile device vibrations.},
	journal = {2010 IEEE Haptics Symposium, HAPTICS 2010},
	author = {Hwang, Inwook and Choi, Seungmoon},
	month = mar,
	year = {2010}
}

@inproceedings{pasquero_perceptual_2006,
	address = {Alexandria, VA, USA},
	title = {Perceptual {Analysis} of {Haptic} {Icons}: an {Investigation} into the {Validity} of {Cluster} {Sorted} {MDS}},
	isbn = {978-1-4244-0226-7},
	shorttitle = {Perceptual {Analysis} of {Haptic} {Icons}},
	url = {http://ieeexplore.ieee.org/document/1627122/},
	doi = {10.1109/HAPTIC.2006.1627122},
	abstract = {The design of usable haptic icons (brief informational signals delivered through the sense of touch) requires a tool for measuring perceptual distances between icons that will be used together as a set. Our experiences with one potentially powerful approach, Multidimensional Scaling (MDS) analysis of perceptual data acquired using an efﬁcient cluster sorting technique, raised questions relating to the methodology for data collection. In this paper, we review key issues relating to perceptual data collection method, describe an example data set and present its initial MDS analysis, and then examine the impact of collection method on MDS outcome through a secondary analysis of the data and the inherent structure of the algorithm components. Our analysis suggests that an understanding of these issues is important for the method’s effective use, but has not exposed any major ﬂaws with the process.},
	language = {en},
	urldate = {2020-04-23},
	booktitle = {2006 14th {Symposium} on {Haptic} {Interfaces} for {Virtual} {Environment} and {Teleoperator} {Systems}},
	publisher = {IEEE},
	author = {Pasquero, J. and Luk, J. and Little, S. and MacLean, K.},
	year = {2006},
	pages = {437--444}
}

@misc{noauthor_how_2011,
	title = {How to {Use} {Custom} {Vibrations} in {iOS} 5},
	url = {https://www.pcworld.com/article/242238/how_to_use_custom_vibrations_in_ios_5.html},
	abstract = {Custom vibrations are among the best-kept secrets of iOS 5. Here's how to customize the vibration pattern of your iPhone 4 or iPhone 4S.},
	language = {en},
	urldate = {2020-04-18},
	journal = {PCWorld},
	month = oct,
	year = {2011}
}

@book{seifi_personalizing_2019,
	address = {Cham},
	series = {Springer {Series} on {Touch} and {Haptic} {Systems}},
	title = {Personalizing {Haptics}: {From} {Individuals}' {Sense}-{Making} {Schemas} to {End}-{User} {Haptic} {Tools}},
	isbn = {978-3-030-11378-0 978-3-030-11379-7},
	shorttitle = {Personalizing {Haptics}},
	url = {http://link.springer.com/10.1007/978-3-030-11379-7},
	language = {en},
	urldate = {2020-04-18},
	publisher = {Springer International Publishing},
	author = {Seifi, Hasti},
	year = {2019},
	doi = {10.1007/978-3-030-11379-7}
}

@inproceedings{kim_defining_2020,
	title = {Defining {Haptic} {Experience}: {Foundations} for {Understanding}, {Communicating}, and {Evaluating} {HX}},
	shorttitle = {Defining {Haptic} {Experience}},
	url = {https://uwspace.uwaterloo.ca/handle/10012/15721},
	doi = {https://doi.org/10.1145/3313831.3376280},
	abstract = {Haptic technology is maturing, with expectations and evidence that it will contribute to user experience (UX). However, we have very little understanding about how haptic technology can influence people’s experience. Researchers and designers need a way to understand, communicate, and evaluate haptic technology’s effect on UX. From a literature review and two studies – one with haptics novices, the other with expert hapticians – we developed a theoretical model of the factors that constitute a good haptic experience (HX). We define HX and propose its constituent factors: design parameters of Timeliness, Density, Intensity, and Timbre; the cross-cutting concern of Personalization; usability requirements of Utility, Causality, Consistency, and Saliency; and experiential factors of Harmony, Expressivity, Autotelics, Immersion, and Realism as guiding constructs important for haptic experience. This model will help guide design and research of haptic systems, inform language around haptics, and provide the basis for evaluative instruments, such as checklists, heuristics, or questionnaires.},
	language = {en},
	urldate = {2020-04-17},
	publisher = {ACM},
	author = {Kim, Erin and Schneider, Oliver},
	month = apr,
	year = {2020}
}

@book{hultman_simple_2019,
	title = {Simple {Affective} {Hapticons} using {Web} {Technologies}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-271588},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 49 universities and research institutions.},
	language = {eng},
	urldate = {2020-04-16},
	author = {Hultman, Axel},
	year = {2019}
}

@inproceedings{pasquero_perceptual_2006-1,
	title = {Perceptual {Analysis} of {Haptic} {Icons}: an {Investigation} into the {Validity} of {Cluster} {Sorted} {MDS}},
	shorttitle = {Perceptual {Analysis} of {Haptic} {Icons}},
	doi = {10.1109/HAPTIC.2006.1627122},
	abstract = {The design of usable haptic icons (brief informational signals delivered through the sense of touch) requires a tool for measuring perceptual distances between icons that will be used together as a set. Our experiences with one potentially powerful approach, Multidimensional Scaling (MDS) analysis of perceptual data acquired using an efficient cluster sorting technique, raised questions relating to the methodology for data collection. In this paper, we review key issues relating to perceptual data collection method, describe an example data set and present its initial MDS analysis, and then examine the impact of collection method on MDS outcome through a secondary analysis of the data and the inherent structure of the algorithm components. Our analysis suggests that an understanding of these issues is important for the method’s effective use, but has not exposed any major flaws with the process.},
	booktitle = {2006 14th {Symposium} on {Haptic} {Interfaces} for {Virtual} {Environment} and {Teleoperator} {Systems}},
	author = {Pasquero, J. and Luk, J. and Little, S. and MacLean, K.},
	month = mar,
	year = {2006},
	note = {ISSN: 2324-7355},
	keywords = {Actuators, Algorithm design and analysis, Data analysis, Displays, Frequency, Haptic interfaces, Information analysis, Machine intelligence, Multidimensional systems, State feedback, handheld device, haptic icons, multidimensional scaling, tactile display, tactile feedback, tactile perception},
	pages = {437--444}
}

@inproceedings{mun_perceptual_2019,
	title = {Perceptual {Space} of {Regular} {Homogeneous} {Haptic} {Textures} {Rendered} {Using} {Electrovibration}},
	doi = {10.1109/WHC.2019.8816143},
	abstract = {This paper is concerned with the perceptual structure of homogeneous and deterministic haptic textures rendered by an electrovibration display. Textures were modeled using 32 regular tessellations of polygons by changing the polygon, density, edge width, pixel intensity, and image reversal. We conducted a perceptual experiment to estimate the pairwise dissimilarities between the 32 textures using the cluster sorting procedure. We then applied multi-dimensional scaling to the data and obtained a perceptual space that accounted for the effects of the five design variables on texture perception. The subjective impressions of the textures were also rated against eight adjective pairs. We projected the rating results into the perceptual space to find adequate perceptual dimensions for the texture perception. Our results contribute to designing perceptually distinctive textures elicited by electrovibration with an appropriate understanding of their subjective qualities.},
	booktitle = {2019 {IEEE} {World} {Haptics} {Conference} ({WHC})},
	author = {Mun, Sunung and Lee, Hojin and Choi, Seungmoon},
	month = jul,
	year = {2019},
	keywords = {Bars, Force, Haptic interfaces, Image edge detection, Rendering (computer graphics), Sorting, Three-dimensional displays, cluster sorting, computational geometry, deterministic haptic texture rendering, edge width, electrovibration display, haptic interfaces, homogeneous haptic textures, image reversal, image texture, multidimensional data scaling, perceptual dimensions, perceptually distinctive textures, pixel intensity, polygon tessellations, rendering (computer graphics), sorting, texture perception},
	pages = {7--12}
}

@inproceedings{inwook_hwang_perceptual_2010,
	title = {Perceptual space and adjective rating of sinusoidal vibrations perceived via mobile device},
	doi = {10.1109/HAPTIC.2010.5444692},
	abstract = {In the past five years, how to utilize the haptics technology in the mobile device to improve its limited user interface has emerged as an attractive research topic. In this paper, we report two kinds of perceptual data related to vibrotactile signals perceived through a mobile device held in the hand. In Experiment I, we estimated perceptual dissimilarities between sinusoidal vibrations with seven frequencies in 40–250 Hz and two amplitudes of 30 and 40 dB SL. Multi-dimensional scaling was then applied to the perceptual distances, and led to a two-dimensional perceptual space. In the perceptual space, the vibrations of the two amplitudes formed distinct groups. The two groups showed similar structures with respect to the frequency variation. In particular, two perceptual dimensions that spanned a low frequency range (40–100 Hz) and a high frequency range (100–250 Hz) were close to be orthogonal. In Experiment II, we evaluated the subjective qualities of sinusoidal vibrations with different frequencies via adjective rating. Thirteen adjective pairs were carefully selected, and rated for the sinusoidal vibrations played through the mobile device. The results were regressed to the perceptual space, revealing several adjective pairs that can largely account for the distributions of vibration points in the perceptual space, such as ‘dark-bright,’ ‘dull-clear,’ ‘slow-fast,’ ‘vague-distinct,’ ‘thick-thin,’ and ‘heavy-light.’ The findings of this paper can help understand the perceptual characteristics and subjective impressions of mobile device vibrations.},
	booktitle = {2010 {IEEE} {Haptics} {Symposium}},
	author = {Inwook Hwang and Choi, Seungmoon},
	month = mar,
	year = {2010},
	note = {ISSN: 2324-7355},
	keywords = {Computer Society, Educational programs, Engineering profession, H.1.2 [Models and Principles]: User/Machines Systems—Human Information Processing, H.5.2 [Information Interfaces and Presentation]: User Interfaces—Haptic I/O, Haptic interfaces, IEEE news, Joining IEEE, Neuroscience, Robotics and Automation Society, Scheduling, USA Councils},
	pages = {1--8}
}

@inproceedings{park_perceptual_2011,
	title = {Perceptual space of amplitude-modulated vibrotactile stimuli},
	doi = {10.1109/WHC.2011.5945462},
	abstract = {Amplitude-modulated vibrotactile stimuli have been broadly used for tactile perception and rendering research. However, understandings of the perceptual relations between amplitude-modulated vibrations are not comprehensive yet. In this paper, we present a perceptual analysis on the identifying characteristics of amplitude-modulated vibrations and their perceptual relations. We estimated the perceptual dissimilarities among one carrier and seven amplitude-modulated sinusoidal vibrations (150-Hz carrier frequency; seven modulation frequencies in 1-80 Hz) in a psychophysical experiment. The dissimilarity scores were inspected using multi-dimensional scaling to obtain an appropriate perceptual space. The optimal perceptual space was two-dimensional, where the vibration points exhibited a circular formation. The analysis showed that the pulse-like low-frequency sensation of an amplitude-modulated vibration increased for very low modulation frequencies (1-10 Hz), then decreased for higher modulation frequencies (10-80 Hz), and eventually converged to the smooth vibrational sensation of the 150-Hz carrier signal. It also suggested that the envelope waveform is primary information for the discrimination of amplitude-modulated signals, instead of their spectral energy distributions. These findings can contribute to the design of perceptually salient and distinctive vibrotactile signals using amplitude modulation.},
	booktitle = {2011 {IEEE} {World} {Haptics} {Conference}},
	author = {Park, Gunhyuk and Choi, Seungmoon},
	month = jun,
	year = {2011},
	keywords = {Actuators, Amplitude modulation, Frequency modulation, H.1.2 [Models and Principles]: User/Machines Systems—Human Information Processing, H.5.2 [Information Interfaces and Presentation]: User Interfaces—Haptic I/O, Resonant frequency, Time frequency analysis, Vibrations, amplitude modulated vibrotactile stimuli, amplitude modulation, bioelectric phenomena, frequency 150 Hz, frequency modulation, haptic interfaces, neurophysiology, perceptual analysis, perceptual space, psychology, psychophysical esperiment, rendering, rendering (computer graphics), tactile perception, vibrations, vibrotactile signals},
	pages = {59--64}
}

@article{hwang_perceptual_2017,
	title = {Perceptual {Space} of {Superimposed} {Dual}-{Frequency} {Vibrations} in the {Hands}},
	volume = {12},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169570},
	doi = {10.1371/journal.pone.0169570},
	abstract = {The use of distinguishable complex vibrations that have multiple spectral components can improve the transfer of information by vibrotactile interfaces. We investigated the qualitative characteristics of dual-frequency vibrations as the simplest complex vibrations compared to single-frequency vibrations. Two psychophysical experiments were conducted to elucidate the perceptual characteristics of these vibrations by measuring the perceptual distances among single-frequency and dual-frequency vibrations. The perceptual distances of dual-frequency vibrations between their two frequency components along their relative intensity ratio were measured in Experiment I. The estimated perceptual spaces for three frequency conditions showed non-linear perceptual differences between the dual-frequency and single-frequency vibrations. A perceptual space was estimated from the measured perceptual distances among ten dual-frequency compositions and five single-frequency vibrations in Experiment II. The effect of the component frequency and the frequency ratio was revealed in the perceptual space. In a percept of dual-frequency vibration, the lower frequency component showed a dominant effect. Additionally, the perceptual difference among single-frequency and dual-frequency vibrations were increased with a low relative difference between two frequencies of a dual-frequency vibration. These results are expected to provide a fundamental understanding about the perception of complex vibrations to enrich the transfer of information using vibrotactile stimuli.},
	language = {en},
	number = {1},
	urldate = {2020-04-15},
	journal = {PLOS ONE},
	author = {Hwang, Inwook and Seo, Jeongil and Choi, Seungmoon},
	month = jan,
	year = {2017},
	keywords = {Actuators, Distance measurement, Perception, Psychophysics, Sensory perception, Tactile sensation, Vibration, Vibration engineering},
	pages = {e0169570}
}

@inproceedings{hou_deep_2017,
	address = {Anchorage, AK, USA},
	title = {Deep learning approach to link weight prediction},
	isbn = {978-1-5090-6182-2},
	url = {http://ieeexplore.ieee.org/document/7966076/},
	doi = {10.1109/IJCNN.2017.7966076},
	abstract = {Deep learning has been successful in various domains including image recognition, speech recognition and natural language processing. However, the research on its application in graph mining is still in an early stage. Here we present Model R, a neural network model created to provide a deep learning approach to link weight prediction problem. This model extracts knowledge of nodes from known links’ weights and uses this knowledge to predict unknown links’ weights. We demonstrate the power of Model R through experiments and compare it with stochastic block model and its derivatives. Model R shows that deep learning can be successfully applied to link weight prediction and it outperforms stochastic block model and its derivatives by up to 73\% in terms of prediction accuracy. We anticipate this new approach to provide effective solutions to more graph mining tasks.},
	language = {en},
	urldate = {2020-03-26},
	booktitle = {2017 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Hou, Yuchen and Holder, Lawrence B.},
	month = may,
	year = {2017},
	pages = {1855--1862}
}

@article{patel_handbook_2013,
	title = {The {Handbook} of {Touch}: {Neuroscience}, {Behavioral}, and {Health} {Perspectives}},
	volume = {92},
	issn = {0894-9115},
	shorttitle = {The {Handbook} of {Touch}},
	url = {https://journals.lww.com/ajpmr/Citation/2013/10000/The_Handbook_of_Touch__Neuroscience,_Behavioral,.14.aspx},
	doi = {10.1097/PHM.0b013e31829e78ed},
	abstract = {An abstract is unavailable.},
	language = {en-US},
	number = {10},
	urldate = {2020-03-23},
	journal = {American Journal of Physical Medicine \& Rehabilitation},
	author = {Patel, Atul T.},
	month = oct,
	year = {2013},
	pages = {945}
}

@book{bullough_handbook_2011,
	title = {The {Handbook} of {Touch}: {Neuroscience}, {Behavioral}, and {Health} {Perspectives}},
	isbn = {978-0-8261-2191-2},
	shorttitle = {The {Handbook} of {Touch}},
	abstract = {This book is excellent in its coverage of neurobiological underpinnings through perception, measurement, and communication...a great resource for researchers and clinicians." Score: 94, 4 stars. --Doody's Medical Reviews This is an expertly constructed volume, due mainly to an expert composition of authors for the individual chapters. Every chapter is like opening a door to a different laboratory, each examining a unique corner of the tactile research universe."--PsycCRITIQUES ...a solid, authoritative resource."--New Hampshire Nurses Association  Touch has received increased attention over the last few decades, with growing recognition of its profound import to all facets of life. The Handbook of Touch is the first authoritative, state-of-the-art resource for scientists, scholars, and students interested in the neurobehavioral foundations of touch and its many applications.  This text provides an in-depth overview of the conceptual and empirical scope of the field. Chapters are written by a cadre of internationally known experts on touch, representing an expansive breadth of knowledge from behavioral, health, and neuroscience disciplines. Key Features:    Integrates knowledge regarding the neurobiology of touch, covering the spectrum from skin physiology and somatosensory pathways to touch-related genes and proteins Synthesizes research about the neural processing and perception of touch Describes diverse methods for measuring touch behavior and human response to touch Discusses the role of touch in social communication, along with the influence of context and culture Presents cutting edge research that links touch to brain organization and plasticity, human development, and varied dimensions of health},
	language = {en},
	publisher = {Springer Publishing Company},
	author = {Bullough, Bonnie},
	month = jun,
	year = {2011},
	note = {Google-Books-ID: futOTes5spcC},
	keywords = {Medical / Reference, Psychology / Neuropsychology, Psychology / Physiological Psychology, Psychology / Social Psychology}
}

@article{san_diego_researching_2012,
	series = {{CAL} 2011},
	title = {Researching haptics in higher education: {The} complexity of developing haptics virtual learning systems and evaluating its impact on students’ learning},
	volume = {59},
	issn = {0360-1315},
	shorttitle = {Researching haptics in higher education},
	url = {http://www.sciencedirect.com/science/article/pii/S036013151100279X},
	doi = {10.1016/j.compedu.2011.11.009},
	abstract = {hapTEL, an interdisciplinary project funded by two UK research councils from 2007 to 2011, involves a large interdisciplinary team (with undergraduate and post-graduate student participants) which has been developing and evaluating a virtual learning system within an HE healthcare education setting, working on three overlapping strands. Strand 1 involves the technical development and evaluation of the hapTEL workstation which simulates clinical conditions for dental training including haptics (sense of touch). Strand 2 involves examining the traditional undergraduate curriculum and how this could benefit from the use of haptics. Strand 3 is concerned with the educational evaluation of the impact of the work carried out within Strands 1 and 2. Two theoretical frameworks (Entwistle, (1987) and Webb and Cox (2004)) have been used to identify as many factors as possible which could affect the impact of Technology Enhanced Learning (TEL) on the quality of the learning achieved. These frameworks have formed a foundation for measuring the impact of TEL on curriculum change, teachers’ pedagogical practices, students’ learning and on institutional practices. A range of quantitative and qualitative methods were designed, piloted and evaluated in order to measure the impact of TEL on teaching and learning; and to have a rich and robust data set which also addresses the variables in the frameworks. The results from using these frameworks show that institutional and departmental factors should be considered when evaluating the impact of TEL in higher education and that these had a major influence on the design and curriculum integration of the hapTEL systems. We have also shown that by involving the end users from the beginning enabled not only an enhancement of the students’ learning experiences but also a modification to the traditional curriculum itself and the successful integration of TEL within a very traditional undergraduate higher education dental curriculum. The conclusions from this paper confirm earlier reviews of researching TEL that technology integration is extremely complex and the related research requires a comprehensive approach of both quantitative and qualitative methods if one is to take account of the range of variables identified by theoretical frameworks. Finally, repeating the range of empirical investigations for a second year enables researchers to validate the effectiveness of the methods used in the initial year and thereby maximise the reliability and generalisability of the research outcomes.},
	language = {en},
	number = {1},
	urldate = {2020-02-29},
	journal = {Computers \& Education},
	author = {San Diego, Jonathan P. and Cox, Margaret J. and Quinn, Barry F. A. and Newton, Jonathan Tim and Banerjee, Avijit and Woolford, Mark},
	month = aug,
	year = {2012},
	keywords = {Evaluation methodologies, Interactive learning environments, Interdisciplinary projects, Pedagogical issues, Virtual reality},
	pages = {156--166}
}

@article{ferro_innovative_2019,
	title = {Innovative {Trends} in {Implant} {Dentistry} {Training} and {Education}: {A} {Narrative} {Review}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Innovative {Trends} in {Implant} {Dentistry} {Training} and {Education}},
	url = {https://www.mdpi.com/2077-0383/8/10/1618},
	doi = {10.3390/jcm8101618},
	abstract = {Background: The field of implant dentistry education is rapidly evolving as new technologies permit innovative methods to teach the fundamentals of implant dentistry. Methods: Literature from the fields of active learning, blended learning, augmented reality, artificial intelligence, haptics, and mixed reality were reviewed and combined with the experience and opinions of expert authors. Both positive and negative aspects of the learning methods are presented. Results and Conclusion: The fundamental objectives of teaching and learning remain unchanged, yet the opportunities to reach larger audiences and integrate their learning into active experiences are evolving due to the introduction of new teaching and learning methodologies. The ability to reach a global audience has never been more apparent. Nevertheless, as much as new technology can be alluring, each new method comes with unique limitations.},
	language = {en},
	number = {10},
	urldate = {2020-02-29},
	journal = {Journal of Clinical Medicine},
	author = {Ferro, Ana Santos and Nicholson, Ken and Koka, Sreenivas},
	month = oct,
	year = {2019},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {augmented reality, blended learning, haptics, implant dentistry education, mixed reality, online learning, virtual reality},
	pages = {1618}
}

@article{towers_scoping_2019,
	title = {A scoping review of the use and application of virtual reality in pre-clinical dental education},
	volume = {226},
	copyright = {2019 British Dental Association},
	issn = {1476-5373},
	url = {https://www.nature.com/articles/s41415-019-0041-0},
	doi = {10.1038/s41415-019-0041-0},
	abstract = {Introduction Virtual reality (VR) is gaining recognition as a valuable tool for training dental students and its use by dental schools around the world is growing. It is timely to review the literature relating to the use of VR in dental education, in order to ensure that educators are well-informed of current areas of inquiry, and those requiring further investigation, to enable appropriate decisions about whether to employ VR as a teaching tool. Method A scoping review using the method outlined by Arksey and O'Malley was conducted. Both Web of Science and ERIC databases were searched. Inclusion and exclusion criteria were established to filter results. The data were collected and categorised using a custom data collection spreadsheet. Results The review identified 68 relevant articles. Following review, four educational thematic areas relating to the 'simulation hardware', the 'realism of the simulation', 'scoring systems' and 'validation' of the systems emerged. Conclusion This paper summarises and draws out themes from the current areas of inquiry in the literature, uncovering a number of weaknesses and assumptions. It recommends areas where additional investigation is required in order to form a better evidence base for the utility of VR in dental education, as well as to inform its future development.},
	language = {en},
	number = {5},
	urldate = {2020-02-29},
	journal = {British Dental Journal},
	author = {Towers, Ashley and Field, James and Stokes, Christopher and Maddock, Stephen and Martin, Nicolas},
	month = mar,
	year = {2019},
	note = {Number: 5
Publisher: Nature Publishing Group},
	pages = {358--366}
}

@article{edwards_haptic_2019,
	title = {Haptic virtual reality and immersive learning for enhanced organic chemistry instruction},
	volume = {23},
	issn = {1434-9957},
	url = {https://doi.org/10.1007/s10055-018-0345-4},
	doi = {10.1007/s10055-018-0345-4},
	abstract = {Human–Computer interaction, including technology-aided instruction, is beginning to focus on virtual reality (VR) technology due to its ability to support immersive learning, teaching through simulation, and gamification of learning. These systems can deliver high-level multisensory learning experiences that are important in the teaching of many subjects, especially those involving abstract concepts or requiring spatial skills, such as organic chemistry. Haptic experiences with VR, however, remain a challenge. In addition, development has focused on general entertainment/gaming; VR systems in chemistry implement simulations of the chemistry laboratory and other advanced systems whereas those that support safe, game-like, immersive and multisensory learning of organic chemistry with haptics at pre-university education levels are scarce. We developed the VR Multisensory Classroom (VRMC) as an immersive learning environment within a VR head-mounted display, where learners employ hand movements to build hydrocarbon molecules and experience haptic feedback through gloves with built-in sensors and hand-tracking with the Leap Motion system. We report here the evaluation of the first prototype by learners from diverse backgrounds who reported on the ability of the VRMC to support high engagement, motivation, interest and organic chemistry learning as well as diverse learning styles. The VRMC is a novel VR classroom that supports immersive learning in molecular organic chemistry with haptics for multisensory learning.},
	language = {en},
	number = {4},
	urldate = {2020-02-29},
	journal = {Virtual Reality},
	author = {Edwards, Bosede Iyiade and Bielawski, Kevin S. and Prada, Rui and Cheok, Adrian David},
	month = dec,
	year = {2019},
	pages = {363--373}
}

@article{huang_pianotouch_2008,
	title = {{PianoTouch}: {A} wearable haptic piano instruction system for passive learning of piano skills},
	shorttitle = {{PianoTouch}},
	doi = {10.1109/ISWC.2008.4911582},
	abstract = {We present PianoTouch, a wearable, wireless haptic piano instruction system, composed of (1) five small vibration motors, one for each finger, fitted inside a glove, (2) a Bluetooth module mounted on the glove, and (3) piano music output from a laptop. Users hear the piano music and feel the vibrations indicating which finger is used to play the note. We investigate the system's potential for passive learning, i.e. learning piano playing automatically while engaged in everyday activities. In a preliminary study, four subjects learned two songs initially and then wore the PianoTouch glove for 30 minutes while listening to the songs repeated. One of the songs included tactile sensations and the other did not. The study found that after 30 minutes, the PianoTouch subjects were able to play the song accompanied by tactile sensations better than the non-tactile song. These results suggest the value of a more detailed study.},
	journal = {2008 12th IEEE International Symposium on Wearable Computers},
	author = {Huang, Kevin and Do, Ellen Yi-Luen and Starner, Thad},
	year = {2008}
}

@article{bowers_touching_2019,
	title = {Touching creativity; a review and early pilot test of haptic tooling to support design practice, within a distance learning curriculum},
	volume = {34},
	issn = {0268-0513},
	url = {https://doi.org/10.1080/02680513.2018.1545637},
	doi = {10.1080/02680513.2018.1545637},
	abstract = {Machine haptics has been shown to assist and enhance human–computer interactions. Research from previous studies in the field of haptics has focused on developing a user’s sense of realism of touch when using a haptic device. This paper examines the use of haptics for education, specifically for creative online education. The paper is presented in two parts. First, a review of literature was conducted and used to aid the rationale and underpin the design of a pilot test. Second, a pilot test was designed using a single-point kinaesthetic haptic device with a haptic rendered interface, to support the assembly of a virtual design prototype. The pilot test proved to be extremely valuable in creating and developing a rich virtual environment for non-sighted and sighted participants to use. The results from the initial pilot test showed that although users were positive about their experience of using the haptic device, there were improvements to be made to the interface to enhance the user experience in the next phase of testing.},
	number = {1},
	urldate = {2020-02-29},
	journal = {Open Learning: The Journal of Open, Distance and e-Learning},
	author = {Bowers, Lisa Jane},
	month = jan,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02680513.2018.1545637},
	keywords = {Augmented haptic tooling, design practice, distance learning, experiential practice, haptics in education},
	pages = {6--18}
}

@misc{castaneda_development_2020,
	type = {chapter},
	title = {On the {Development} of {Haptic}-{Virtual} {Learning} {Systems} for the {Education} of {Blind} {People}},
	copyright = {Access limited to members},
	url = {www.igi-global.com/chapter/on-the-development-of-haptic-virtual-learning-systems-for-the-education-of-blind-people/247883},
	abstract = {The concept of inclusive education goes beyond considering the needs of people with disabilities; it refers to the process of recognizing the students' learning needs and to act according to such needs. People with visual limitations do not necessarily require more attention and dedication than othe...},
	language = {en},
	urldate = {2020-02-29},
	journal = {UXD and UCD Approaches for Accessible Education},
	author = {Castañeda, Raquel Espinosa and Castillo, Hugo Ivan Medellín},
	year = {2020},
	doi = {10.4018/978-1-7998-2325-4.ch014},
	note = {ISBN: 9781799823254
Library Catalog: www.igi-global.com
Pages: 249-273
Publisher: IGI Global}
}

@inproceedings{brandt_toys_2008,
	title = {Toys in the {Classroom}: {LEGO} {MindStorms} as an {Educational} {Haptics} {Platform}},
	shorttitle = {Toys in the {Classroom}},
	doi = {10.1109/HAPTICS.2008.4479982},
	abstract = {Haptics has the potential to be: a powerful tool in science and engineering education of college and pre-college students. This paper proposes teaching engineering and programming concepts using haptic interfaces created with LEGO MindStorms, a popular system for developing robotic devices. A general overview of the MindStorms system is presented, followed by the results of experiments that characterize the performance of the MindStorms components and establish the suitability of MindStorms for constructing haptic interfaces. Two prototype haptic interfaces are created and interfaced with a PC-based graphics display. Initial results show that MindStorms provides an excellent platform for designing, constructing, programming, and interfacing simple haptic devices,. Potential uses in college and pre-college curricula are discussed.},
	booktitle = {2008 {Symposium} on {Haptic} {Interfaces} for {Virtual} {Environment} and {Teleoperator} {Systems}},
	author = {Brandt, Adam M. and Colton, Mark B.},
	month = mar,
	year = {2008},
	note = {ISSN: 2324-7355},
	keywords = {Displays, Educational institutions, Educational robots, Engineering education, Graphics, Haptic interfaces, LEGO mindstorm, PC-based graphics display, Power engineering and energy, Programming profession, Prototypes, Robot programming, computer aided instruction, computer displays, computer science education, educational haptics platform, engineering education, haptic interface, haptic interfaces, robotic device, robots},
	pages = {389--395}
}

@article{rangarajan_systematic_2020,
	title = {Systematic {Review} of {Virtual} {Haptics} in {Surgical} {Simulation}: {A} {Valid} {Educational} {Tool}?},
	volume = {77},
	issn = {1931-7204},
	shorttitle = {Systematic {Review} of {Virtual} {Haptics} in {Surgical} {Simulation}},
	url = {http://www.sciencedirect.com/science/article/pii/S1931720419306609},
	doi = {10.1016/j.jsurg.2019.09.006},
	abstract = {BACKGROUND
Virtual reality (VR)-based surgical simulation is an expanding and rapidly advancing modality which aims to serve the increasing demand to acquire surgical skills outside the live operating room. Haptic, or “force-feedback" technology in VR simulation is a rapidly developing field, however the role of haptics in surgical education and its efficacy is unclear.
METHODS
A systematic literature search was carried out until September 2018 in MEDLINE, Embase, and Cochrane Library using the following keywords: (VR OR VR OR simulation OR simulator) AND (Haptic feedback OR Haptics OR Force feedback) AND (Surgery). All randomized controlled studies comparing VR training with and without haptics were included. PRISMA guidelines were adhered to
RESULTS
Eight randomized controlled trials that compare VR training with and without haptics were included and 1 survey study with a total of 215 participants, 116 of which received haptic feedback and 99 were assigned to nonhaptic feedback group. Training tasks included basic proficiency based laparoscopic tasks such as object translocation, cutting, camera navigation, and more complex tasks including diathermy, suturing, dissection, knot tying, and operative maneuvers. Six randomized controlled trials demonstrated that haptic enhanced VR simulation is significantly more effective than without haptics for skill training with a reduced learning curve and faster time to proficiency and task completion, particularly in novice learners. Two studies showed no significant differences in task-assessed parameters between the haptics and nonhaptics cohorts, whereas 1 survey study suggested haptics negatively affected training with decreased realism.
CONCLUSION
Haptic feedback has been shown to improve the fidelity, realism and thus the training effect of VR simulators. However, at present haptic simulators are expensive and in a nascent stage and further research as well as cost-benefit analyses of such tools must be considered to determine whether haptics is truly a surgical necessity.},
	language = {en},
	number = {2},
	urldate = {2020-02-28},
	journal = {Journal of Surgical Education},
	author = {Rangarajan, Karan and Davis, Heather and Pucher, Philip H.},
	month = mar,
	year = {2020},
	keywords = {Force-feedback, Haptic-feedback, Laparoscopy, Medical Knowledge, Patient Care, Practice-Based Learning and Improvement, Simulation, Surgery, Training},
	pages = {337--347}
}

@article{reid_how_2019,
	title = {How {Haptics} and {Drawing} {Enhance} the {Learning} of {Anatomy}},
	volume = {12},
	copyright = {© 2018 American Association of Anatomists},
	issn = {1935-9780},
	url = {https://anatomypubs.onlinelibrary.wiley.com/doi/abs/10.1002/ase.1807},
	doi = {10.1002/ase.1807},
	abstract = {Students’ engagement with two-dimensional (2D) representations as opposed to three-dimensional (3D) representations of anatomy such as in dissection, is significant in terms of the depth of their comprehension. This qualitative study aimed to understand how students learned anatomy using observational and drawing activities that included touch, called haptics. Five volunteer second year medical students at the University of Cape Town participated in a six-day educational intervention in which a novel “haptico-visual observation and drawing” (HVOD) method was employed. Data were collected through individual interviews as well as a focus group discussion. The HVOD method was successfully applied by all the participants, who reported an improvement of their cognitive understanding and memorization of the 3D form of the anatomical part. All the five participants described the development of a “mental picture” of the object as being central to “deep learning.” The use of the haptic senses coupled with the simultaneous act of drawing enrolled sources of information that were reported by the participants to have enabled better memorization. We postulate that the more sources of information about an object, the greater degree of complexity could be appreciated, and therefore the more clearly it could be captured and memorized. The inclusion of haptics has implications for cadaveric dissection versus non-cadaveric forms of learning. This study was limited by its sample size as well as the bias and position of the researchers, but the sample of five produced a sufficient amount of data to generate a conceptual model and hypothesis.},
	language = {en},
	number = {2},
	urldate = {2020-02-28},
	journal = {Anatomical Sciences Education},
	author = {Reid, Stephen and Shapiro, Leonard and Louw, Graham},
	year = {2019},
	note = {\_eprint: https://anatomypubs.onlinelibrary.wiley.com/doi/pdf/10.1002/ase.1807},
	keywords = {anatomical drawing, cadaveric dissection, cognition, gross anatomy education, haptics, medical education, touch, undergraduate education},
	pages = {164--172}
}

@inproceedings{lopes_impacto_2015,
	address = {Charlotte, NC, USA},
	series = {{UIST} '15},
	title = {Impacto: {Simulating} {Physical} {Impact} by {Combining} {Tactile} {Stimulation} with {Electrical} {Muscle} {Stimulation}},
	isbn = {978-1-4503-3779-3},
	shorttitle = {Impacto},
	url = {https://doi.org/10.1145/2807442.2807443},
	doi = {10.1145/2807442.2807443},
	abstract = {We present impacto, a device designed to render the haptic sensation of hitting or being hit in virtual reality. The key idea that allows the small and light impacto device to simulate a strong hit is that it decomposes the stimulus: it renders the tactile aspect of being hit by tapping the skin using a solenoid; it adds impact to the hit by thrusting the user's arm backwards using electrical muscle stimulation. The device is self-contained, wireless, and small enough for wearable use, thus leaves the user unencumbered and able to walk around freely in a virtual environment. The device is of generic shape, allowing it to also be worn on legs, so as to enhance the experience of kicking, or merged into props, such as a baseball bat. We demonstrate how to assemble multiple impacto units into a simple haptic suit. Participants of our study rated impact simulated using impacto's combination of solenoid hit and electrical muscle stimulation as more realistic than either technique in isolation.},
	urldate = {2020-02-28},
	booktitle = {Proceedings of the 28th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} \& {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Lopes, Pedro and Ion, Alexandra and Baudisch, Patrick},
	month = nov,
	year = {2015},
	keywords = {electrical muscle stimulation, force feedback, haptics, impact, mobile, solenoid, virtual reality, wearable},
	pages = {11--19}
}

@article{kos_challenges_2019,
	title = {Challenges in wireless communication for connected sensors and wearable devices used in sport biofeedback applications},
	volume = {92},
	issn = {0167-739X},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X17316692},
	doi = {10.1016/j.future.2018.03.032},
	abstract = {Sensors, wearables, wireless networks, and other Internet of Things technologies are ever more present in our daily life. We study their applicability and use in biofeedback systems and applications in sport. Biofeedback systems are important in motor learning where a person in the loop uses the feedback information to influence the execution performance. Sensors, actuators, and wireless technologies come in great varieties regarding their properties. We describe the most common groups of sensors and actuators that are used in sport and list the most widespread and easily available wireless technologies. We present the most important constraints of a biofeedback system operation and define a number of fundamental architectures of biofeedback systems. Taking into account all of the above, we present a number of different biofeedback application scenarios in sports. We match the scenarios to the most appropriate existing wireless technology that is expected to sustain scalability in the number of nodes or increased data rates for the expected application lifetime. We find out that currently none of the existing wireless technologies can satisfy the variety of demands of different biofeedback application scenarios.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Future Generation Computer Systems},
	author = {Kos, Anton and Milutinović, Veljko and Umek, Anton},
	month = mar,
	year = {2019},
	keywords = {Biofeedback systems, Distributed applications, Embedded devices, Internet of Things, Wearable sensors, Wireless technologies},
	pages = {582--592}
}

@inproceedings{ye_pull-ups_2019,
	address = {New Orleans, LA, USA},
	series = {{UIST} '19},
	title = {Pull-{Ups}: {Enhancing} {Suspension} {Activities} in {Virtual} {Reality} with {Body}-{Scale} {Kinesthetic} {Force} {Feedback}},
	isbn = {978-1-4503-6816-2},
	shorttitle = {Pull-{Ups}},
	url = {https://doi.org/10.1145/3332165.3347874},
	doi = {10.1145/3332165.3347874},
	abstract = {We present Pull-Ups, a suspension kit that can suggest a range of body postures and thus enables various exercise styles of users perceiving the kinesthetic force feedback by suspending their weight with arm exertion during the interaction. Pull-Ups actuates the user's body to move up to 15 cm by pulling his or her hands using a pair of pneumatic artificial muscle groups. Our studies informed the discernible kinesthetic force feedbacks that were then exploited for the design of kinesthetic force feedback in three physical activities: kitesurfing, paragliding, and space invader. Our final study on user experiences suggested that a passive suspension kit alone added substantially to users' perceptions of realism and enjoyment (all above neutral) with passive physical support, while sufficient active feedback can further level them up. In addition, we found that both passive and active feedback of the suspension kit significantly reduced motion sickness in simulated kitesurfing and paragliding compared to when no suspension kit (thus no feedback) was provided. This work suggests that a passive suspension kit is cost-effective as a home exercise kit, while active feedback can further level up user experience, though at the cost of the installation (e.g., an air compressor in our prototype).},
	urldate = {2020-02-27},
	booktitle = {Proceedings of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Ye, Yuan-Syun and Chen, Hsin-Yu and Chan, Liwei},
	month = oct,
	year = {2019},
	keywords = {exertion, kinesthetic force feedback, physical exercise, suspension exercise, virtual reality},
	pages = {791--801}
}

@inproceedings{cauchard_activibe_2016,
	address = {San Jose, California, USA},
	series = {{CHI} '16},
	title = {{ActiVibe}: {Design} and {Evaluation} of {Vibrations} for {Progress} {Monitoring}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {{ActiVibe}},
	url = {https://doi.org/10.1145/2858036.2858046},
	doi = {10.1145/2858036.2858046},
	abstract = {Smartwatches and activity trackers are becoming prevalent, providing information about health and fitness, and offering personalized progress monitoring. These wearable devices often offer multimodal feedback with embedded visual, audio, and vibrotactile displays. Vibrations are particularly useful when providing discreet feedback, without users having to look at a display or anyone else noticing, thus preserving the flow of the primary activity. Yet, current use of vibrations is limited to basic patterns, since representing more complex information with a single actuator is challenging. Moreover, it is unclear how much the user--s current physical activity may interfere with their understanding of the vibrations. We address both issues through the design and evaluation of ActiVibe, a set of vibrotactile icons designed to represent progress through the values 1 to 10. We demonstrate a recognition rate of over 96\% in a laboratory setting using a commercial smartwatch. ActiVibe was also evaluated in situ with 22 participants for a 28-day period. We show that the recognition rate is 88.7\% in the wild and give a list of factors that affect the recognition, as well as provide design guidelines for communicating progress via vibrations.},
	urldate = {2020-02-27},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cauchard, Jessica R. and Cheng, Janette L. and Pietrzak, Thomas and Landay, James A.},
	month = may,
	year = {2016},
	keywords = {tactile display, tactons, vibrotactile icons},
	pages = {3261--3271}
}

@article{cauchard_positive_2019,
	title = {The {Positive} {Impact} of {Push} vs {Pull} {Progress} {Feedback}},
	url = {https://dl.acm.org/doi/abs/10.1145/3351234},
	abstract = {Lack of physical activity has been shown to increase disease and reduce life expectancy. In response, mobile devices are increasingly being used to support people's health and fitness by tracking p...},
	language = {EN},
	urldate = {2020-02-25},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Cauchard, Jessica and FreyJeremy and ZahrtOctavia and JohnsonKrister and CrumAlia and A, LandayJames},
	month = sep,
	year = {2019}
}

@inproceedings{frisoli_preliminary_2008,
	title = {Preliminary design of rowing simulator for in-door skill training},
	doi = {10.4108/ICST.AMBISYS2008.2911},
	abstract = {In this paper we report on the preliminary design of a rowing simulator to be integrated in a VR sport training system for rowing. The proposed simulator aims at bringing in an indoor location the specific features and situations of outdoor rowing, by means of an enhanced Virtual Environment (VE) that combines visual, haptic, acoustic flows to proprio- and exteroception of user status. This paper describes the experimental activities carried out on in-door rowing to characterize the main features of the stroke gesture, the design and analytical study of a fluidodynamic dissipator for force rendering and an overview of graphic simulation and of the overall system architecture.},
	booktitle = {{HAS} '08},
	author = {Frisoli, Antonio and Ruffaldi, Emanuele and Bagnoli, Leonardo and Filippeschi, Alessandro and Avizzano, Carlo Alberto and Vanni, Federico and Bergamasco, Massimo},
	year = {2008}
}

@misc{erp_application_2006,
	title = {Application of tactile displays in sports : where to, how and when to move},
	shorttitle = {Application of tactile displays in sports},
	url = {/paper/Application-of-tactile-displays-in-sports-%3A-where-Erp-Saturday/b73605f32024a4611151e5f69820243bae018ecb},
	abstract = {In this paper we explore the possibilities of tactile displays in sports applications, and report an experiment that shows that a tactile feedback systems improves rowing efficiency compared to traditional feedback systems. Earlier papers have shown that localized vibrations provide intuitive cues for orientation and navigation, i.e. where to move to, and motion initiation, i.e. how to move. In the first part of the paper we will give examples for the spin-off of these applications of tactile displays to the sports domain, including tactical guidance for soccer players (where) and body posture feedback for speed skaters and cyclists (how). In part two we report a study that extends the where and how examples with coordinated movement patterns. These systems also provide cues on when to move. In a laboratory experiment we showed that motion feedback with a localized and timed tactile cue resulted in better performance than the current methods of motion feedback.},
	language = {en},
	urldate = {2020-02-27},
	author = {Erp, J. B. F. van and Saturday, Ian McEwans and Jansen, Craig},
	year = {2006},
	note = {Library Catalog: www.semanticscholar.org}
}

@inproceedings{marschall_does_2007,
	title = {Does frequent augmented feedback really degrade learning? {A} meta-analysis},
	shorttitle = {Does frequent augmented feedback really degrade learning?},
	abstract = {s of the 6th annual congress of the European College of Sport Science, 15th congress of the German Society of Sport Science (p. 129). Koln: Sport und Buch Strauss. *McCullagh, P., \& Little, W. S. (1990). Demonstrations and knowledge of results in motor skill acquisition. Perceptual and Motor Skills, 71, 735-742. *Nicholson, D. E., \& Schmidt, R. A. (1991). Scheduling infor- mation feedback to enhance training effectiveness. Pro- ceedings of the Human Factors and Ergonomics Society, USA, 35, 1400-1402. Raudenbush, S. W. (1994). Random effects models. In H. Cooper \& L. V. Hedges (Eds.), The handbook of research synthesis (pp. 301-322). New York: Sage. Rosenthal, M. C. (1994). The fugitive literature. In H. Cooper \& L. V. Hedges (Eds.), The handbook of research synthesis (pp. 8596). New York: Sage. Rosenthal, R. (1994). Parametric measures of effect size. In H. Cooper \& L. V. Hedges (Eds.), The handbook of re- search synthesis (pp. 231-244). New York: Sage. Rosenthal, R. \& DiMatteo, M. R. (2001). Meta Analysis: Re- cent Developments in Quantitative Methods for Literature Reviews. Annual Review of Psychology, 52, 59-82. Russel, D. M., \& Newell, K. M. (2007). On No-KR tests in mo- tor learning, retention and transfer. Human Movement Science,26, 155-173. Rustenbach, J. S. (2003). Metaanalyse. Eine anwendungsorientierte Einfuhrung. Bern, Switzerland: Hans Huber. Salmoni, A. W., Schmidt, R. A., \& Walter, C. B. (1984). Knowledge of results and perceptual motor learning. Psychological Bulletin, 95, 355-386. *Schlicher, R. (1996). Experimentelle Untersuchung zum Einflus reduzierter und maximaler Sollwert-Prasentationsfrequenzen bei videogestutzten TechniktrainingsProzeduren im Sport [On the effect of reduced and maximum presentation of goal information in video-assisted skill-training in sport]. Unpublished diploma thesis. Universitat des Saarlandes, Saarbrucken, Germany. Schlicht, W. (1994). Sport und Primarpravention [Sport and primary prevention]. Gottingen, Germany: Hogrefe. Schmidt, R. A. (1982). Motor control and learning. A behavioral emphasis. Champaign/IL: Human Kinetics. Schmidt, R. A. (1991). Frequent augmented feedback can degrade learning: Evidence and interpretations. In G. E. Stelmach \& J. Requin (Eds.), Tutorials in motor neuroscience (pp. 59-75). Dordrecht: Kluwer. *Schmidt, R. A., Lange, C., \& Young, D. E. (1990). Optimizing summary knowledge of results for skill learning. Human Movement Science, 9 , 325-348. *Schmidt, R. A., Young, D. E., Swinnen, S., \& Shapiro, D. C. (1989). Summary knowledge of results for skill acquisition. Support for the guidance hypothesis. Journal of Experimental Psychology: Learning, Memory, and Cognition, 15, 352-},
	author = {Marschall, Franz and Bund, Andreas and Wiemeyer, Josef},
	year = {2007}
}

@article{girdler_mid-air_2020,
	title = {Mid-{Air} {Haptics} in {Aviation} -- creating the sensation of touch where there is nothing but thin air},
	url = {https://arxiv.org/abs/2001.01445v1},
	abstract = {The exciting new technology known as mid-air haptics has been adopted by
several industries including Automotive and Entertainment, however it has yet
to emerge in simulated pilot training or in real-life flight decks. Full-flight
simulators are expensive to manufacture, maintain and operate. Not only that,
each simulator is limited to one aircraft type, which is inefficient for the
majority of airlines that have several in service. With the growing trend in
touchscreen instrumentation, cockpit displays require the pilot's attention to
be drawn away from their view out of the window. But by using gesture
recognition interfaces combined with mid-air haptic feedback, we can mitigate
this shortcoming while also adding another dimension to the existing technology
for pilots already familiar with using legacy cockpits, complete with
traditional instrumentation. Meanwhile, simulation environments using augmented
and virtual reality technology offers quality immersive training to the extent
that pilots can go from hundreds of hours of simulated training to being
responsible for hundreds of lives on their very first flight. The software
re-programmability and dynamic richness afforded by mid-air haptic technologies
combined with a basic full-motion platform could allow for an interchange of
instrumentation layouts thus enhancing simulation immersiveness and
environments. Finally, by borrowing and exploring concepts within the
automotive sector, this concept paper presents how flight deck design could
evolve by adopting this technology. If pilot testimony suggests that they can
adapt to virtual objects, can this replace physical controls?},
	language = {en},
	urldate = {2020-02-27},
	author = {Girdler, Alex and Georgiou, Orestis},
	month = jan,
	year = {2020}
}

@article{girdler_mid-air_nodate,
	title = {Mid-{Air} {Haptics} in {Aviation} - creating the sensation of touch where there is nothing but thin air},
	abstract = {The exciting new technology known as mid-air haptics has been adopted by several industries including Automotive and Entertainment, however it has yet to emerge in simulated pilot training or in real-life flight decks. Full-flight simulators are expensive to manufacture, maintain and operate. Not only that, each simulator is limited to one aircraft type, which is inefficient for the majority of airlines that have several in service.},
	language = {en},
	author = {Girdler, Alex and Georgiou, Orestis},
	pages = {13}
}

@article{alahakone_real-time_2010,
	title = {A real-time interactive biofeedback system for sports training and rehabilitation},
	volume = {224},
	issn = {1754-3371},
	url = {https://doi.org/10.1243/17543371JSET52},
	doi = {10.1243/17543371JSET52},
	abstract = {Biofeedback systems have become a prominent component in the sports domain as a means of motor training and rehabilitation. This paper presents the development of a biofeedback prototype and system software framework facilitating its functionality in real time. The prototype incorporates an inertial measurement sensor unit, a wireless vibration stimulus module for vibrotactile biofeedback, and interactive system software behaving as the backbone of the system. The functionality of the prototype was tested with a stability test during which biofeedback was provided to improve postural control based on trunk tilt displacements. The test involved subjects standing in the tandem Romberg position during which their medial—lateral trunk tilt was measured, and postural sway biofeedback was conveyed via vibrotactile actuators placed on either side of the trunk. Two conditions were tested, namely eyes open and eyes closed, and postural sway with biofeedback was evaluated, as opposed to with no feedback. A 15.2per cent sway reduction resulted in the eyes-open condition, and a significant reduction of 55.2per cent was reported for the eyes-closed condition. The results demonstrate that instantaneous feedback provided via vibration stimulus can reduce postural sway based on trunk tilt measurements. Hence, the system's pertinence to comparable approaches employed in sports training and rehabilitation is foreseen.},
	language = {en},
	number = {2},
	urldate = {2020-02-25},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part P: Journal of Sports Engineering and Technology},
	author = {Alahakone, A U and Senanayake, A},
	month = jun,
	year = {2010},
	keywords = {Keywordsinertial sensors, motor augmentation, sports training, vibrotactile biofeedback, virtual instrumentation},
	pages = {181--190}
}

@inproceedings{lindeman_tactapack_2006,
	title = {The {TactaPack}: {A} {Wireless} {Sensor}/{Actuator} {Package} for {Physical} {Therapy} {Applications}},
	shorttitle = {The {TactaPack}},
	doi = {10.1109/HAPTIC.2006.1627117},
	abstract = {In this paper, we present preliminary work we have done on designing the TactaPack, a wearable sensor/actuator device that uses a Bluetooth wireless connection to return sensor data to a host, and to receive commands to initiate expressive vibrotactile stimuli. We present our work in the context of a physical therapy application designed to provide more autonomy for patients when performing rehabilitative exercises. This assistive technology has the potential to reduce injuries during therapy due to improper patient joint movement, and decrease the workload of physical therapists, thereby reducing healthcare costs. Though still in the early stages of design, we believe the TactaPack can be used to produce systems that are less cumbersome than current, wired solutions, and simplify the creation of high-level applications by offloading from the CPU to the device the process of sensing, testing against threshold values, and actuation.},
	booktitle = {2006 14th {Symposium} on {Haptic} {Interfaces} for {Virtual} {Environment} and {Teleoperator} {Systems}},
	author = {Lindeman, R.W. and Yanagida, Y. and Hosaka, K. and Abe, S.},
	month = mar,
	year = {2006},
	note = {ISSN: 2324-7355},
	keywords = {Actuators, Bluetooth, Costs, Injuries, Medical services, Medical treatment, Packaging, System testing, Wearable sensors, Wireless sensor, Wireless sensor networks, actuator, physical therapy, vibrotactile, virtual reality},
	pages = {337--341}
}

@misc{noauthor_applica-tion_nodate,
	title = {Applica-tion of tactile displays in sports: where to, how andwhen to move. - {Recherche} {Google}},
	url = {https://www.google.com/search?client=firefox-b-d&q=Applica-tion+of+tactile+displays+in+sports%3A+where+to%2C+how+andwhen+to+move.},
	urldate = {2020-02-25}
}

@inproceedings{frisoli_preliminary_2008-1,
	address = {Quebec, Canada},
	title = {Preliminary design of rowing simulator for in-door skill training},
	isbn = {978-963-9799-16-5},
	url = {http://eudl.eu/doi/10.4108/ICST.AMBISYS2008.2911},
	doi = {10.4108/ICST.AMBISYS2008.2911},
	abstract = {In this paper we report on the preliminary design of a rowing simulator to be integrated in a VR sport training system for rowing. The proposed simulator aims at bringing in an indoor location the speciﬁc features and situations of outdoor rowing, by means of an enhanced Virtual Environment (VE) that combines visual, haptic, acoustic ﬂows to proprio- and exteroception of user status. This paper describes the experimental activities carried out on in-door rowing to characterize the main features of the stroke gesture, the design and analytical study of a ﬂuidodynamic dissipator for force rendering and an overview of graphic simulation and of the overall system architecture.},
	language = {en},
	urldate = {2020-02-25},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Ambient} {Media} and {Systems}},
	publisher = {ICST},
	author = {Frisoli, Antonio and Ruffaldi, Emanuele and Bagnoli, Leonardo and Filippeschi, Alessandro and Avizzano, Carlo Alberto and Vanni, Federico and Bergamasco, Massimo},
	year = {2008}
}

@inproceedings{hirano_synchronized_2019,
	title = {Synchronized {Running}: {Running} {Support} {System} for {Guide} {Runners} by {Haptic} {Sharing} in {Blind} {Marathon}},
	shorttitle = {Synchronized {Running}},
	doi = {10.1109/WHC.2019.8816134},
	abstract = {Blind marathon is a sport where visually impaired people can run with sighted guides in pairs. In this paper, we present an assistant system for blind marathon runners called "Synchronized Running" that improves the guidance experience for the runners. Our proposed system allows both runners to match their running tempo and synchronize with each other, similar to a three-legged race case, without any direct physical attachment. Two modules are located on the ankle of both runners, that measure the acceleration of the visually impaired runner, and provide haptic feedback to the guide's ankle according the tempo of the running pace. This synchronization allows the guide to grasp a comfortable running pace towards the visually impaired person, allowing seamless running communication between both runners. The evaluation results indicate that our system encourage runners (primarily novice guides) to achieve comfortable guidance running experience toward the blind runners.},
	booktitle = {2019 {IEEE} {World} {Haptics} {Conference} ({WHC})},
	author = {Hirano, Tomohisa and Kanebako, Junichi and Saraiji, MHD Yamen and Peiris, Roshan Lalintha and Minamizawa, Kouta},
	month = jul,
	year = {2019},
	note = {ISSN: null},
	keywords = {Accelerometers, Foot, Haptic interfaces, Sports, Synchronization, Transducers, Vibrations, assistant system, blind marathon runners, blind runners, comfortable guidance running experience, comfortable running pace, guide runners, handicapped aids, haptic feedback, haptic interfaces, haptic sharing, running support system, running tempo, seamless running communication, sighted guides, sport, synchronization, synchronized running, three-legged race case, visually impaired people, visually impaired person, visually impaired runner},
	pages = {25--30}
}

@misc{noauthor_activibe_nodate,
	title = {{ActiVibe} {\textbar} {Proceedings} of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	url = {https://dl.acm.org/doi/abs/10.1145/2858036.2858046},
	language = {EN},
	urldate = {2020-02-25}
}

@misc{noauthor_pull-ups_nodate,
	title = {Pull-{Ups}: {Enhancing} {Suspension} {Activities} in {Virtual} {Reality} with {Body}-{Scale} {Kinesthetic} {Force} {Feedback} {\textbar} {Proceedings} of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	shorttitle = {Pull-{Ups}},
	url = {https://dl.acm.org/doi/abs/10.1145/3332165.3347874},
	language = {EN},
	urldate = {2020-02-25}
}

@article{baldi_wearable_2020,
	title = {Wearable {Haptics} for {Remote} {Social} {Walking}},
	issn = {1939-1412, 2329-4051, 2334-0134},
	url = {http://arxiv.org/abs/2001.03899},
	doi = {10.1109/TOH.2020.2967049},
	abstract = {Walking is an essential activity for a healthy life, which becomes less tiring and more enjoyable if done together. Common difficulties we have in performing sufficient physical exercise, for instance the lack of motivation, can be overcome by exploiting its social aspect. However, our lifestyle sometimes makes it very difficult to find time together with others who live far away from us to go for a walk. In this paper we propose a novel system enabling people to have a 'remote social walk' by streaming the gait cadence between two persons walking in different places, increasing the sense of mutual presence. Vibrations provided at the users' ankles display the partner's sensation perceived during the heel-strike. In order to achieve the aforementioned goal in a two users experiment, we envisaged a four-step incremental validation process: i) a single walker has to adapt the cadence with a virtual reference generated by a software; ii) a single user is tasked to follow a predefined time varying gait cadence; iii) a leader-follower scenario in which the haptic actuation is mono-directional; iv) a peer-to-peer case with bi-directional haptic communication. Careful experimental validation was conducted involving a total of 50 people, which confirmed the efficacy of our system in perceiving the partners' gait cadence in each of the proposed scenarios.},
	urldate = {2020-02-25},
	journal = {IEEE Transactions on Haptics},
	author = {Baldi, Tommaso Lisini and Paolocci, Gianluca and Barcelli, Davide and Prattichizzo, Domenico},
	year = {2020},
	note = {arXiv: 2001.03899},
	keywords = {Computer Science - Human-Computer Interaction},
	pages = {1--1}
}

@misc{noauthor_us_nodate,
	title = {{US} {Patent} {Application} for {ACTUATED} {TENDON} {PAIRS} {IN} {A} {VIRTUAL} {REALITY} {DEVICE} {Patent} {Application} ({Application} \#20180077976 issued {March} 22, 2018) - {Justia} {Patents} {Search}},
	url = {https://patents.justia.com/patent/20180077976},
	urldate = {2020-02-25}
}

@article{song_immersive_2012,
	title = {An {Immersive} {VR} {System} for {Sports} {Education}},
	volume = {E95-D},
	issn = {1745-1361, 0916-8532},
	url = {http://search.ieice.org/bin/summary.php?id=e95-d_5_1324&category=D&year=2012&lang=E&abst=},
	abstract = {The development of new technologies has undoubtedly promoted the advances of modern education, among which Virtual Reality (VR) technologies have made the education more visually accessible for students. However, classroom education has been the focus of VR applications whereas not much research has been done in promoting sports education using VR technologies. In this paper, an immersive VR system is designed and implemented to create a more intuitive and visual way of teaching tennis. A scalable system architecture is proposed in addition to the hardware setup layout, which can be used for various immersive interactive applications such as architecture walkthroughs, military training simulations, other sports game simulations, interactive theaters, and telepresent exhibitions. Realistic interaction experience is achieved through accurate and robust hybrid tracking technology, while the virtual human opponent is animated in real time using shader-based skin deformation. Potential future extensions are also discussed to improve the teaching/learning experience.},
	number = {5},
	urldate = {2020-02-25},
	journal = {IEICE TRANSACTIONS on Information and Systems},
	author = {Song, Peng and Xu, Shuhong and Fong, Wee Teck and Chin, Ching Ling and Chua, Gim Guan and Huang, Zhiyong},
	month = may,
	year = {2012},
	pages = {1324--1331}
}
@article{van_breda_vibrotactile_2017,
	title = {Vibrotactile feedback as a tool to improve motor learning and sports performance: a systematic review},
	volume = {3},
	issn = {2055-7647},
	shorttitle = {Vibrotactile feedback as a tool to improve motor learning and sports performance},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5530110/},
	doi = {10.1136/bmjsem-2016-000216},
	abstract = {Background
Evidence concerning the use of vibrotactile feedback for acquiring and learning new motor skills is limited. Although various concepts and applications for tactile feedback have been proposed, little is known about the suitability of this feedback mechanism in sports training.

Aim
The goal of this systematic review was to gather knowledge on the efficacy of the use of vibrotactile feedback in improving sports performance skills.

Design
Systematic review.

Methods
Comprehensively searched databases were: PubMed, Cochrane and Web of Science. Studies investigating the effects of using vibrotactile feedback in sports training in healthy subjects were included in this review.

Results
No consensus was found regarding the positive effectiveness on performance using vibrotactile feedback in a sports context. No evidence was found that the addition of tactile feedback is effective for acquiring new motor skills. None of the studies show a significant learning effect.},
	number = {1},
	urldate = {2020-02-25},
	journal = {BMJ Open Sport — Exercise Medicine},
	author = {van Breda, Eric and Verwulgen, Stijn and Saeys, Wim and Wuyts, Katja and Peeters, Thomas and Truijen, Steven},
	month = jul,
	year = {2017},
	pmid = {28761708},
	pmcid = {PMC5530110}
}

@misc{noauthor_teslasuit_nodate,
	title = {{TESLASUIT} - {VR} and haptic feedback training for athletic performance},
	url = {https://teslasuit.io/athletics/},
	abstract = {TESLASUIT's full body suit VR and AR solution for athletes helps perfect technique and master complex sequences of action by programming human muscle memory. With TESLASUIT, the expert is embedded into training with physical haptic feedback.},
	language = {en-US},
	urldate = {2020-02-25},
	journal = {TESLASUIT}
}

@inproceedings{shiraishi_haptic_2018,
	address = {Singapore},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Haptic {Directional} {Instruction} {System} for {Sports}},
	isbn = {978-981-10-4157-0},
	doi = {10.1007/978-981-10-4157-0_61},
	abstract = {We proposed a new haptic instruction system for sports trainings that provides field players with instructed directions. The system consists of a stimulation unit (SU) for a player and an instruction unit (IU) for an instructor. Players wear the SU around their waist, and can recognize instructed directions by vibrations using 13 vibration actuators. The IU sends a direction where the joystick tilts to the SU via wireless communication modules. Preliminary experiments confirmed that the all participants did not feel the slipping away of the SU, and all participants were able to recognize its vibration even though they were running at 5, 10 km/h and standing (0 km/h). However, at 15 km/h, a participant who has a plump body recognized that a little or hardly recognized that at back part. We need to improve the method of providing stimuli at back part. By using the system, instructors and directors can provide the instructed directions to a field player without both any voice and gesture.},
	language = {en},
	booktitle = {Haptic {Interaction}},
	publisher = {Springer},
	author = {Shiraishi, Ryoichiro and Sato, Koya and Sano, Yuji and Otsuki, Mai},
	editor = {Hasegawa, Shoichi and Konyo, Masashi and Kyung, Ki-Uk and Nojima, Takuya and Kajimoto, Hiroyuki},
	year = {2018},
	keywords = {Direction instruction, Haptic device, Superhuman sports, Support system, Vibration},
	pages = {361--368}
}

@incollection{noauthor_2_1995,
	series = {Classics in {Applied} {Mathematics}},
	title = {2. {Analysis} of the {Least} {Squares} {Problem}},
	isbn = {978-0-89871-356-5},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971217.ch2},
	abstract = {The central point of this chapter will be an analysis of Problem LS based on a certain decomposition of an m × n matrix A in the form  HRKTHRKT{\textless}math display="inline" overflow="scroll"{\textgreater} {\textless}mrow{\textgreater} {\textless}msup{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}H{\textless}/mi{\textgreater}{\textless}mi{\textgreater}R{\textless}/mi{\textgreater}{\textless}mi{\textgreater}K{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}T{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/msup{\textgreater} {\textless}/mrow{\textgreater} {\textless}/math{\textgreater}  where H and K are orthogonal matrices. The definition of an orthogonal matrix and other linear algebraic concepts are summarized in Appendix A. Our interest in this general type of decomposition  A=HRKTA=HRKT{\textless}math display="inline" overflow="scroll"{\textgreater} {\textless}mrow{\textgreater}{\textless}mi{\textgreater}A{\textless}/mi{\textgreater}{\textless}mo{\textgreater}={\textless}/mo{\textgreater} {\textless}msup{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}H{\textless}/mi{\textgreater}{\textless}mi{\textgreater}R{\textless}/mi{\textgreater}{\textless}mi{\textgreater}K{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}T{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/msup{\textgreater} {\textless}/mrow{\textgreater} {\textless}/math{\textgreater}  is motivated by the practicality and usefulness of certain specific computable decompositions of this type that are introduced in Chapters 3 and 4.},
	urldate = {2020-02-12},
	booktitle = {Solving {Least} {Squares} {Problems}},
	publisher = {Society for Industrial and Applied Mathematics},
	month = jan,
	year = {1995},
	doi = {10.1137/1.9781611971217.ch2},
	pages = {5--8}
}

@incollection{lawson_notitle_1995,
	series = {Classics in {Applied} {Mathematics}},
	isbn = {978-0-89871-356-5},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971217},
	abstract = {An accessible text for the study of numerical methods for solving least squares problems remains an essential part of a scientific software foundation. Feedback that we have received from practicing engineers and scientists, as well as from educators and students in numerical analysis, indicates that this book has served this purpose. We were pleased when SIAM decided to republish the book in their Classics in Applied Mathematics series. The main body of the book remains unchanged from the original book that was published by Prentice-Hall in 1974, with the exception of corrections to known errata. Appendix C has been edited to reflect changes in the associated software package and the software distribution method. A new Appendix D has been added, giving a brief survey of the many new developments in topics treated in the book during the period 1974–1995. Appendix D is organized into sections corresponding to the chapters of the main body of the book and includes a bibliography listing about 230 publications from 1974 to 1995.},
	urldate = {2019-02-03},
	booktitle = {Solving {Least} {Squares} {Problems}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Lawson, C. and Hanson, R.},
	month = jan,
	year = {1995},
	doi = {10.1137/1.9781611971217}
}

@inproceedings{kay_how_2015,
	address = {Seoul, Republic of Korea},
	title = {How {Good} is 85\%?: {A} {Survey} {Tool} to {Connect} {Classifier} {Evaluation} to {Acceptability} of {Accuracy}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {How {Good} is 85\%?},
	url = {http://dl.acm.org/citation.cfm?doid=2702123.2702603},
	doi = {10.1145/2702123.2702603},
	abstract = {Many HCI and ubiquitous computing systems are characterized by two important properties: their output is uncertain—it has an associated accuracy that researchers attempt to optimize—and this uncertainty is user-facing—it directly affects the quality of the user experience. Novel classifiers are typically evaluated using measures like the F1 score—but given an F-score of (e.g.) 0.85, how do we know whether this performance is good enough? Is this level of uncertainty actually tolerable to users of the intended application—and do people weight precision and recall equally? We set out to develop a survey instrument that can systematically answer such questions. We introduce a new measure, acceptability of accuracy, and show how to predict it based on measures of classifier accuracy. Out tool allows us to systematically select an objective function to optimize during classifier evaluation, but can also offer new insights into how to design feedback for user-facing classification systems (e.g., by combining a seemingly-low-performing classifier with appropriate feedback to make a highly usable system). It also reveals potential issues with the ubiquitous F1-measure as applied to user-facing systems.},
	language = {en},
	urldate = {2020-01-22},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '15},
	publisher = {ACM Press},
	author = {Kay, Matthew and Patel, Shwetak N. and Kientz, Julie A.},
	year = {2015},
	pages = {347--356}
}

@article{doan_crowdsourcing_2011,
	title = {Crowdsourcing {Systems} on the {World}-{Wide} {Web}},
	volume = {54},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1924421.1924442},
	doi = {10.1145/1924421.1924442},
	abstract = {The practice of crowdsourcing is transforming the Web and giving rise to a new field.},
	number = {4},
	urldate = {2019-12-13},
	journal = {Commun. ACM},
	author = {Doan, Anhai and Ramakrishnan, Raghu and Halevy, Alon Y.},
	month = apr,
	year = {2011},
	pages = {86--96}
}

@article{doan_crowdsourcing_2011-1,
	title = {Crowdsourcing systems on the {World}-{Wide} {Web}},
	volume = {54},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=1924421.1924442},
	doi = {10.1145/1924421.1924442},
	language = {en},
	number = {4},
	urldate = {2019-12-13},
	journal = {Communications of the ACM},
	author = {Doan, Anhai and Ramakrishnan, Raghu and Halevy, Alon Y.},
	month = apr,
	year = {2011},
	pages = {86}
}

@article{law_evaluation_nodate,
	title = {{EVALUATION} {OF} {ALGORITHMS} {USING} {GAMES}: {THE} {CASE} {OF} {MUSIC} {TAGGING}},
	abstract = {Search by keyword is an extremely popular method for retrieving music. To support this, novel algorithms that automatically tag music are being developed. The conventional way to evaluate audio tagging algorithms is to compute measures of agreement between the output and the ground truth set. In this work, we introduce a new method for evaluating audio tagging algorithms on a large scale by collecting set-level judgments from players of a human computation game called TagATune. We present the design and preliminary results of an experiment comparing ﬁve algorithms using this new evaluation metric, and contrast the results with those obtained by applying several conventional agreement-based evaluation metrics.},
	language = {en},
	author = {Law, Edith and West, Kris and Mandel, Michael},
	pages = {6}
}

@article{pastor_functional_2004,
	title = {The {Functional} {Neuroanatomy} of {Temporal} {Discrimination}},
	volume = {24},
	doi = {10.1523/JNEUROSCI.4210-03.2004},
	abstract = {Two identical stimuli, such as a pair of electrical shocks to the skin, are readily perceived as two separate events in time provided the interval between them is sufficiently long. However, as they are presented progressively closer together, there comes a point when the two separate stimuli are perceived as a single stimulus. Damage to posterior parietal cortex, peri-supplementary motor area (peri-SMA), and basal ganglia can disturb this form of temporal discrimination. Our aim was to establish, in healthy subjects, the brain areas that are involved in this process. During functional magnetic resonance imaging scanning, paired electrical pulses, separated by variable inter-stimulus intervals (5-110 msec), were delivered to different sites on one forearm (8-64 mm from the midline). Subjects were required to simply detect the stimulus (control task) or to identify a stimulus property. For temporal discrimination (TD), subjects reported whether they felt one or two stimuli. For spatial discrimination, they reported whether the stimuli were located on the right or left side of the forearm. Subjects reported their choice by pressing a button with the opposite hand. Our results showed that discrimination, as opposed to simply detection, activated several brain areas. Most were common to both discrimination tasks. These included regions of prefrontal cortex, right postcentral gyrus and inferior parietal lobule, basal ganglia, and cerebellum. However, activation of pre-SMA and anterior cingulate was found to be specific to the TD task. This suggests that these two frontal regions may play a role in the temporal processing of somatosensory events.},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Pastor, Maria and Day, Brian and Macaluso, Emiliano and Friston, Karl and Frackowiak, Richard},
	month = apr,
	year = {2004},
	pages = {2585--91}
}

@article{luz_survey_2015,
	title = {A survey of task-oriented crowdsourcing},
	volume = {44},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-014-9423-5},
	doi = {10.1007/s10462-014-9423-5},
	abstract = {Since the advent of artificial intelligence, researchers have been trying to create machines that emulate human behaviour. Back in the 1960s however, Licklider (IRE Trans Hum Factors Electron 4–11, 1960) believed that machines and computers were just part of a scale in which computers were on one side and humans on the other (human computation). After almost a decade of active research into human computation and crowdsourcing, this paper presents a survey of crowdsourcing human computation systems, with the focus being on solving micro-tasks and complex tasks. An analysis of the current state of the art is performed from a technical standpoint, which includes a systematized description of the terminologies used by crowdsourcing platforms and the relationships between each term. Furthermore, the similarities between task-oriented crowdsourcing platforms are described and presented in a process diagram according to a proposed classification. Using this analysis as a stepping stone, this paper concludes with a discussion of challenges and possible future research directions.},
	language = {en},
	number = {2},
	urldate = {2019-11-19},
	journal = {Artificial Intelligence Review},
	author = {Luz, Nuno and Silva, Nuno and Novais, Paulo},
	month = aug,
	year = {2015},
	keywords = {Complex tasks, Crowdsourcing, Human computation, Micro-task, Survey},
	pages = {187--213}
}

@inproceedings{wiggins_conservation_2011,
	title = {From {Conservation} to {Crowdsourcing}: {A} {Typology} of {Citizen} {Science}},
	shorttitle = {From {Conservation} to {Crowdsourcing}},
	doi = {10.1109/HICSS.2011.207},
	abstract = {Citizen science is a form of research collaboration involving members of the public in scientific research projects to address real-world problems. Often organized as a virtual collaboration, these projects are a type of open movement, with collective goals addressed through open participation in research tasks. Existing typologies of citizen science projects focus primarily on the structure of participation, paying little attention to the organizational and macrostructural properties that are important to designing and managing effective projects and technologies. By examining a variety of project characteristics, we identified five types-Action, Conservation, Investigation, Virtual, and Education- that differ in primary project goals and the importance of physical environment to participation.},
	booktitle = {2011 44th {Hawaii} {International} {Conference} on {System} {Sciences}},
	author = {Wiggins, Andrea and Crowston, Kevin},
	month = jan,
	year = {2011},
	note = {ISSN: 1530-1605},
	keywords = {Biological system modeling, Collaboration, Communities, Education, Monitoring, Organizations, Production, citizen science typology, crowdsourcing, groupware, natural sciences computing, research and development, research collaboration, scientific research projects, social sciences, virtual collaboration},
	pages = {1--10}
}

@misc{noauthor_conservation_nodate,
	title = {From {Conservation} to {Crowdsourcing}: {A} {Typology} of {Citizen} {Science} - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore.ieee.org/abstract/document/5718708},
	urldate = {2019-11-19}
}

@article{daniel_quality_2018,
	title = {Quality {Control} in {Crowdsourcing}: {A} {Survey} of {Quality} {Attributes}, {Assessment} {Techniques}, and {Assurance} {Actions}},
	volume = {51},
	issn = {0360-0300},
	shorttitle = {Quality {Control} in {Crowdsourcing}},
	url = {http://doi.acm.org/10.1145/3148148},
	doi = {10.1145/3148148},
	abstract = {Crowdsourcing enables one to leverage on the intelligence and wisdom of potentially large groups of individuals toward solving problems. Common problems approached with crowdsourcing are labeling images, translating or transcribing text, providing opinions or ideas, and similar—all tasks that computers are not good at or where they may even fail altogether. The introduction of humans into computations and/or everyday work, however, also poses critical, novel challenges in terms of quality control, as the crowd is typically composed of people with unknown and very diverse abilities, skills, interests, personal objectives, and technological resources. This survey studies quality in the context of crowdsourcing along several dimensions, so as to define and characterize it and to understand the current state of the art. Specifically, this survey derives a quality model for crowdsourcing tasks, identifies the methods and techniques that can be used to assess the attributes of the model, and the actions and strategies that help prevent and mitigate quality problems. An analysis of how these features are supported by the state of the art further identifies open issues and informs an outlook on hot future research directions.},
	number = {1},
	urldate = {2019-11-19},
	journal = {ACM Comput. Surv.},
	author = {Daniel, Florian and Kucherbaev, Pavel and Cappiello, Cinzia and Benatallah, Boualem and Allahbakhsh, Mohammad},
	month = jan,
	year = {2018},
	keywords = {Crowdsourcing, assessment, assurance, attributes, quality model},
	pages = {7:1--7:40}
}

@inproceedings{law_curiosity_2016,
	address = {Santa Clara, California, USA},
	title = {Curiosity {Killed} the {Cat}, but {Makes} {Crowdwork} {Better}},
	isbn = {978-1-4503-3362-7},
	url = {http://dl.acm.org/citation.cfm?doid=2858036.2858144},
	doi = {10.1145/2858036.2858144},
	abstract = {Crowdsourcing systems are designed to elicit help from humans to accomplish tasks that are still difﬁcult for computers. How to motivate workers to stay longer and/or perform better in crowdsourcing systems is a critical question for designers. Previous work have explored different motivational frameworks, both extrinsic and intrinsic. In this work, we examine the potential for curiosity as a new type of intrinsic motivational driver to incentivize crowd workers. We design crowdsourcing task interfaces that explicitly incorporate mechanisms to induce curiosity and conduct a set of experiments on Amazon’s Mechanical Turk. Our experiment results show that curiosity interventions improve worker retention without degrading performance, and the magnitude of the effects are inﬂuenced by both the personal characteristics of the worker and the nature of the task.},
	language = {en},
	urldate = {2019-11-19},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Law, Edith and Yin, Ming and Goh, Joslin and Chen, Kevin and Terry, Michael A. and Gajos, Krzysztof Z.},
	year = {2016},
	pages = {4098--4110}
}

@article{allahbakhsh_quality_2013,
	title = {Quality {Control} in {Crowdsourcing} {Systems}: {Issues} and {Directions}},
	volume = {17},
	issn = {1089-7801, 1941-0131},
	shorttitle = {Quality {Control} in {Crowdsourcing} {Systems}},
	doi = {10.1109/MIC.2013.20},
	abstract = {As a new distributed computing model, crowdsourcing lets people leverage the crowd's intelligence and wisdom toward solving problems. This article proposes a framework for characterizing various dimensions of quality control in crowdsourcing systems, a critical issue. The authors briefly review existing quality-control approaches, identify open issues, and look to future research directions. In the Web extra, the authors discuss both design-time and runtime approaches in more detail.},
	number = {2},
	journal = {IEEE Internet Computing},
	author = {Allahbakhsh, Mohammad and Benatallah, Boualem and Ignjatovic, Aleksandar and Motahari-Nezhad, Hamid Reza and Bertino, Elisa and Dustdar, Schahram},
	month = mar,
	year = {2013},
	keywords = {Communities, Crowdsourcing, Electronic publishing, Encyclopedias, Quality control, crowdsourcing, crowdsourcing system, crowdsourcing workflows, design-time approach, distributed computing model, distributed processing, quality control, runtime approach, software quality},
	pages = {76--81}
}

@article{eickhoff_increasing_2013,
	title = {Increasing cheat robustness of crowdsourcing tasks},
	volume = {16},
	issn = {1573-7659},
	url = {https://doi.org/10.1007/s10791-011-9181-9},
	doi = {10.1007/s10791-011-9181-9},
	abstract = {Crowdsourcing successfully strives to become a widely used means of collecting large-scale scientific corpora. Many research fields, including Information Retrieval, rely on this novel way of data acquisition. However, it seems to be undermined by a significant share of workers that are primarily interested in producing quick generic answers rather than correct ones in order to optimise their time-efficiency and, in turn, earn more money. Recently, we have seen numerous sophisticated schemes of identifying such workers. Those, however, often require additional resources or introduce artificial limitations to the task. In this work, we take a different approach by investigating means of a priori making crowdsourced tasks more resistant against cheaters.},
	language = {en},
	number = {2},
	urldate = {2019-11-18},
	journal = {Information Retrieval},
	author = {Eickhoff, Carsten and de Vries, Arjen P.},
	month = apr,
	year = {2013},
	keywords = {Crowdsourcing, Human factors, Stability, User experiments},
	pages = {121--137}
}

@article{blum_getting_2019,
	title = {Getting {Your} {Hands} {Dirty} {Outside} the {Lab}: {A} {Practical} {Primer} for {Conducting} {Wearable} {Vibrotactile} {Haptics} {Research}},
	volume = {PP},
	shorttitle = {Getting {Your} {Hands} {Dirty} {Outside} the {Lab}},
	doi = {10.1109/TOH.2019.2930608},
	abstract = {As haptics have become an ingrained part of our wearable experience, particularly through phones, smartwatches and fitness trackers, significant research effort has been conducted to find new ways of using wearable haptics to convey information, especially while we are on-the-go. In this article, instead of focusing on aspects of haptic information design, such as tacton encoding methods, actuators, and technical fabrication of devices, we address the more general recurring issues and "gotchas" that arise when moving from core haptic perceptual studies and in-lab wearable experiments to real world testing of wearable vibrotactile haptic systems. We summarize key issues for practitioners to take into account when designing and carrying out in-the-wild wearable haptic user studies, as well as for user studies in a lab environment that seek to simulate real-world conditions. We include not only examples from published work and commercial sources, but also hard-won illustrative examples derived from issues and failures from our own haptic studies. By providing a broad-based, accessible overview of recurring issues, we expect that both novice and experienced haptic researchers will find suggestions that will improve their own mobile wearable haptic studies.},
	journal = {IEEE Transactions on Haptics},
	author = {Blum, Jeffrey and Fortin, Pascal and Taha, Feras and Alirezaee, Parisa and Demers, Marc and Weill-Duflos, Antoine and Cooperstock, Jeremy},
	month = jul,
	year = {2019},
	pages = {1--1}
}

@inproceedings{findlater_differences_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {Differences in {Crowdsourced} vs. {Lab}-based {Mobile} and {Desktop} {Input} {Performance} {Data}},
	isbn = {978-1-4503-4655-9},
	url = {http://doi.acm.org/10.1145/3025453.3025820},
	doi = {10.1145/3025453.3025820},
	abstract = {Research on the viability of using crowdsourcing for HCI performance experiments has concluded that online results are similar to those achieved in the lab---at least for desktop interactions. However, mobile devices, the most popular form of online access today, may be more problematic due to variability in the user's posture and in movement of the device. To assess this possibility, we conducted two experiments with 30 lab-based and 303 crowdsourced participants using basic mouse and touchscreen tasks. Our findings show that: (1) separately analyzing the crowd and lab data yields different study conclusions-touchscreen input was significantly less error prone than mouse input in the lab but more error prone online; (2) age-matched crowdsourced participants were significantly faster and less accurate than their lab-based counterparts, contrasting past work; (3) variability in mobile device movement and orientation increased as experimenter control decreased--a potential factor affecting the touchscreen error differences. This study cautions against assuming that crowdsourced data for performance experiments will directly reflect lab-based data, particularly for mobile devices.},
	urldate = {2019-11-18},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Findlater, Leah and Zhang, Joan and Froehlich, Jon E. and Moffatt, Karyn},
	year = {2017},
	note = {event-place: Denver, Colorado, USA},
	keywords = {crowdsourcing, human performance, input devices, mobile},
	pages = {6813--6824}
}

@inproceedings{chen_pairwise_2013,
	address = {Rome, Italy},
	title = {Pairwise ranking aggregation in a crowdsourced setting},
	isbn = {978-1-4503-1869-3},
	url = {http://dl.acm.org/citation.cfm?doid=2433396.2433420},
	doi = {10.1145/2433396.2433420},
	language = {en},
	urldate = {2019-11-18},
	booktitle = {Proceedings of the sixth {ACM} international conference on {Web} search and data mining - {WSDM} '13},
	publisher = {ACM Press},
	author = {Chen, Xi and Bennett, Paul N. and Collins-Thompson, Kevyn and Horvitz, Eric},
	year = {2013},
	pages = {193}
}

@article{jamieson_active_nodate,
	title = {Active {Ranking} using {Pairwise} {Comparisons}},
	abstract = {This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of n objects can be identiﬁed by standard sorting methods using n log2 n pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Speciﬁcally, we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reﬂect their relative distances from a common reference point in Rd. We show that under this assumption the number of possible rankings grows like n2d and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis.},
	language = {en},
	author = {Jamieson, Kevin G and Nowak, Robert D},
	pages = {17}
}

@article{xu_hodgerank_2017,
	title = {{HodgeRank} with {Information} {Maximization} for {Crowdsourced} {Pairwise} {Ranking} {Aggregation}},
	url = {http://arxiv.org/abs/1711.05957},
	abstract = {Recently, crowdsourcing has emerged as an effective paradigm for human-powered large scale problem solving in various domains. However, task requester usually has a limited amount of budget, thus it is desirable to have a policy to wisely allocate the budget to achieve better quality. In this paper, we study the principle of information maximization for active sampling strategies in the framework of HodgeRank, an approach based on Hodge Decomposition of pairwise ranking data with multiple workers. The principle exhibits two scenarios of active sampling: Fisher information maximization that leads to unsupervised sampling based on a sequential maximization of graph algebraic connectivity without considering labels; and Bayesian information maximization that selects samples with the largest information gain from prior to posterior, which gives a supervised sampling involving the labels collected. Experiments show that the proposed methods boost the sampling efficiency as compared to traditional sampling schemes and are thus valuable to practical crowdsourcing experiments.},
	urldate = {2019-11-18},
	journal = {arXiv:1711.05957 [stat]},
	author = {Xu, Qianqian and Xiong, Jiechao and Chen, Xi and Huang, Qingming and Yao, Yuan},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.05957},
	keywords = {Statistics - Machine Learning}
}

@inproceedings{pfeiffer_adaptive_2012,
	title = {Adaptive {Polling} for {Information} {Aggregation}},
	abstract = {The flourishing of online labor markets such as Amazon Mechanical Turk (MTurk) makes it easy to recruit many workers for solving small tasks. We study whether information elicitation and aggregation over a combinatorial space can be achieved by integrating small pieces of potentially imprecise information, gathered from a large number of workers through simple, one-shot interactions in an online labor market. We consider the setting of predicting the ranking of n competing candidates, each having a hidden underlying strength parameter. At each step, our method estimates the strength parameters from the collected pairwise comparison data and adaptively chooses another pairwise comparison question for the next recruited worker. Through an MTurk experiment, we show that the adaptive method effectively elicits and aggregates information, outperforming a naive method using a random pairwise comparison question at each step.},
	booktitle = {{AAAI}},
	author = {Pfeiffer, Thomas and Gao, Xi Alice and Chen, Yiling and Mao, Andrew and Rand, David G.},
	year = {2012},
	keywords = {Amazon Mechanical Turk, Interaction, The Turk}
}

@misc{noauthor_pfeiffer_nodate,
	title = {Pfeiffer},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/4747},
	urldate = {2019-11-18}
}

@inproceedings{li_subjective_2013,
	address = {Seoul, South Korea},
	title = {{SUBJECTIVE} {ASSESSMENT} {METHODOLOGY} {FOR} {PREFERENCE} {OF} {EXPERIENCE} {IN} {3DTV}},
	url = {https://hal.archives-ouvertes.fr/hal-00860258},
	abstract = {The measurement of the Quality of Experience (QoE) in 3DTV re- cently became an important research topic as it relates to the devel- opment of the 3D industry. Pair comparison is a reliable method as it is easier for the observers to provide their preference on a pair rather than give an absolute scale value to a stimulus. The QoE measured by pair comparison is thus called "Preference of Experience (PoE)". In this paper, we introduce some efficient designs for pair compari- son which can reduce the number of comparisons. The constraints of the presentation order of the stimuli in pair comparison test are listed. Finally, some analysis methods for pair comparison data are provided accompanied with some examples from the studies of the measurement of PoE.},
	urldate = {2019-11-18},
	booktitle = {11th {IEEE} {IVMSP} {Workshop} : {3D} {Image}/{Video} {Technologies} and {Applications}},
	author = {Li, Jing and Barkowsky, Marcus and Le Callet, Patrick},
	month = jun,
	year = {2013},
	keywords = {3DTV, Paired comparison, Preference of Experience, Quality of Experience, efficient methods},
	pages = {pp.1--4}
}

@inproceedings{li_boosting_2013,
	title = {Boosting paired comparison methodology in measuring visual discomfort of {3DTV}: performances of three different designs},
	volume = {8648},
	shorttitle = {Boosting paired comparison methodology in measuring visual discomfort of {3DTV}},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8648/86481V/Boosting-paired-comparison-methodology-in-measuring-visual-discomfort-of-3DTV/10.1117/12.2002075.short},
	doi = {10.1117/12.2002075},
	abstract = {The pair comparison method is often recommended in subjective experiments because of the reliability of the obtained results. However, a drawback of this method is that the number of comparisons increases exponentially with the number of stimuli, which limits its usability for a large number of stimuli. Several design methods that aim to reduce the number of comparisons were proposed in the literature. However, their performances in the context of 3DTV should be evaluated carefully due to the fact that the results obtained from a paired comparison experiment in 3DTV may be influenced by two important factors. One is the observation error from observer's attentiveness, in particular inverting the vote. The second factor concerns the dependence on the context in which the evaluation takes place. In this study, three design methods, namely Full Paired Comparison method (FPC), Square Design method (SD) and the Adaptive Square Design method (ASD) were evaluated by subjective visual discomfort experiment in 3DTV. The results from the FPC method were considered as the ground truth. Comparing with the ground truth, the ASD method provided the most accurate results with a given number of trials. It also showed the highest robustness against observation errors and interdependence of comparisons. Due to the efficiency of the ASD method, paired comparison experiments become feasible with a reasonably large number of stimuli for measuring 3DTV visual discomfort.},
	urldate = {2019-11-18},
	booktitle = {Stereoscopic {Displays} and {Applications} {XXIV}},
	publisher = {International Society for Optics and Photonics},
	author = {Li, Jing and Barkowsky, Marcus and Callet, Patrick Le},
	month = mar,
	year = {2013},
	pages = {86481V}
}

@inproceedings{silverstein_quantifying_1998,
	title = {Quantifying {Perceptual} {Image} {Quality}},
	abstract = {This paper describes a more efficient paired comparison method that reduces the number of trials necessary for converting a table of paired comparisons into scalar data. Instead of comparing every pair of samples (the complete method), a partial method is used that makes more comparisons between closer samples than between more distant samples. A sorting algorithm is used to efficiently order the samples with paired comparisons, and each comparison is recorded. When the sorting is completed, more trials will have been conducted between closer samples than between distant samples. A regression is used to scale the resulting comparison matrix into a one dimensional perceptual quality estimate.},
	booktitle = {{PICS}},
	author = {Silverstein, D. Amnon and Farrell, Joyce E.},
	year = {1998},
	keywords = {Image quality, Sorting algorithm}
}

@inproceedings{xu_online_2012,
	address = {New York, NY, USA},
	series = {{MM} '12},
	title = {Online {Crowdsourcing} {Subjective} {Image} {Quality} {Assessment}},
	isbn = {978-1-4503-1089-5},
	url = {http://doi.acm.org/10.1145/2393347.2393400},
	doi = {10.1145/2393347.2393400},
	abstract = {Recently, HodgeRank on random graphs has been proposed as an effective framework for multimedia quality assessment problem based on paired comparison method. With the random design on large graphs, it is particularly suitable for large scale crowdsourcing experiments on Internet. However, to make it more practical toward this purpose, it is necessary to develop online algorithms to deal with sequential or streaming data. In this paper, we propose an online rating scheme based on HodgeRank on random graphs, to assess image quality when assessors and image pairs enter the system in a sequential way in a crowdsourceable scenario. The scheme is shown in both theory and experiments to be effective by exhibiting similar performance to batch learning under the Erdös-Rényi random graph model for sampling. It enables us to derive global rating and monitor intrinsic inconsistency in the real time. We demonstrate the effectiveness of the proposed framework on LIVE and IVC databases.},
	urldate = {2019-11-18},
	booktitle = {Proceedings of the 20th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Xu, Qianqian and Huang, Qingming and Yao, Yuan},
	year = {2012},
	note = {event-place: Nara, Japan},
	keywords = {crowdsourcing, hodgerank, online, paired comparison, persistent homology, random graphs, subjective image quality assessment, topology evolution, triangular curl},
	pages = {359--368}
}

@article{dykstra_rank_1960,
	title = {Rank {Analysis} of {Incomplete} {Block} {Designs}: {A} {Method} of {Paired} {Comparisons} {Employing} {Unequal} {Repetitions} on {Pairs}},
	volume = {16},
	issn = {0006-341X},
	shorttitle = {Rank {Analysis} of {Incomplete} {Block} {Designs}},
	url = {www.jstor.org/stable/2527550},
	doi = {10.2307/2527550},
	number = {2},
	urldate = {2019-11-18},
	journal = {Biometrics},
	author = {Dykstra, Otto},
	year = {1960},
	pages = {176--188}
}

@book{bradley_rank_1952,
	address = {Blacksburg, Va.},
	title = {The rank analysis of incomplete block designs 1: the method of paired comparisons},
	shorttitle = {The rank analysis of incomplete block designs 1},
	language = {English},
	publisher = {Virginia Agricultural Experiment Station},
	author = {Bradley, R. A and Terry, M. E},
	year = {1952},
	note = {OCLC: 48031947}
}

@article{thurstone_law_1927,
	title = {A law of comparative judgment},
	volume = {34},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/h0070288},
	abstract = {A new psychological law, called the law of comparative judgment, is presented with some of its special applications in the measurement of psychological values. This law is applicable not only to the comparison of physical stimulus intensities but also to qualitative comparative judgments, such as those of excellence of specimens in an educational scale. It should be possible also to verify it on comparative judgments which involve simultaneous and successive contrast. The law is stated as follows:[Equation omitted]in which S1 and S2 are the psychological scale values of the two compared stimuli; x12 is the sigma value corresponding to the proportion of judgments p1 {\textgreater} p2. ς1 is the discriminal dispersion of stimulus R1 and ς2 is the dispersion of stimulus R2. r is the correlation between the discriminal deviations of R1 and R2 in the same judgment. This law is basic for work on Weber's and Fechner's laws, applies to the judgments of a single observer who compares a series of stimuli by the method of paired comparisons when no "equal" judgments are allowed, and is a rational equation for the method of constant stimuli. The law is then applied to five cases each of which involves different assumptions and different degrees of simplification of the law for practical use. The weighting of the observation equations is discussed because the observation equations obtained with the five cases are not of the same reliability and hence should not be equally weighted. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Psychological Review},
	author = {Thurstone, L. L.},
	year = {1927},
	keywords = {Judgment, Values},
	pages = {273--286}
}

@article{mallows_non-null_1957,
	title = {{NON}-{NULL} {RANKING} {MODELS}. {I}},
	volume = {44},
	issn = {0006-3444},
	url = {https://academic.oup.com/biomet/article/44/1-2/114/269788},
	doi = {10.1093/biomet/44.1-2.114},
	abstract = {C. L. MALLOWS;  NON-NULL RANKING MODELS. I, Biometrika, Volume 44, Issue 1-2, 1 June 1957, Pages 114–130, https://doi.org/10.1093/biomet/44.1-2.114},
	language = {en},
	number = {1-2},
	urldate = {2019-11-18},
	journal = {Biometrika},
	author = {Mallows, C. L.},
	month = jun,
	year = {1957},
	pages = {114--130}
}

@book{luce_individual_2012,
	title = {Individual {Choice} {Behavior}: {A} {Theoretical} {Analysis}},
	isbn = {978-0-486-15339-1},
	shorttitle = {Individual {Choice} {Behavior}},
	abstract = {This influential treatise presents upper-level undergraduates and graduate students with a mathematical analysis of choice behavior. It begins with the statement of a general axiom upon which the rest of the book rests; the following three chapters, which may be read independently of each other, are devoted to applications of the theory to substantive problems: psychophysics, utility, and learning.Applications to psychophysics include considerations of time- and space-order effects, the Fechnerian assumption, the power law and its relation to discrimination data, interaction of continua, discriminal processes, signal detectability theory, and ranking of stimuli. The next major theme, utility theory, features unusual results that suggest an experiment to test the theory. The final chapters explore learning-related topics, analyzing the stochastic theories of learning as the basic approach—with the exception that distributions of response strengths are assumed to be transformed rather than response probabilities. The author arrives at three classes of learning operators, both linear and nonlinear, and the text concludes with a useful series of appendixes.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Luce, R. Duncan},
	month = jun,
	year = {2012},
	note = {Google-Books-ID: ERQsKkPiKkkC},
	keywords = {Mathematics / Probability \& Statistics / General}
}

@article{plackett_analysis_1975,
	title = {The {Analysis} of {Permutations}},
	volume = {24},
	issn = {0035-9254},
	url = {www.jstor.org/stable/2346567},
	doi = {10.2307/2346567},
	abstract = {A probability distribution is defined over the r! permutations of r objects in such a way as to incorporate up to r! - 1 parameters. Problems of estimation and testing are considered. The results are applied to data on voting at elections and beanstores.},
	number = {2},
	urldate = {2019-11-18},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Plackett, R. L.},
	year = {1975},
	pages = {193--202}
}

@article{emerson_original_2013,
	title = {The original {Borda} count and partial voting},
	volume = {40},
	url = {https://ideas.repec.org/a/spr/sochwe/v40y2013i2p353-358.html},
	abstract = {In a Borda count, bc, M. de Borda suggested the last preference cast should receive 1 point, the voter’s penultimate ranking should get 2 points, and so on. Today, however, points are often awarded to (first, second,..., last) preferences cast as per (n, n−1, ..., 1) or more frequently, (n −1, n−2,..., 0). If partial voting is allowed, and if a first preference is to be given n or n − 1 points regardless of how many preferences the voter casts, he/she will be incentivised to rank only one option/candidate. If everyone acts in this way, the bc metamorphoses into a plurality vote... which de Borda criticized at length. If all the voters submit full ballots, the outcome—social choice or ranking—will be the same under any of the above three counting procedures. In the event of one or more persons submitting a partial vote, however, outcomes may vary considerably. This preliminary paper suggests research should consider partial voting. The author examines the consequences of the various rules so far advocated and then purports that M. de Borda, in using his formula, was perhaps more astute than the science has hitherto recognised. Copyright Springer-Verlag 2013},
	language = {en},
	number = {2},
	urldate = {2019-11-18},
	journal = {Social Choice and Welfare},
	author = {Emerson, Peter},
	year = {2013},
	pages = {353--358}
}

@misc{noauthor_when_nodate,
	title = {When {Challenger} {Players} {Get} {Creative}... - {YouTube}},
	url = {https://www.youtube.com/watch?v=Q4YjwvLbkPE},
	urldate = {2019-11-16}
}

@article{israr_feel_2014,
	title = {Feel {Effects}: {Enriching} {Storytelling} with {Haptic} {Feedback}},
	volume = {11},
	issn = {15443558},
	shorttitle = {Feel {Effects}},
	url = {http://dl.acm.org/citation.cfm?doid=2663596.2641570},
	doi = {10.1145/2641570},
	language = {en},
	number = {3},
	urldate = {2019-11-15},
	journal = {ACM Transactions on Applied Perception},
	author = {Israr, Ali and Zhao, Siyan and Schwalje, Kaitlyn and Klatzky, Roberta and Lehman, Jill},
	month = sep,
	year = {2014},
	pages = {1--17}
}

@misc{noauthor_picard_nodate,
	title = {picard 1995 - {Recherche} {Google}},
	url = {https://www.google.com/search?client=ubuntu&channel=fs&q=picard+1995&ie=utf-8&oe=utf-8},
	urldate = {2019-11-13}
}

@article{picard_mit_nodate,
	title = {{MIT} {Media} {Laboratory}; {Perceptual} {Computing}; 20 {Ames} {St}., {Cambridge}, {MA} 02139 picard@media.mit.edu, http://www.media.mit.edu/˜picard/},
	abstract = {Computers are beginning to acquire the ability to express and recognize aﬀect, and may soon be given the ability to “have emotions.” The essential role of emotion in both human cognition and perception, as demonstrated by recent neurological studies, indicates that aﬀective computers should not only provide better performance in assisting humans, but also might enhance computers’ abilities to make decisions. This paper presents and discusses key issues in “aﬀective computing,” computing that relates to, arises from, or inﬂuences emotions. Models are suggested for computer recognition of human emotion, and new applications are presented for computerassisted learning, perceptual information retrieval, arts and entertainment, and human health and interaction. Aﬀective computing, coupled with new wearable computers, will also provide the ability to gather new data necessary for advances in emotion and cognition theory.},
	language = {en},
	author = {Picard, R W},
	pages = {16}
}

@inproceedings{ye_personalized_2017,
	address = {Portland, Oregon, USA},
	title = {Personalized {Feedback} {Versus} {Money}: {The} {Effect} on {Reliability} of {Subjective} {Data} in {Online} {Experimental} {Platforms}},
	isbn = {978-1-4503-4688-7},
	shorttitle = {Personalized {Feedback} {Versus} {Money}},
	url = {http://dl.acm.org/citation.cfm?doid=3022198.3026339},
	doi = {10.1145/3022198.3026339},
	abstract = {We compared the data reliability on a subjective task from two platforms: Amazon's Mechanical Turk (MTurk) and LabintheWild. MTurk incentivizes participants with financial compensation while LabintheWild provides participants with personalized feedback. LabintheWild was found to produce higher data reliability than MTurk. Our findings suggest that online experiment platforms providing feedback in exchange for study participation can produce more reliable data in subjective preference tasks than those offering financial compensation.},
	language = {en},
	urldate = {2019-11-05},
	booktitle = {Companion of the 2017 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing} - {CSCW} '17 {Companion}},
	publisher = {ACM Press},
	author = {Ye, Teng and Reinecke, Katharina and Robert, Lionel P.},
	year = {2017},
	pages = {343--346}
}

@misc{noauthor_hcomp_nodate,
	title = {{HCOMP} 2018},
	url = {https://www.humancomputation.com/2018/past%20meetings.html},
	urldate = {2019-10-18}
}

@inproceedings{law_crowdsourcing_2017,
	address = {New York, NY, USA},
	series = {{CSCW} '17},
	title = {Crowdsourcing {As} a {Tool} for {Research}: {Implications} of {Uncertainty}},
	isbn = {978-1-4503-4335-0},
	shorttitle = {Crowdsourcing {As} a {Tool} for {Research}},
	url = {http://doi.acm.org/10.1145/2998181.2998197},
	doi = {10.1145/2998181.2998197},
	abstract = {Numerous crowdsourcing platforms are now available to support research as well as commercial goals. However, crowdsourcing is not yet widely adopted by researchers for generating, processing or analyzing research data. This study develops a deeper understanding of the circumstances under which crowdsourcing is a useful, feasible or desirable tool for research, as well as the factors that may influence researchers' decisions around adopting crowdsourcing technology. We conducted semi-structured interviews with 18 researchers in diverse disciplines, spanning the humanities and sciences, to illuminate how research norms and practitioners' dispositions were related to uncertainties around research processes, data, knowledge, delegation and quality. The paper concludes with a discussion of the design implications for future crowdsourcing systems to support research.},
	urldate = {2019-10-18},
	booktitle = {Proceedings of the 2017 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {ACM},
	author = {Law, Edith and Gajos, Krzysztof Z. and Wiggins, Andrea and Gray, Mary L. and Williams, Alex},
	year = {2017},
	note = {event-place: Portland, Oregon, USA},
	keywords = {citizen science, crowdsourcing for research, interviews},
	pages = {1544--1561}
}

@article{jaini_online_2016,
	title = {Online {Bayesian} {Transfer} {Learning} for {Sequential} {Data} {Modeling}},
	url = {https://openreview.net/forum?id=ByqiJIqxg},
	abstract = {We consider the problem of inferring a sequence of hidden states associated with a sequence of observations produced by an individual within a population.  Instead of learning a single sequence...},
	urldate = {2019-10-18},
	author = {Jaini, Priyank and Chen, Zhitang and Carbajal, Pablo and Law, Edith and Middleton, Laura and Regan, Kayla and Schaekermann, Mike and Trimponias, George and Tung, James and Poupart, Pascal},
	month = nov,
	year = {2016}
}

@incollection{hutchison_learning_2010,
	address = {Berlin, Heidelberg},
	title = {Learning to {Tag} from {Open} {Vocabulary} {Labels}},
	volume = {6322},
	isbn = {978-3-642-15882-7 978-3-642-15883-4},
	url = {http://link.springer.com/10.1007/978-3-642-15883-4_14},
	abstract = {Most approaches to classifying media content assume a ﬁxed, closed vocabulary of labels. In contrast, we advocate machine learning approaches which take advantage of the millions of free-form tags obtainable via online crowd-sourcing platforms and social tagging websites. The use of such open vocabularies presents learning challenges due to typographical errors, synonymy, and a potentially unbounded set of tag labels. In this work, we present a new approach that organizes these noisy tags into well-behaved semantic classes using topic modeling, and learn to predict tags accurately using a mixture of topic classes. This method can utilize an arbitrary open vocabulary of tags, reduces training time by 94\% compared to learning from these tags directly, and achieves comparable performance for classiﬁcation and superior performance for retrieval. We also demonstrate that on open vocabulary tasks, human evaluations are essential for measuring the true performance of tag classiﬁers, which traditional evaluation methods will consistently underestimate. We focus on the domain of tagging music clips, and demonstrate our results using data collected with a human computation game called TagATune.},
	language = {en},
	urldate = {2019-10-18},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer Berlin Heidelberg},
	author = {Law, Edith and Settles, Burr and Mitchell, Tom},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Balcázar, José Luis and Bonchi, Francesco and Gionis, Aristides and Sebag, Michèle},
	year = {2010},
	doi = {10.1007/978-3-642-15883-4_14},
	pages = {211--226}
}

@article{law_evaluation_2009,
	title = {{EVALUATION} {OF} {ALGORITHMS} {USING} {GAMES}: {THE} {CASE} {OF} {MUSIC} {TAGGING}},
	abstract = {Search by keyword is an extremely popular method for retrieving music. To support this, novel algorithms that automatically tag music are being developed. The conventional way to evaluate audio tagging algorithms is to compute measures of agreement between the output and the ground truth set. In this work, we introduce a new method for evaluating audio tagging algorithms on a large scale by collecting set-level judgments from players of a human computation game called TagATune. We present the design and preliminary results of an experiment comparing ﬁve algorithms using this new evaluation metric, and contrast the results with those obtained by applying several conventional agreement-based evaluation metrics.},
	language = {en},
	journal = {Oral Session},
	author = {Law, Edith and West, Kris and Mandel, Michael},
	year = {2009},
	pages = {6}
}

@misc{noauthor_edith_nodate,
	title = {Edith {Law} @ {U}.{Waterloo}},
	url = {http://edithlaw.ca/research.html},
	urldate = {2019-10-18}
}

@article{handley_comparative_nodate,
	title = {Comparative {Analysis} of {Bradley}-{Terry} and {Thurstone}-{Mosteller} {Paired} {Comparison} {Models} for {Image} {Quality} {Assessment}},
	abstract = {In image quality assessment, preference for various image processing algorithms or treatments is often determined using paired comparisons. In this experimental design, pairs of images processed by different algorithms or “treatments” are presented to a judge. The preferred treatment is selected and a tally is kept of the number of times each treatment is preferred to another. It is possible to estimate an interval scale for treatments in a hypothetical psychological space using this method.},
	language = {en},
	author = {Handley, John C and Road, Phillips},
	pages = {6}
}

@article{ailon_reconciling_nodate,
	title = {Reconciling {Real} {Scores} with {Binary} {Comparisons}: {A} {Uniﬁed} {Logistic} {Model} for {Ranking}},
	abstract = {The problem of ranking arises ubiquitously in almost every aspect of life, and in particular in Machine Learning/Information Retrieval. A statistical model for ranking predicts how humans rank subsets V of some universe U . In this work we deﬁne a statistical model for ranking that satisﬁes certain desirable properties.},
	language = {en},
	author = {Ailon, Nir},
	pages = {8}
}

@patent{dinh_wireless_2010,
	title = {Wireless haptic glove for language and information transference},
	url = {https://patents.google.com/patent/US20100134327A1/en},
	nationality = {US},
	assignee = {US Secretary of Navy},
	number = {US20100134327A1},
	urldate = {2019-05-05},
	author = {DINH, Vincent Vinh and Phan, Hoa Van and Tran, Nghia Xuan and Ceruti, Marion G. and Ton, Tu-Anh and Duffy, LorRaine},
	month = jun,
	year = {2010},
	keywords = {characters, glove, language, language characters, type}
}
@article{cazenave_nested_nodate,
	title = {Nested {Monte}-{Carlo} {Search}},
	abstract = {Many problems have a huge state space and no good heuristic to order moves so as to guide the search toward the best positions. Random games can be used to score positions and evaluate their interest. Random games can also be improved using random games to choose a move to try at each step of a game. Nested Monte-Carlo Search addresses the problem of guiding the search toward better states when there is no available heuristic. It uses nested levels of random games in order to guide the search. The algorithm is studied theoretically on simple abstract problems and applied successfully to three different games: Morpion Solitaire, SameGame and 16x16 Sudoku.},
	language = {en},
	author = {Cazenave, Tristan},
	pages = {6}
}

@article{guo_long_2017,
	title = {Long {Text} {Generation} via {Adversarial} {Training} with {Leaked} {Information}},
	url = {http://arxiv.org/abs/1709.08624},
	abstract = {Automatically generating coherent and semantically meaningful text has many applications in machine translation, dialogue systems, image captioning, etc. Recently, by combining with policy gradient, Generative Adversarial Nets (GAN) that use a discriminative model to guide the training of the generative model as a reinforcement learning policy has shown promising results in text generation. However, the scalar guiding signal is only available after the entire text has been generated and lacks intermediate information about text structure during the generative process. As such, it limits its success when the length of the generated text samples is long (more than 20 words). In this paper, we propose a new framework, called LeakGAN, to address the problem for long text generation. We allow the discriminative net to leak its own high-level extracted features to the generative net to further help the guidance. The generator incorporates such informative signals into all generation steps through an additional Manager module, which takes the extracted features of current generated words and outputs a latent vector to guide the Worker module for next-word generation. Our extensive experiments on synthetic data and various real-world tasks with Turing test demonstrate that LeakGAN is highly effective in long text generation and also improves the performance in short text generation scenarios. More importantly, without any supervision, LeakGAN would be able to implicitly learn sentence structures only through the interaction between Manager and Worker.},
	urldate = {2019-04-25},
	journal = {arXiv:1709.08624 [cs]},
	author = {Guo, Jiaxian and Lu, Sidi and Cai, Han and Zhang, Weinan and Yu, Yong and Wang, Jun},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.08624},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning}
}

@article{lin_adversarial_2017,
	title = {Adversarial {Ranking} for {Language} {Generation}},
	url = {http://arxiv.org/abs/1705.11001},
	abstract = {Generative adversarial networks (GANs) have great successes on synthesizing data. However, the existing GANs restrict the discriminator to be a binary classifier, and thus limit their learning capacity for tasks that need to synthesize output with rich structures such as natural language descriptions. In this paper, we propose a novel generative adversarial network, RankGAN, for generating high-quality language descriptions. Rather than training the discriminator to learn and assign absolute binary predicate for individual data sample, the proposed RankGAN is able to analyze and rank a collection of human-written and machine-written sentences by giving a reference group. By viewing a set of data samples collectively and evaluating their quality through relative ranking scores, the discriminator is able to make better assessment which in turn helps to learn a better generator. The proposed RankGAN is optimized through the policy gradient technique. Experimental results on multiple public datasets clearly demonstrate the effectiveness of the proposed approach.},
	urldate = {2019-04-25},
	journal = {arXiv:1705.11001 [cs]},
	author = {Lin, Kevin and Li, Dianqi and He, Xiaodong and Zhang, Zhengyou and Sun, Ming-Ting},
	month = may,
	year = {2017},
	note = {arXiv: 1705.11001},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning}
}

@article{zhang_sequence_2018,
	title = {Sequence {Generation} with {Guider} {Network}},
	url = {http://arxiv.org/abs/1811.00696},
	abstract = {Sequence generation with reinforcement learning (RL) has received significant attention recently. However, a challenge with such methods is the sparse-reward problem in the RL training process, in which a scalar guiding signal is often only available after an entire sequence has been generated. This type of sparse reward tends to ignore the global structural information of a sequence, causing generation of sequences that are semantically inconsistent. In this paper, we present a model-based RL approach to overcome this issue. Specifically, we propose a novel guider network to model the sequence-generation environment, which can assist next-word prediction and provide intermediate rewards for generator optimization. Extensive experiments show that the proposed method leads to improved performance for both unconditional and conditional sequence-generation tasks.},
	urldate = {2019-04-25},
	journal = {arXiv:1811.00696 [cs]},
	author = {Zhang, Ruiyi and Chen, Changyou and Gan, Zhe and Wang, Wenlin and Chen, Liqun and Shen, Dinghan and Wang, Guoyin and Carin, Lawrence},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.00696},
	keywords = {Computer Science - Computation and Language}
}

@article{balagopalan_regan:_2018,
	title = {{ReGAN}: {RE}[{LAX}{\textbar}{BAR}{\textbar}{INFORCE}] based {Sequence} {Generation} using {GANs}},
	shorttitle = {{ReGAN}},
	url = {http://arxiv.org/abs/1805.02788},
	abstract = {Generative Adversarial Networks (GANs) have seen steep ascension to the peak of ML research zeitgeist in recent years. Mostly catalyzed by its success in the domain of image generation, the technique has seen wide range of adoption in a variety of other problem domains. Although GANs have had a lot of success in producing more realistic images than other approaches, they have only seen limited use for text sequences. Generation of longer sequences compounds this problem. Most recently, SeqGAN (Yu et al., 2017) has shown improvements in adversarial evaluation and results with human evaluation compared to a MLE based trained baseline. The main contributions of this paper are three-fold: 1. We show results for sequence generation using a GAN architecture with efficient policy gradient estimators, 2. We attain improved training stability, and 3. We perform a comparative study of recent unbiased low variance gradient estimation techniques such as REBAR (Tucker et al., 2017), RELAX (Grathwohl et al., 2018) and REINFORCE (Williams, 1992). Using a simple grammar on synthetic datasets with varying length, we indicate the quality of sequences generated by the model.},
	urldate = {2019-04-25},
	journal = {arXiv:1805.02788 [cs, stat]},
	author = {Balagopalan, Aparna and Gorti, Satya and Ravaut, Mathieu and Saqur, Raeid},
	month = may,
	year = {2018},
	note = {arXiv: 1805.02788},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{che_maximum-likelihood_2017,
	title = {Maximum-{Likelihood} {Augmented} {Discrete} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1702.07983},
	abstract = {Despite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted. The fundamental reason is the difficulty of back-propagation through discrete random variables combined with the inherent instability of the GAN training objective. To address these problems, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks. Instead of directly optimizing the GAN objective, we derive a novel and low-variance objective using the discriminator's output that follows corresponds to the log-likelihood. Compared with the original, the new objective is proved to be consistent in theory and beneficial in practice. The experimental results on various discrete datasets demonstrate the effectiveness of the proposed approach.},
	urldate = {2019-04-25},
	journal = {arXiv:1702.07983 [cs]},
	author = {Che, Tong and Li, Yanran and Zhang, Ruixiang and Hjelm, R. Devon and Li, Wenjie and Song, Yangqiu and Bengio, Yoshua},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.07983},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning}
}

@article{guimaraes_objective-reinforced_2017,
	title = {Objective-{Reinforced} {Generative} {Adversarial} {Networks} ({ORGAN}) for {Sequence} {Generation} {Models}},
	url = {http://arxiv.org/abs/1705.10843},
	abstract = {In unsupervised data generation tasks, besides the generation of a sample based on previous observations, one would often like to give hints to the model in order to bias the generation towards desirable metrics. We propose a method that combines Generative Adversarial Networks (GANs) and reinforcement learning (RL) in order to accomplish exactly that. While RL biases the data generation process towards arbitrary metrics, the GAN component of the reward function ensures that the model still remembers information learned from data. We build upon previous results that incorporated GANs and RL in order to generate sequence data and test this model in several settings for the generation of molecules encoded as text sequences (SMILES) and in the context of music generation, showing for each case that we can effectively bias the generation process towards desired metrics.},
	urldate = {2019-04-25},
	journal = {arXiv:1705.10843 [cs, stat]},
	author = {Guimaraes, Gabriel Lima and Sanchez-Lengeling, Benjamin and Outeiral, Carlos and Farias, Pedro Luis Cunha and Aspuru-Guzik, Alán},
	month = may,
	year = {2017},
	note = {arXiv: 1705.10843},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_[1705.10843]_nodate,
	title = {[1705.10843] {Objective}-{Reinforced} {Generative} {Adversarial} {Networks} ({ORGAN}) for {Sequence} {Generation} {Models}},
	url = {https://arxiv.org/abs/1705.10843},
	urldate = {2019-04-25}
}

@misc{noauthor_[1705.10843]_nodate-1,
	title = {[1705.10843] {Objective}-{Reinforced} {Generative} {Adversarial} {Networks} ({ORGAN}) for {Sequence} {Generation} {Models}},
	url = {https://arxiv.org/abs/1705.10843},
	urldate = {2019-04-25}
}

@article{semeniuta_hybrid_2017,
	title = {A {Hybrid} {Convolutional} {Variational} {Autoencoder} for {Text} {Generation}},
	url = {http://arxiv.org/abs/1702.02390},
	abstract = {In this paper we explore the effect of architectural choices on learning a Variational Autoencoder (VAE) for text generation. In contrast to the previously introduced VAE model for text where both the encoder and decoder are RNNs, we propose a novel hybrid architecture that blends fully feed-forward convolutional and deconvolutional components with a recurrent language model. Our architecture exhibits several attractive properties such as faster run time and convergence, ability to better handle long sequences and, more importantly, it helps to avoid some of the major difficulties posed by training VAE models on textual data.},
	urldate = {2019-04-25},
	journal = {arXiv:1702.02390 [cs]},
	author = {Semeniuta, Stanislau and Severyn, Aliaksei and Barth, Erhardt},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.02390},
	keywords = {Computer Science - Computation and Language}
}

@article{rajeswar_adversarial_2017,
	title = {Adversarial {Generation} of {Natural} {Language}},
	url = {http://arxiv.org/abs/1705.10929},
	abstract = {Generative Adversarial Networks (GANs) have gathered a lot of attention from the computer vision community, yielding impressive results for image generation. Advances in the adversarial generation of natural language from noise however are not commensurate with the progress made in generating images, and still lag far behind likelihood based methods. In this paper, we take a step towards generating natural language with a GAN objective alone. We introduce a simple baseline that addresses the discrete output space problem without relying on gradient estimators and show that it is able to achieve state-of-the-art results on a Chinese poem generation dataset. We present quantitative results on generating sentences from context-free and probabilistic context-free grammars, and qualitative language modeling results. A conditional version is also described that can generate sequences conditioned on sentence characteristics.},
	urldate = {2019-04-25},
	journal = {arXiv:1705.10929 [cs, stat]},
	author = {Rajeswar, Sai and Subramanian, Sandeep and Dutil, Francis and Pal, Christopher and Courville, Aaron},
	month = may,
	year = {2017},
	note = {arXiv: 1705.10929},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@misc{noauthor_[1705.10929]_nodate,
	title = {[1705.10929] {Adversarial} {Generation} of {Natural} {Language}},
	url = {https://arxiv.org/abs/1705.10929},
	urldate = {2019-04-25}
}

@article{press_language_2017,
	title = {Language {Generation} with {Recurrent} {Generative} {Adversarial} {Networks} without {Pre}-training},
	url = {http://arxiv.org/abs/1706.01399},
	abstract = {Generative Adversarial Networks (GANs) have shown great promise recently in image generation. Training GANs for language generation has proven to be more difficult, because of the non-differentiable nature of generating text with recurrent neural networks. Consequently, past work has either resorted to pre-training with maximum-likelihood or used convolutional networks for generation. In this work, we show that recurrent neural networks can be trained to generate text with GANs from scratch using curriculum learning, by slowly teaching the model to generate sequences of increasing and variable length. We empirically show that our approach vastly improves the quality of generated sequences compared to a convolutional baseline.},
	urldate = {2019-04-25},
	journal = {arXiv:1706.01399 [cs]},
	author = {Press, Ofir and Bar, Amir and Bogin, Ben and Berant, Jonathan and Wolf, Lior},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.01399},
	keywords = {Computer Science - Computation and Language}
}

@article{semeniuta_accurate_2018,
	title = {On {Accurate} {Evaluation} of {GANs} for {Language} {Generation}},
	url = {http://arxiv.org/abs/1806.04936},
	abstract = {Generative Adversarial Networks (GANs) are a promising approach to language generation. The latest works introducing novel GAN models for language generation use n-gram based metrics for evaluation and only report single scores of the best run. In this paper, we argue that this often misrepresents the true picture and does not tell the full story, as GAN models can be extremely sensitive to the random initialization and small deviations from the best hyperparameter choice. In particular, we demonstrate that the previously used BLEU score is not sensitive to semantic deterioration of generated texts and propose alternative metrics that better capture the quality and diversity of the generated samples. We also conduct a set of experiments comparing a number of GAN models for text with a conventional Language Model (LM) and find that neither of the considered models performs convincingly better than the LM.},
	urldate = {2019-04-25},
	journal = {arXiv:1806.04936 [cs]},
	author = {Semeniuta, Stanislau and Severyn, Aliaksei and Gelly, Sylvain},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.04936},
	keywords = {Computer Science - Computation and Language}
}

@article{caccia_language_2018,
	title = {Language {GANs} {Falling} {Short}},
	url = {http://arxiv.org/abs/1811.02549},
	abstract = {Generating high-quality text with sufficient diversity is essential for a wide range of Natural Language Generation (NLG) tasks. Maximum-Likelihood (MLE) models trained with teacher forcing have consistently been reported as weak baselines, where poor performance is attributed to exposure bias (Bengio et al., 2015; Ranzato et al., 2015); at inference time, the model is fed its own prediction instead of a ground-truth token, which can lead to accumulating errors and poor samples. This line of reasoning has led to an outbreak of adversarial based approaches for NLG, on the account that GANs do not suffer from exposure bias. In this work, we make several surprising observations which contradict common beliefs. First, we revisit the canonical evaluation framework for NLG, and point out fundamental flaws with quality-only evaluation: we show that one can outperform such metrics using a simple, well-known temperature parameter to artificially reduce the entropy of the model's conditional distributions. Second, we leverage the control over the quality / diversity trade-off given by this parameter to evaluate models over the whole quality-diversity spectrum and find MLE models constantly outperform the proposed GAN variants over the whole quality-diversity space. Our results have several implications: 1) The impact of exposure bias on sample quality is less severe than previously thought, 2) temperature tuning provides a better quality / diversity trade-off than adversarial training while being easier to train, easier to cross-validate, and less computationally expensive. Code to reproduce the experiments is available at github.com/pclucas14/GansFallingShort},
	urldate = {2019-04-25},
	journal = {arXiv:1811.02549 [cs]},
	author = {Caccia, Massimo and Caccia, Lucas and Fedus, William and Larochelle, Hugo and Pineau, Joelle and Charlin, Laurent},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.02549},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning}
}

@article{bachman_data_2015,
	title = {Data {Generation} as {Sequential} {Decision} {Making}},
	url = {http://arxiv.org/abs/1506.03504},
	abstract = {We connect a broad class of generative models through their shared reliance on sequential decision making. Motivated by this view, we develop extensions to an existing model, and then explore the idea further in the context of data imputation -- perhaps the simplest setting in which to investigate the relation between unconditional and conditional generative modelling. We formulate data imputation as an MDP and develop models capable of representing effective policies for it. We construct the models using neural networks and train them using a form of guided policy search. Our models generate predictions through an iterative process of feedback and refinement. We show that this approach can learn effective policies for imputation problems of varying difficulty and across multiple datasets.},
	urldate = {2019-04-25},
	journal = {arXiv:1506.03504 [cs, stat]},
	author = {Bachman, Philip and Precup, Doina},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.03504},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{montahaei_jointly_2019,
	title = {Jointly {Measuring} {Diversity} and {Quality} in {Text} {Generation} {Models}},
	url = {http://arxiv.org/abs/1904.03971},
	abstract = {Text generation is an important Natural Language Processing task with various applications. Although several metrics have already been introduced to evaluate the text generation methods, each of them has its own shortcomings. The most widely used metrics such as BLEU only consider the quality of generated sentences and neglect their diversity. For example, repeatedly generation of only one high quality sentence would result in a high BLEU score. On the other hand, the more recent metric introduced to evaluate the diversity of generated texts known as Self-BLEU ignores the quality of generated texts. In this paper, we propose metrics to evaluate both the quality and diversity simultaneously by approximating the distance of the learned generative model and the real data distribution. For this purpose, we first introduce a metric that approximates this distance using n-gram based measures. Then, a feature-based measure which is based on a recent highly deep model trained on a large text corpus called BERT is introduced. Finally, for oracle training mode in which the generator's density can also be calculated, we propose to use the distance measures between the corresponding explicit distributions. Eventually, the most popular and recent text generation models are evaluated using both the existing and the proposed metrics and the preferences of the proposed metrics are determined.},
	urldate = {2019-04-25},
	journal = {arXiv:1904.03971 [cs, stat]},
	author = {Montahaei, Ehsan and Alihosseini, Danial and Baghshah, Mahdieh Soleymani},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.03971},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{nie_relgan:_2018,
	title = {{RelGAN}: {Relational} {Generative} {Adversarial} {Networks} for {Text} {Generation}},
	shorttitle = {{RelGAN}},
	url = {https://openreview.net/forum?id=rJedV3R5tm},
	abstract = {Generative adversarial networks (GANs) have achieved great success at generating realistic images. However, the text generation still remains a challenging task for modern GAN architectures. In...},
	urldate = {2019-04-25},
	author = {Nie, Weili and Narodytska, Nina and Patel, Ankit},
	month = sep,
	year = {2018}
}

@article{toyama_expert-based_2018,
	title = {Expert-based reward function training: the novel method to train sequence generators},
	shorttitle = {Expert-based reward function training},
	url = {https://openreview.net/forum?id=ByuM23RUG},
	abstract = {The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.
  In this paper, we propose expert-based reward function training: the novel...},
	urldate = {2019-04-25},
	author = {Toyama, Joji and Iwasawa, Yusuke and Nakayama, Kotaro and Matsuo, Yutaka},
	month = feb,
	year = {2018}
}

@article{tevet_evaluating_2018,
	title = {Evaluating {Text} {GANs} as {Language} {Models}},
	url = {http://arxiv.org/abs/1810.12686},
	abstract = {Generative Adversarial Networks (GANs) are a promising approach for text generation that, unlike traditional language models (LM), does not suffer from the problem of ``exposure bias''. However, A major hurdle for understanding the potential of GANs for text generation is the lack of a clear evaluation metric. In this work, we propose to approximate the distribution of text generated by a GAN, which permits evaluating them with traditional probability-based LM metrics. We apply our approximation procedure on several GAN-based models and show that they currently perform substantially worse than state-of-the-art LMs. Our evaluation procedure promotes better understanding of the relation between GANs and LMs, and can accelerate progress in GAN-based text generation.},
	urldate = {2019-04-25},
	journal = {arXiv:1810.12686 [cs]},
	author = {Tevet, Guy and Habib, Gavriel and Shwartz, Vered and Berant, Jonathan},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.12686},
	keywords = {Computer Science - Computation and Language}
}

@misc{noauthor_[1811.00696]_nodate,
	title = {[1811.00696] {Sequence} {Generation} with {Guider} {Network}},
	url = {https://arxiv.org/abs/1811.00696#},
	urldate = {2019-04-25}
}

@article{montahaei_jointly_2019-1,
	title = {Jointly {Measuring} {Diversity} and {Quality} in {Text} {Generation} {Models}},
	url = {http://arxiv.org/abs/1904.03971},
	abstract = {Text generation is an important Natural Language Processing task with various applications. Although several metrics have already been introduced to evaluate the text generation methods, each of them has its own shortcomings. The most widely used metrics such as BLEU only consider the quality of generated sentences and neglect their diversity. For example, repeatedly generation of only one high quality sentence would result in a high BLEU score. On the other hand, the more recent metric introduced to evaluate the diversity of generated texts known as Self-BLEU ignores the quality of generated texts. In this paper, we propose metrics to evaluate both the quality and diversity simultaneously by approximating the distance of the learned generative model and the real data distribution. For this purpose, we first introduce a metric that approximates this distance using n-gram based measures. Then, a feature-based measure which is based on a recent highly deep model trained on a large text corpus called BERT is introduced. Finally, for oracle training mode in which the generator's density can also be calculated, we propose to use the distance measures between the corresponding explicit distributions. Eventually, the most popular and recent text generation models are evaluated using both the existing and the proposed metrics and the preferences of the proposed metrics are determined.},
	urldate = {2019-04-25},
	journal = {arXiv:1904.03971 [cs, stat]},
	author = {Montahaei, Ehsan and Alihosseini, Danial and Baghshah, Mahdieh Soleymani},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.03971},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{hinton_fast_2006,
	title = {A {Fast} {Learning} {Algorithm} for {Deep} {Belief} {Nets}},
	volume = {18},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.2006.18.7.1527},
	doi = {10.1162/neco.2006.18.7.1527},
	abstract = {We show how to use “complementary priors” to eliminate the explaining away effects that make inference difﬁcult in densely-connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that ﬁne-tunes the weights using a contrastive version of the wake-sleep algorithm. After ﬁne-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classiﬁcation than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modelled by long ravines in the free-energy landscape of the top-level associative memory and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
	language = {en},
	number = {7},
	urldate = {2019-04-25},
	journal = {Neural Computation},
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
	month = jul,
	year = {2006},
	pages = {1527--1554}
}

@article{kingma_auto-encoding_2013,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2019-04-25},
	journal = {arXiv:1312.6114 [cs, stat]},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6114},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_[1312.6114]_nodate,
	title = {[1312.6114] {Auto}-{Encoding} {Variational} {Bayes}},
	url = {https://arxiv.org/abs/1312.6114},
	urldate = {2019-04-25}
}

@article{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	urldate = {2019-04-25},
	journal = {arXiv:1406.2661 [cs, stat]},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.2661},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_[1406.2661]_nodate,
	title = {[1406.2661] {Generative} {Adversarial} {Networks}},
	url = {https://arxiv.org/abs/1406.2661},
	urldate = {2019-04-25}
}

@article{yu_seqgan:_2016,
	title = {{SeqGAN}: {Sequence} {Generative} {Adversarial} {Nets} with {Policy} {Gradient}},
	shorttitle = {{SeqGAN}},
	url = {http://arxiv.org/abs/1609.05473},
	abstract = {As a new way of training generative models, Generative Adversarial Nets (GAN) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real-valued data. However, it has limitations when the goal is for generating sequences of discrete tokens. A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model. Also, the discriminative model can only assess a complete sequence, while for a partially generated sequence, it is non-trivial to balance its current score and the future one once the entire sequence has been generated. In this paper, we propose a sequence generation framework, called SeqGAN, to solve the problems. Modeling the data generator as a stochastic policy in reinforcement learning (RL), SeqGAN bypasses the generator differentiation problem by directly performing gradient policy update. The RL reward signal comes from the GAN discriminator judged on a complete sequence, and is passed back to the intermediate state-action steps using Monte Carlo search. Extensive experiments on synthetic data and real-world tasks demonstrate significant improvements over strong baselines.},
	urldate = {2019-04-25},
	journal = {arXiv:1609.05473 [cs]},
	author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.05473},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning}
}

@article{schneider_reflections_2014,
	title = {Reflections on a {WYFIWIF} {Tool} for {Eliciting} {User} {Feedback}},
	abstract = {Designing haptic phenomena is increasingly important but diﬃcult. Eliciting user feedback is particularly challenging. Direct means of sharing haptic sensations are limited, and the absence of unifying conceptual models for working with haptic sensations further restricts communication between designers and users. This is especially troublesome for pleasurable, aﬀectively targeted interactions that rely on subjective user experience. In this paper, we summarize a recently-published qualitative study evaluating mHIVE, a What-You-Feel-Is-What-I-Feel (WYFIWIF) device for the direct manipulation and communication of vibrotactile stimuli. mHIVE is designed for rapid feedback and collaborative exploration, and shows promise for providing an additional, tactile mode of communication between designers and users in support of improved haptic design.},
	language = {en},
	author = {Schneider, Oliver and MacLean, Karon},
	year = {2014},
	pages = {5}
}

@misc{clark_predictable_2017,
	title = {Predictable and distinguishable morphing of vibrotactile rhythm - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore.ieee.org/abstract/document/7989881},
	urldate = {2019-02-07},
	author = {Clark},
	year = {2017}
}

@misc{brown_first_2005,
	title = {A first investigation into the effectiveness of {Tactons} - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore.ieee.org/abstract/document/1406930},
	urldate = {2019-04-15},
	author = {Brown},
	year = {2005}
}

@article{stein_design_2017,
	title = {{DESIGN} {RECOMMENDATIONS} {FOR} {TACTONS} {IN} {TOUCH} {SCREEN} {INTERACTION}},
	abstract = {Tactons are structured tactile messages and used to transmit information to users via the tactile sense. In recent studies, tactons were tested under various conditions and their benefits were demonstrated, while tactons were mostly applied on a non-interacting part of participants’ body. In future applications, e. g. in touch screen interaction, the device itself will probably generate the tactile feedback providing it to the user’s interacting finger. Therefore, common parameters (i. e., frequency, amplitude, rhythm, roughness, waveform, and duration) in such a setting were examined and tested for discriminability in order to derive guidelines for tacton design in touch screen interaction. 51 participants took part in the experiment, which consisted of 98 randomized tasks. In each task, participants were presented two vibration signals via a touch screen and had to decide, whether signals were identical or different. 87 tasks comprised a comparison between different signals, while only one parameter was altered in a single comparison, and 11 control pair signals were identical. The overall recognition rate was 0.69 ± 0.15 but various combinations showed recognition rates above 90\%. It became clear that some parameters are more suitable in tacton design than others. Frequency and roughness achieved the best results, involving all paired comparisons which were correctly distinguished by each participant. Distinguishable levels of parameters and design recommendations were derived from the experiment, and considerations about future tacton design are presented.},
	language = {en},
	author = {Stein, Tobias and Seeger, Martin and Borys, Bernd-Burkhard and Schmidt, Ludger},
	year = {2017},
	pages = {16}
}

@article{seifi_exploiting_2017,
	series = {Multisensory {Human}-{Computer} {Interaction}},
	title = {Exploiting haptic facets: {Users}' sensemaking schemas as a path to design and personalization of experience},
	volume = {107},
	issn = {1071-5819},
	shorttitle = {Exploiting haptic facets},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581917300617},
	doi = {10.1016/j.ijhcs.2017.04.003},
	abstract = {Our poor understanding of the connection between haptic effect engineering – using controllable parameters like frequency, amplitude and rhythm – and how sensations are comprehended by end-users hinders effective design. Haptic facets (categories of attributes that characterize collection items in different ways) are a way to describe, navigate and analyze the cognitive frameworks by which users make sense of qualitative and affective characteristics of haptic sensations. Embedded in tools, they will provide designers and end-users interested in customization with a road-mapped perceptual and cognitive design space. We previously compiled five haptic facets based on how people describe vibrations: physical, sensory, emotional, metaphoric, and usage examples. Here, we report a study in which we deployed these facets to identify underlying dimensions and cross-linkages in participants' perception of a 120-item vibration library. We show that the facets are crosslinked in people's minds, and discuss three scenarios where the facet-based organizational schemes, their linkages and consequent redundancies can support design, evaluation and personalization of expressive vibrotactile effects. Finally, we report between-subject variation (individual differences) and within-subject consistency (reliability) in participants' rating and tagging patterns to inform future progress on haptic evaluation. This facet-based approach is also applicable to other kinds of haptic sensations and even other modalities, and can inform multimodal experience design through a descriptive design language shared between different modalities.},
	urldate = {2019-04-15},
	journal = {International Journal of Human-Computer Studies},
	author = {Seifi, Hasti and MacLean, Karon E.},
	month = nov,
	year = {2017},
	keywords = {Affective vibration annotations, Data collection methodology, Haptic language, Individual differences, Perceptual dimensions},
	pages = {38--61}
}

@misc{noauthor_ebscohost_nodate,
	title = {{EBSCOhost} {\textbar} 130467615 {\textbar} {DESIGN} {RECOMMENDATIONS} {FOR} {TACTONS} {IN} {TOUCH} {SCREEN} {INTERACTION}.},
	url = {http://web.a.ebscohost.com/abstract?site=ehost&scope=site&jrnl=16457641&AN=130467615&h=OwomnMAfM24c8L%2fpFundzlzkF4vcEpXo7%2fL5piTQg48XH%2flsjCiZTBXuoRtHoiKW%2ftiMZSfUfx9ONfFGS9dGgw%3d%3d&crl=c&resultLocal=ErrCrlNoResults&resultNs=Ehost&crlhashurl=login.aspx%3fdirect%3dtrue%26profile%3dehost%26scope%3dsite%26authtype%3dcrawler%26jrnl%3d16457641%26AN%3d130467615},
	urldate = {2019-04-15}
}

@inproceedings{brewster_non-visual_2004,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '04},
	title = {Non-visual {Information} {Display} {Using} {Tactons}},
	isbn = {978-1-58113-703-3},
	url = {http://doi.acm.org/10.1145/985921.985936},
	doi = {10.1145/985921.985936},
	abstract = {This paper describes a novel form of display using tactile output. Tactons, or tactile icons, are structured tactile messages that can be used to communicate message to users non visually. A range of different parameters can be used to construct Tactons, e.g.: frequency, amplitude, waveform and duration of a tactile pulse, plus body location. Tactons have the potential to improve interaction in a range of different areas, particularly where the visual display is overloaded, limited in size or not available, such as interfaces for blind people or on mobile and wearable devices.},
	urldate = {2019-04-15},
	booktitle = {{CHI} '04 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brewster, Stephen A. and Brown, Lorna M.},
	year = {2004},
	note = {event-place: Vienna, Austria},
	keywords = {multimodality, non-visual interaction, tactile displays, tactons},
	pages = {787--788}
}

@inproceedings{ferguson_evaluating_2018,
	address = {New York, NY, USA},
	series = {{NordiCHI} '18},
	title = {Evaluating {Mapping} {Designs} for {Conveying} {Data} {Through} {Tactons}},
	isbn = {978-1-4503-6437-9},
	url = {http://doi.acm.org/10.1145/3240167.3240175},
	doi = {10.1145/3240167.3240175},
	abstract = {Tactons are structured vibrotactile messages which can be used to transmit information solely through the cutaneous sense. These are particularly useful in situations where visual or auditory displays are unavailable or inappropriate. Most data:vibration mappings do not consider the user's perceptions of the mappings being used, which can lead to confusion and Tactons which are difficult to interpret. To explore this issue, we conducted a magnitude estimation experiment to map how a number of vibrotactile parameters such as duration and frequency relate to the perceived magnitude of data variables that may be used in a real-world context such as error and danger. Results from this study show that when tempo and duration are used to convey data, they are perceived in the same polarity, regardless of the type of data being conveyed. This study provides polarity and scaling values which may be directly utilised by Tacton designers when creating new sets of vibrotactile messages.},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 10th {Nordic} {Conference} on {Human}-{Computer} {Interaction}},
	publisher = {ACM},
	author = {Ferguson, Jamie and Williamson, John and Brewster, Stephen},
	year = {2018},
	note = {event-place: Oslo, Norway},
	keywords = {analogy, mental model, non-visual, tactons, vibrotactile},
	pages = {215--223}
}

@inproceedings{ernst_exploring_2016,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '16},
	title = {Exploring {Haptics} for {Learning} {Bend} {Gestures} for the {Blind}},
	isbn = {978-1-4503-4082-3},
	url = {http://doi.acm.org/10.1145/2851581.2892382},
	doi = {10.1145/2851581.2892382},
	abstract = {This paper explores the use of haptic stimuli as non-visual affordances to assist in learnability of bend gestures. We tested 48 haptic Tactons with simulated blind participants to understand what haptic sensation could intuitively map to bend location and direction. We identify that a short, single motor Tacton indicates reliably a bend location, while participants agreed that the combination of two motors with varying intensities could indicate bend direction. This work is the first to explore the use of Tactons to communicate bend gesture location and direction, to eventually create a tactile interaction method for blind smartphone users},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ernst, Matthew and Girouard, Audrey},
	year = {2016},
	note = {event-place: San Jose, California, USA},
	keywords = {accessibility, bend gestures, deformable user interfaces, haptics, tactons, usability, visually impaired},
	pages = {2097--2104}
}

@inproceedings{jones_perceptual_2018,
	title = {Perceptual dimensions of vibrotactile actuators},
	doi = {10.1109/HAPTICS.2018.8357193},
	abstract = {The objective of the present research was to determine how variations in the signals generated by different vibrotactile actuators are perceived and which features are judged as being distinctive. For this purpose, three different types of actuator were used to generate signals that varied in amplitude, waveform and frequency. Participants were required to judge the degree of similarity-dissimilarity between pairs of stimuli. Multi-dimensional scaling (MDS) techniques were then used as an exploratory data analysis technique to create a spatial map that depicted the relations among the various vibrotactile signals. The first dimension that emerged from the MDS represented a continuum associated with transitions in the amplitudes of the signals, with a smooth sine wave pattern contrasting with the more abrupt transitions in square waves. This may be considered a smooth-rough dimension. The second dimension extracted from the data was more difficult to characterize in that each of the two clusters along this dimension involved signals of varying waveform and frequency. Further work will aim at defining the perceptual qualities of this dimension.},
	booktitle = {2018 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	author = {Jones, L. A. and Singhal, A.},
	month = mar,
	year = {2018},
	keywords = {Actuators, Communication systems, Haptic interfaces, Libraries, MDS, Sensitivity, Skin, Vibrations, actuators, exploratory data analysis technique, multidimensional scaling techniques, perceptual qualities, similarity-dissimilarity, smooth sine wave pattern, smooth-rough dimension, spatial map, square waves, vibrational signal processing, vibrotactile actuators, vibrotactile signals},
	pages = {307--312}
}

@inproceedings{osman_mobile_2014,
	title = {Mobile phone short message tacton notification based on mood and urgency},
	doi = {10.1109/HAVE.2014.6954335},
	abstract = {Tactile haptic support on mobile phones is becoming an indispensable feature of numerous devices. This in turn permits developers to create various tactile icons, or tactons to communicate information through the non-visual and non-auditory modality of touch. Tactons are messages conveyed through various patterns of vibrations. In this paper, we present our preliminary work on the use of tactons in order to discreetly convey information regarding the mood and urgency of text messages received on mobile phones. Such mechanism replaces the simple buzzing effect currently associated with text message notifications. Our preliminary evaluation shows encouraging results in terms of the ability of users to distinguish and recall various tactons produced by a mobile phone.},
	booktitle = {2014 {IEEE} {International} {Symposium} on {Haptic}, {Audio} and {Visual} {Environments} and {Games} ({HAVE}) {Proceedings}},
	author = {Osman, H. Al and Pilon, A. F. and Saddik, A. El},
	month = oct,
	year = {2014},
	keywords = {Detectors, Dictionaries, Haptic interfaces, Human Computer Interaction, Mobile handsets, Mood, Non-Visual Cues, Tactile Haptics, Tactons, Touch Modality, Vibrations, Visualization, buzzing effect, electronic messaging, haptic interfaces, mobile handsets, mobile phone short message tacton notification, mood, nonauditory modality, nonvisual modality, psychology, text message notifications, urgency, vibration patterns},
	pages = {76--81}
}
@article{geldard_neglected_1960,
	title = {Some {Neglected} {Possibilities} of {Communication}},
	volume = {131},
	copyright = {© 1960},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/131/3413/1583},
	doi = {10.1126/science.131.3413.1583},
	language = {en},
	number = {3413},
	urldate = {2019-04-15},
	journal = {Science},
	author = {Geldard, Frank A.},
	month = may,
	year = {1960},
	pmid = {13827173},
	pages = {1583--1588}
}

@inproceedings{hoggan_mapping_2009,
	address = {New York, NY, USA},
	series = {{ICMI}-{MLMI} '09},
	title = {Mapping {Information} to {Audio} and {Tactile} {Icons}},
	isbn = {978-1-60558-772-1},
	url = {http://doi.acm.org/10.1145/1647314.1647382},
	doi = {10.1145/1647314.1647382},
	abstract = {We report the results of a study focusing on the meanings that can be conveyed by audio and tactile icons. Our research considers the following question: how can audio and tactile icons be designed to optimise congruence between crossmodal feedback and the type of information this feedback is intended to convey? For example, if we have a set of system warnings, confirmations, progress up-dates and errors: what audio and tactile representations best match the information or type of message? Is one modality more appropriate at presenting certain types of information than the other modality? The results of this study indicate that certain parameters of the audio and tactile modalities such as rhythm, texture and tempo play an important role in the creation of congruent sets of feedback when given a specific type of information to transmit. We argue that a combination of audio or tactile parameters derived from our results allows the same type of information to be derived through touch and sound with an intuitive match to the content of the message.},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 2009 {International} {Conference} on {Multimodal} {Interfaces}},
	publisher = {ACM},
	author = {Hoggan, Eve and Raisamo, Roope and Brewster, Stephen A.},
	year = {2009},
	note = {event-place: Cambridge, Massachusetts, USA},
	keywords = {auditory feedback, earcons, information mapping, mobile touchscreen interaction, tactile feedback, tactons},
	pages = {327--334}
}

@inproceedings{hoggan_crossmodal_2006,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '06},
	title = {Crossmodal {Icons} for {Information} {Display}},
	isbn = {978-1-59593-298-3},
	url = {http://doi.acm.org/10.1145/1125451.1125619},
	doi = {10.1145/1125451.1125619},
	abstract = {This paper describes a novel form of display using crossmodal output. A crossmodal icon is an abstract icon that can be instantiated in one of two equivalent forms (auditory or tactile). These can be used in interfaces as a means of non-visual output. This paper discusses how crossmodal icons can be constructed and the potential benefits they bring to mobile human computer interfaces.},
	urldate = {2019-04-15},
	booktitle = {{CHI} '06 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Hoggan, Eve E. and Brewster, Stephen A.},
	year = {2006},
	note = {event-place: Montréal, Québec, Canada},
	keywords = {audio icons, crossmodal interaction, non-visual interaction, tactile icons},
	pages = {857--862}
}

@inproceedings{qian_tactile_2013,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '13},
	title = {Tactile {Notifications} for {Ambulatory} {Users}},
	isbn = {978-1-4503-1952-2},
	url = {http://doi.acm.org/10.1145/2468356.2468637},
	doi = {10.1145/2468356.2468637},
	abstract = {Difficulties are often associated with perceiving tactile feedback from a mobile device while ambulatory. In this paper, we describe a study conducted using multi-parameter tactile icons (tactons) with a view to identifying designs to better resist the masking effects associated with walking. Our findings suggest that tactons encoded with longer durations (800ms) or those with stronger intensities (Amplitude: 2.1g Frequency: 255Hz) offer promise to individuals on-the-move. In terms of future work, we aim to identify ways to reduce the recognition time and the levels of cognitive workload experienced when resolving multi-parameter tactons, to augment the human-mobile interaction experience.},
	urldate = {2019-04-15},
	booktitle = {{CHI} '13 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Qian, Huimin and Kuber, Ravi and Sears, Andrew},
	year = {2013},
	note = {event-place: Paris, France},
	keywords = {interfaces, tactile},
	pages = {1569--1574}
}

@inproceedings{brewster_tactile_2010,
	address = {Swinton, UK, UK},
	series = {{BCS} '10},
	title = {Tactile {Feedback} for {Ambient} {Awareness} in {Mobile} {Interactions}},
	isbn = {978-1-78017-130-2},
	url = {http://dl.acm.org/citation.cfm?id=2146303.2146365},
	abstract = {The study of tactile feedback has attracted increasing interest in HCI over recent years. Similar to icons, tactile messages, or Tactons, can encode and transmit information through the touch sense [1]. We report an experiment to investigate if we can present contextual information to a user in a low attention, ambient manner. In this case, it is done by changing the tactile 'feel' of buttons on a touchscreen keyboard to indicate external events, for example when a friend is close by. Very short Tactons ({\textless}=300ms) on each key press were changed in roughness and rhythm to indicate the events. Results showed that users correctly identified the Tactons for the different events with a rate of 88\% when 180 Tactons were presented in 45 minutes, and 98\% when the Tactons were presented in a more realistic manner. This shows that changing tactile feedback can be an effective method of presenting ambient information on a mobile device.},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 24th {BCS} {Interaction} {Specialist} {Group} {Conference}},
	publisher = {British Computer Society},
	author = {Brewster, Stephen and Constantin, Aurora},
	year = {2010},
	note = {event-place: Dundee, United Kingdom},
	keywords = {tactile feedback, tactons, text entry, touchscreen mobile devices},
	pages = {412--417}
}

@inproceedings{pakkanen_audio-haptic_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Audio-{Haptic} {Car} {Navigation} {Interface} with {Rhythmic} {Tactons}},
	isbn = {978-3-662-44193-0},
	abstract = {While car environment is often noisy and driving requires visual attention, still navigation instructions are given with audio and visual feedbacks. By using rhythmic tactons together with audio, navigation task could be supported better in the driving context. In this paper we describe haptic-audio interface with simple two-actuator setup on the wheel using rhythmic tactons for supporting navigation in the car environment. The users who tested the interface with a driving game would choose audio-haptic interface over audio only interface for a real navigation task.},
	language = {en},
	booktitle = {Haptics: {Neuroscience}, {Devices}, {Modeling}, and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Pakkanen, Toni and Raisamo, Roope and Surakka, Veikko},
	editor = {Auvray, Malika and Duriez, Christian},
	year = {2014},
	keywords = {Driving user, Haptic feedback, User interaction},
	pages = {208--215}
}

@article{barber_toward_2015,
	title = {Toward a {Tactile} {Language} for {Human}–{Robot} {Interaction}: {Two} {Studies} of {Tacton} {Learning} and {Performance}},
	volume = {57},
	issn = {0018-7208},
	shorttitle = {Toward a {Tactile} {Language} for {Human}–{Robot} {Interaction}},
	url = {https://doi.org/10.1177/0018720814548063},
	doi = {10.1177/0018720814548063},
	abstract = {Objective:Two experiments were performed to investigate the feasibility for robot-to-human communication of a tactile language using a lexicon of standardized tactons (tactile icons) within a sentence.Background:Improvements in autonomous systems technology and a growing demand within military operations are spurring interest in communication via vibrotactile displays. Tactile communication may become an important element of human?robot interaction (HRI), but it requires the development of messaging capabilities approaching the communication power of the speech and visual signals used in the military.Method:In Experiment 1 (N = 38), we trained participants to identify sets of directional, dynamic, and static tactons and tested performance and workload following training. In Experiment 2 (N = 76), we introduced an extended training procedure and tested participants? ability to correctly identify two-tacton phrases. We also investigated the impact of multitasking on performance and workload. Individual difference factors were assessed.Results:Experiment 1 showed that participants found dynamic and static tactons difficult to learn, but the enhanced training procedure in Experiment 2 produced competency in performance for all tacton categories. Participants in the latter study also performed well on two-tacton phrases and when multitasking. However, some deficits in performance and elevation of workload were observed. Spatial ability predicted some aspects of performance in both studies.Conclusions:Participants may be trained to identify both single tactons and tacton phrases, demonstrating the feasibility of developing a tactile language for HRI.Application:Tactile communication may be incorporated into multi-modal communication systems for HRI. It also has potential for human?human communication in challenging environments.},
	language = {en},
	number = {3},
	urldate = {2019-04-15},
	journal = {Human Factors},
	author = {Barber, Daniel J. and Reinerman-Jones, Lauren E. and Matthews, Gerald},
	month = may,
	year = {2015},
	pages = {471--490}
}

@inproceedings{azadi_identification_2013,
	title = {Identification of vibrotactile patterns: building blocks for tactons},
	shorttitle = {Identification of vibrotactile patterns},
	doi = {10.1109/WHC.2013.6548433},
	abstract = {Vibrotactile stimuli vary along a number of dimensions including frequency, amplitude, waveform and temporal profile all of which can be varied to create tactons. The objective of the present experiment was to measure tactile pattern recognition using eight vibrotactile stimuli that varied with respect to frequency, amplitude and pulse duration. An absolute identification paradigm was used in which each stimulus was presented eight times to the index finger or forearm and participants had to identify the visual image associated with the tacton. The results from the experiment indicated that in the absence of spatial cues, tactons were relatively difficult for participants to identify, with an overall mean recognition rate of 57\% correct and an IT of 1.72 bits. However, there were significant differences in the identification rates among the tactons, with mean scores ranging from 30\% to 83 \% correct. Tactons created using higher frequencies and amplitudes were easier to identify than those with lower frequencies and amplitudes. Surprisingly, there was no difference between the finger and the forearm in tacton identification. The dimension that appeared to be most difficult to encode was amplitude, as reflected in the patterns of misidentification in the confusion matrices. These findings indicate that the specific dimensions and stimulus ranges selected to create tactons can profoundly affect the ability to identify tactile patterns and that differences in spatial and temporal acuity across the skin are not predictive of these abilities.},
	booktitle = {2013 {World} {Haptics} {Conference} ({WHC})},
	author = {Azadi, M. and Jones, L.},
	month = apr,
	year = {2013},
	keywords = {Frequency measurement, Frequency modulation, Permanent magnet motors, Skin, Thumb, Vibrations, absolute identification paradigm, confusion matrix, haptic interfaces, matrix algebra, pattern recognition, tactile display, tactile pattern recognition, tacton identification, touch, vibration, vibrotactile pattern identification, vibrotactile stimuli},
	pages = {347--352}
}

@inproceedings{brown_multidimensional_2006,
	address = {New York, NY, USA},
	series = {{MobileHCI} '06},
	title = {Multidimensional {Tactons} for {Non}-visual {Information} {Presentation} in {Mobile} {Devices}},
	isbn = {978-1-59593-390-4},
	url = {http://doi.acm.org/10.1145/1152215.1152265},
	doi = {10.1145/1152215.1152265},
	abstract = {Tactons are structured vibrotactile messages which can be used for non-visual information presentation when visual displays are limited, unavailable or inappropriate, such as in mobile phones and other mobile devices. Little is yet known about how to design them effectively. Previous studies have investigated the perception of Tactons which encode two dimensions of information using two different vibrotactile parameters (rhythm and roughness) and found recognition rates of around 70. When more dimensions of information are required it may be necessary to extend the parameter-space of these Tactons. Therefore this study investigates recognition rates for Tactons which encode a third dimension of information using spatial location. The results show that identification rate for three-parameter Tactons is just 48, but that this can be increased to 81 by reducing the number of values of one of the parameters. These results will aid designers to select suitable Tactons for use when designing mobile displays.},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 8th {Conference} on {Human}-computer {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Brown, Lorna M. and Brewster, Stephen A. and Purchase, Helen C.},
	year = {2006},
	note = {event-place: Helsinki, Finland},
	keywords = {non-visual interaction, tactile displays, tactile icons, tactons},
	pages = {231--238}
}

@inproceedings{brown_feel_2006,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '06},
	title = {Feel {Who}'s {Talking}: {Using} {Tactons} for {Mobile} {Phone} {Alerts}},
	isbn = {978-1-59593-298-3},
	shorttitle = {Feel {Who}'s {Talking}},
	url = {http://doi.acm.org/10.1145/1125451.1125577},
	doi = {10.1145/1125451.1125577},
	abstract = {While the sense of touch is capable of processing complex stimuli, the vibration feedback used in mobile phones is generally very simple. Using more complex vibrotactile messages would enable the communication of more information through phone alerts, however it has been suggested that phone vibration motors are not capable of presenting complex messages. This paper reports a study investigating the use of Tactons (tactile icons), presented using a standard mobile phone vibration motor, to represent mobile phone alerts. The recognition rate of 72\% achieved for Tactons encoding two pieces of information is comparable to results achieved in a previous experiment with a high specification transducer, indicating that it is possible to communicate multi-dimensional information in mobile phone alerts. These results will help designers to understand the possibilities offered by standard phone vibration motors for communicating complex information.},
	urldate = {2019-04-15},
	booktitle = {{CHI} '06 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Brown, Lorna M. and Kaaresoja, Topi},
	year = {2006},
	note = {event-place: Montréal, Québec, Canada},
	keywords = {mobile computing, mobile phones, non-visual interaction, tactile displays, tactile icons},
	pages = {604--609}
}

@inproceedings{lin_using_2008,
	address = {New York, NY, USA},
	series = {{NordiCHI} '08},
	title = {Using {Tactons} to {Provide} {Navigation} {Cues} in {Pedestrian} {Situations}},
	isbn = {978-1-59593-704-9},
	url = {http://doi.acm.org/10.1145/1463160.1463231},
	doi = {10.1145/1463160.1463231},
	abstract = {Until recently, the existing navigation services do not meet the needs in pedestrian situation. The display of present navigation information is often inappropriate. In this paper, we report two experiments to investigate whether using tactile display to present navigation information is sufficient and appropriate in pedestrian situation. The result of those experiments showed that Tactons could be a successful means of communicating navigation information in user interfaces in pedestrian situations.},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 5th {Nordic} {Conference} on {Human}-computer {Interaction}: {Building} {Bridges}},
	publisher = {ACM},
	author = {Lin, Ming-Wei and Cheng, Yun-Maw and Yu, Wai},
	year = {2008},
	note = {event-place: Lund, Sweden},
	keywords = {Tactons, non-visual interaction, pedestrian navigation, tactile displays, tactile icons},
	pages = {507--510}
}

@article{fox_inverse_1987,
	title = {An inverse fourier transform algorithm for generating random signals of a specified spectral form},
	volume = {13},
	issn = {0098-3004},
	url = {http://www.sciencedirect.com/science/article/pii/0098300487900094},
	doi = {10.1016/0098-3004(87)90009-4},
	abstract = {A simple FORTRAN algorithm which produces a random signal of a specified length and spectral form is presented. Such artificially generated signals are useful in modeling natural phenomena, calibrating other algorithms, comparing signals of measured observational or laboratory data, or providing multiple realizations of a given statistical process. Because of the prevalence of power-law form spectra in nature and its relationship to fractal forms, the algorithm provides a convenient manner of generating profiles of a given fractal dimension. The routine is modified easily for generating signals of any specified spectral form, and several such forms are illustrated.},
	number = {4},
	urldate = {2019-02-16},
	journal = {Computers \& Geosciences},
	author = {Fox, Christopher G.},
	month = jan,
	year = {1987},
	keywords = {FORTRAN, Fourier transform, Fractals, Power-law form spectra, Pseudorandom series, Random signal},
	pages = {369--374}
}

@inproceedings{tam_design_2013,
	address = {Paris, France},
	title = {The design and field observation of a haptic notification system for timing awareness during oral presentations},
	isbn = {978-1-4503-1899-0},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2466223},
	doi = {10.1145/2470654.2466223},
	abstract = {To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user’s awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker ‘internal’ control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.},
	language = {en},
	urldate = {2019-02-13},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Tam, Diane and MacLean, Karon E. and McGrenere, Joanna and Kuchenbecker, Katherine J.},
	year = {2013},
	pages = {1689}
}

@inproceedings{obrist_talking_2013,
	address = {Paris, France},
	title = {Talking about tactile experiences},
	isbn = {978-1-4503-1899-0},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2466220},
	doi = {10.1145/2470654.2466220},
	abstract = {A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants’ verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a humanexperiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.},
	language = {en},
	urldate = {2019-02-13},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Obrist, Marianna and Seah, Sue Ann and Subramanian, Sriram},
	year = {2013},
	pages = {1659}
}

@article{guest_development_2011,
	title = {The development and validation of sensory and emotional scales of touch perception},
	volume = {73},
	issn = {1943-393X},
	url = {https://doi.org/10.3758/s13414-010-0037-y},
	doi = {10.3758/s13414-010-0037-y},
	abstract = {No comprehensive language exists that describes the experience of touch. Three experiments were conducted to take steps toward establishing a touch lexicon. In Experiment I, 49 participants rated how well 262 adjectives described sensory, emotional and evaluative aspects of touch. In Experiment II, participants rated pairwise dissimilarities of the most descriptive words of the set. Multidimensional scaling (MDS) solutions representing semantic–perceptual spaces underlying the words resulted in a touch perception task (TPT) consisting of 26 ‘sensory’ attributes (e.g., bumpiness) and 14 ‘emotional’ attributes (e.g., pleasurable). In Experiment III, 40 participants used the TPT to rate unseen textured materials that were moved actively or received passively against the index fingerpad, volar forearm, and two underarm sites. MDS confirmed similar semantic–perceptual structures in Experiments II and III. Factor analysis of Experiment III data decomposed the sensory attribute ratings into factors labeled Roughness, Slip, Pile and Firmness, and the emotional attribute ratings into Comfort and Arousal factors. Factor scores varied among materials and sites. Greater intensity of sensory and emotional responses were reported when participants passively, as opposed to actively, received stimuli. The sensitivity of the TPT in identifying body site and mode of touch-related perceptual differences affirms the validity and utility of this novel linguistic/perceptual tool.},
	language = {en},
	number = {2},
	urldate = {2019-02-13},
	journal = {Attention, Perception, \& Psychophysics},
	author = {Guest, Steve and Dessirier, Jean Marc and Mehrabyan, Anahit and McGlone, Francis and Essick, Greg and Gescheider, George and Fontana, Anne and Xiong, Rui and Ackerley, Rochelle and Blot, Kevin},
	month = feb,
	year = {2011},
	keywords = {Factor analysis, Multidimensional scaling, Psychometric testing, Texture perception, Touch},
	pages = {531--550}
}

@inproceedings{erp_distilling_2003,
	title = {Distilling the {Underlying} {Dimensions} of {Tactile} {Melodies}},
	abstract = {We created 59 tactile melodies by transforming pieces of music from the auditory domain to the vibrotactile domain. Sixteen observers judged these tactile melodies on a set of 16 characteristics such as ‘melodious’, ‘bombastic’, and ‘alarming’. By using advanced multivariate statistical methods, we distilled two main underlying dimensions of the tactile melodies. We interpreted these dimensions as intrusiveness and tempo. The results are important to understand the perception of tactile melodies and to support the creation of better distinguishable and recognizable tactile signals for single point tactile displays such as in mobile phones and computer mice.},
	author = {Erp, Jan B. F. van and Spapé, Michiel M. A.},
	year = {2003},
	keywords = {Computer mouse, Dimensions, Fifty Nine, Mobile phone}
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {Distilling} the underlying dimensions of tactile melodies},
	url = {https://www.researchgate.net/publication/228823215_Distilling_the_underlying_dimensions_of_tactile_melodies},
	abstract = {PDF {\textbar} We created 59 tactile melodies by transforming pieces of music from the auditory domain to the vibrotactile domain. Sixteen observers judged these tactile melodies on a set of 16 characteristics such as 'melodious', 'bombastic', and 'alarming'. By using advanced multivariate...},
	language = {en},
	urldate = {2019-02-13},
	journal = {ResearchGate}
}

@misc{noauthor_distilling_nodate,
	title = {Distilling the {Underlying} {Dimensions} of {Tactile} {Melodies} - {Semantic} {Scholar}},
	url = {https://www.semanticscholar.org/paper/Distilling-the-Underlying-Dimensions-of-Tactile-Erp-Spap%C3%A9/17d3b6c791b40db6144ff54a9dcfc77f54ec9ab2},
	urldate = {2019-02-13}
}

@inproceedings{seifi_vibviz:_2015,
	title = {{VibViz}: {Organizing}, visualizing and navigating vibration libraries},
	shorttitle = {{VibViz}},
	doi = {10.1109/WHC.2015.7177722},
	abstract = {With haptics now common in consumer devices, diversity in tactile perception and aesthetic preferences confound haptic designers. End-user customization out of example sets is an obvious solution, but haptic collections are notoriously difficult to explore. This work addresses the provision of easy and highly navigable access to large, diverse sets of vibrotactile stimuli, on the premise that multiple access pathways facilitate discovery and engagement. We propose and examine five disparate organization schemes (taxonomies), describe how we created a 120-item library with diverse functional and affective characteristics, and present VibViz, an interactive tool for end-user library navigation and our own investigation of how different taxonomies can assist navigation. An exploratory user study with and of VibViz suggests that most users gravitate towards an organization based on sensory and emotional terms, but also exposes rich variations in their navigation patterns and insights into the basis of effective haptic library navigation.},
	booktitle = {2015 {IEEE} {World} {Haptics} {Conference} ({WHC})},
	author = {Seifi, H. and Zhang, K. and MacLean, K. E.},
	month = jun,
	year = {2015},
	keywords = {Haptic interfaces, Libraries, Navigation, Rhythm, Taxonomy, VibViz, Vibrations, Visualization, aesthetic preferences, disparate organization schemes, end-user library navigation, haptic collections, haptic interfaces, haptic library navigation, tactile perception, vibration libraries, vibrations, vibrotactile stimuli},
	pages = {254--259}
}

@inproceedings{bernard_harmonious_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Harmonious {Textures}: {The} {Perceptual} {Dimensions} of {Synthetic} {Sinusoidal} {Gratings}},
	isbn = {978-3-319-93399-3},
	shorttitle = {Harmonious {Textures}},
	abstract = {Natural gratings explored by a finger generate vibratory patterns. These vibrations contain a wide range of frequencies, which include the fundamental spatial frequency of the grating and other (higher) harmonics. In this study, it was proposed to investigate how the fundamental and harmonic frequencies contribute to the perception of a virtual grating presented in the form of spatial pattern of friction force. Using multidimensional scaling methods, we established that the first overtone was the main characteristic used by the participants to identify gratings. When asked to rate the pleasantness to the touch, participants’ preferences were for gratings with low spatial frequencies and low amplitudes. These results suggest new ways of creating meaningful, pleasant human-computer interactions in the context of surface-haptic displays.},
	language = {en},
	booktitle = {Haptics: {Science}, {Technology}, and {Applications}},
	publisher = {Springer International Publishing},
	author = {Bernard, Corentin and Monnoyer, Jocelyn and Wiertlewski, Michaël},
	editor = {Prattichizzo, Domenico and Shinoda, Hiroyuki and Tan, Hong Z. and Ruffaldi, Emanuele and Frisoli, Antonio},
	year = {2018},
	keywords = {Surface haptic, Texture perception, Texture synthesis},
	pages = {685--695}
}

@inproceedings{zhao_using_2015,
	address = {New York, NY, USA},
	series = {{IDC} '15},
	title = {Using {Haptic} {Inputs} to {Enrich} {Story} {Listening} for {Young} {Children}},
	isbn = {978-1-4503-3590-4},
	url = {http://doi.acm.org/10.1145/2771839.2771886},
	doi = {10.1145/2771839.2771886},
	abstract = {Research on children's cognitive development has demonstrated the positive effects of listening to stories. However, traditional story listening is losing its appeal to other entertainment technology such as video games. Hence, there is growing interest in studying the influence of ancillary media such as sound and interactive effects, although haptic sensory input has remained relatively unexploited. We implemented a haptic vest that generates vibrotactile stimulation related to story content to augment story listening. Study 1 showed that 5- and 6-year olds, but not 4-year olds, could associate haptic effects with semantic interpretations. In Study 2, children listened to stories containing elements with or without haptic effects. The 5- and 6-year olds showed better comprehension of the haptically-signaled content in the higher-performance story. The results provide initial evidence that haptic effects can potentially enhance the reading/listening experience of children beyond 4 years.},
	urldate = {2019-02-07},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Interaction} {Design} and {Children}},
	publisher = {ACM},
	author = {Zhao, Siyan and Lehman, Jill and Israr, Ali and Klatzky, Roberta},
	year = {2015},
	note = {event-place: Boston, Massachusetts},
	keywords = {haptic vest, haptic vocabulary, haptics, story listening technology, vibrotactile feedback},
	pages = {239--242}
}

@inproceedings{yoo_emotional_2017,
	title = {Emotional responses of vibrotactile-thermal stimuli: {Effects} of constant-temperature thermal stimuli},
	shorttitle = {Emotional responses of vibrotactile-thermal stimuli},
	doi = {10.1109/ACII.2017.8273612},
	abstract = {Haptic feedback has been finding increasing uses in affective interaction design. In this paper, we describe the emotional characteristics of multimodal tactile stimuli that combine vibrotactile and thermal stimuli. While varying three vibrotactile parameters of frequency, amplitude, and duration and one thermal parameter of constant temperature, we experimentally evaluated the valence and arousal of 1) thermal stimuli and 2) multimodal vibrotactile-thermal stimuli with 20 participants. Results indicated that the thermal and vibrotactile parameters have clear and somewhat independent effects on emotional responses. The findings of this study can contribute to expanding the design space of affective user interaction involving touch.},
	booktitle = {2017 {Seventh} {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} ({ACII})},
	author = {Yoo, Y. and Lee, H. and Choi, H. and Choi, S.},
	month = oct,
	year = {2017},
	keywords = {Haptic interfaces, Heat sinks, Psychology, Skin, Temperature, Vibrations, Visualization, affective interaction design, constant temperature, constant-temperature thermal stimuli, emotion recognition, emotional characteristics, emotional responses, haptic interfaces, human computer interaction, multimodal tactile stimuli, tactile sensors, thermal parameter, thermal parameters, touch (physiological), vibrotactile-thermal stimuli},
	pages = {273--278}
}

@article{seifi_toward_2018,
	title = {Toward {Affective} {Handles} for {Tuning} {Vibrations}},
	volume = {15},
	issn = {1544-3558},
	url = {http://doi.acm.org/10.1145/3230645},
	doi = {10.1145/3230645},
	abstract = {When refining or personalizing a design, we count on being able to modify or move an element by changing its parameters rather than creating it anew in a different form or location—a standard utility in graphic and auditory authoring tools. Similarly, we need to tune vibrotactile sensations to fit new use cases, distinguish members of communicative icon sets, and personalize items. For tactile vibration display, however, we lack knowledge of the human perceptual mappings that must underlie such tools. Based on evidence that affective dimensions are a natural way to tune vibrations for practical purposes, we attempted to manipulate perception along three emotion dimensions (agitation, liveliness, and strangeness) using engineering parameters of hypothesized relevance. Results from two user studies show that an automatable algorithm can increase a vibration’s perceived agitation and liveliness to different degrees via signal energy, while increasing its discontinuity or randomness makes it more strange. These continuous mappings apply across diverse base vibrations; the extent of achievable emotion change varies. These results illustrate the potential for developing vibrotactile emotion controls as efficient tuning for designers and end-users.},
	number = {3},
	urldate = {2019-02-07},
	journal = {ACM Trans. Appl. Percept.},
	author = {Seifi, Hasti and Chun, Mattew and Maclean, Karon E.},
	month = jul,
	year = {2018},
	keywords = {Affective haptics, design and personalization tools, emotion dimensions, end-user perception},
	pages = {22:1--22:23}
}

@misc{noauthor_emotional_nodate,
	title = {Emotional responses of tactile icons: {Effects} of amplitude, frequency, duration, and envelope - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore.ieee.org/document/7177719/citations?tabFilter=papers#citations},
	urldate = {2019-02-06}
}

@inproceedings{yoo_emotional_2015,
	title = {Emotional responses of tactile icons: {Effects} of amplitude, frequency, duration, and envelope},
	shorttitle = {Emotional responses of tactile icons},
	doi = {10.1109/WHC.2015.7177719},
	abstract = {This paper is concerned with emotional responses of tactile icons. Using three sets of tactile icons in which four physical parameters-amplitude, frequency, duration, and envelope-were systematically varied, we estimated their valence and arousal scores in a perceptual experiment with 24 participants. Results showed that the four parameters have clear relationships to the emotional responses of tactile icons. Our tactile icons spanned to a large region in the valence-arousal space, but they did not elicit very positive-relaxing or very negative-relaxing emotional responses. These findings provide the design guidelines of tactile icons that have desired emotional properties.},
	booktitle = {2015 {IEEE} {World} {Haptics} {Conference} ({WHC})},
	author = {Yoo, Y. and Yoo, T. and Kong, J. and Choi, S.},
	month = jun,
	year = {2015},
	keywords = {Analysis of variance, Iron, amplitude parameter, duration parameter, envelope parameter, frequency parameter, handicapped aids, haptic interfaces, positive-relaxing, social aspects of automation, tactile icons, valence-arousal space, very negative-relaxing emotional responses},
	pages = {235--240}
}

@inproceedings{schneider_studying_2016,
	title = {Studying design process and example use with {Macaron}, a web-based vibrotactile effect editor},
	doi = {10.1109/HAPTICS.2016.7463155},
	abstract = {Examples are a critical part of any design process, but supporting their use for a haptic medium is nontrivial. Current libraries for vibrotactile (VT) effects provide neither insight into examples' construction nor capability for deconstruction and re-composition. To investigate the special requirements of example use for VT design, we studied designers as they used a web-based effect editor, Macaron, which we created as both an evaluation platform and a practical tool. We qualitatively characterized participants' design processes and observed two basic example uses: as a starting point or template for a design task, and as a learning method. We discuss how features supporting internal visibility and composition influenced these example uses, and articulate several implications for VT editing tools and libraries of VT examples. We conclude with future work, including plans to deploy Macaron online to examine examples and other aspects of VT design in situ.},
	booktitle = {2016 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	author = {Schneider, O. S. and MacLean, K. E.},
	month = apr,
	year = {2016},
	keywords = {Animation, Haptic interfaces, Internet, Libraries, Macaron, Media, Time-frequency analysis, VT effects, Visualization, Web-based vibrotactile effect editor, design process, haptic interfaces, haptic medium, learning (artificial intelligence), learning method},
	pages = {52--58}
}

@inproceedings{egloff_haptic_2018,
	title = {Haptic display of melodic intervals for musical applications},
	doi = {10.1109/HAPTICS.2018.8357189},
	abstract = {The focus of this study was to investigate the ability to discriminate between melodic intervals of the equal tempered scale based solely on vibrotactile stimulation. In music, a melodic interval is the musical distance between two pitches, or notes, that are played sequentially. This paper tests the hypothesis that people can detect melodic intervals that are presented to different body sites such as the fingertip of the index finger of the non-dominant hand, as well as to the flank, the lateral region between the ribcage and the hip bone. Vibrotactile stimuli on the flank were displayed through voice coils of different diameters (0 13 mm and 0 25 mm respectively), while those at the finger were displayed with a 0 13 mm diameter voice coil. Six melodic intervals ranging from a minor second (A/=100 cents) to a perfect fifth (A/=700 cents) were compared to the reference interval of a perfect prime (A/=0 cents) at a fundamental frequency (/) of 65 Hz. Discrimination was significant for intervals as small as a major second (A/=200 cents; i.e. 8Hz, or 12.3\%), depending on the location of the body. Overall, results tend to suggest that larger intervals are less difficult to detect than smaller intervals.},
	booktitle = {2018 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	author = {Egloff, D. C. and Wanderley, M. M. and Frissen, I.},
	month = mar,
	year = {2018},
	keywords = {Auditory system, Coils, Haptic interfaces, Music, Skin, Thumb, Vibrations, bone, diameter voice coil, haptic display, haptic interfaces, hip bone, index finger, larger intervals, melodic intervals, music, musical applications, musical distance, nondominant hand, reference interval, ribcage, sensory aids, smaller intervals, statistical analysis, touch (physiological), vibrotactile stimulation},
	pages = {284--289}
}

@book{oviatt_handbook_2017,
	title = {The {Handbook} of {Multimodal}-{Multisensor} {Interfaces}, {Volume} 1: {Foundations}, {User} {Modeling}, and {Common} {Modality} {Combinations}},
	isbn = {978-1-970001-66-2},
	shorttitle = {The {Handbook} of {Multimodal}-{Multisensor} {Interfaces}, {Volume} 1},
	abstract = {The Handbook of Multimodal-Multisensor Interfaces provides the first authoritative resource on what has become the dominant paradigm for new computer interfaces— user input involving new media (speech, multi-touch, gestures, writing) embedded in multimodal-multisensor interfaces. These interfaces support smart phones, wearables, in-vehicle and robotic applications, and many other areas that are now highly competitive commercially. This edited collection is written by international experts and pioneers in the field. It provides a textbook, reference, and technology roadmap for professionals working in this and related areas. This first volume of the handbook presents relevant theory and neuroscience foundations for guiding the development of high-performance systems. Additional chapters discuss approaches to user modeling and interface designs that support user choice, that synergistically combine modalities with sensors, and that blend multimodal input and output. This volume also highlights an in-depth look at the most common multimodal-multisensor combinations—for example, touch and pen input, haptic and non-speech audio output, and speech-centric systems that co-process either gestures, pen input, gaze, or visible lip movements. A common theme throughout these chapters is supporting mobility and individual differences among users. These handbook chapters provide walk-through examples of system design and processing, information on tools and practical resources for developing and evaluating new systems, and terminology and tutorial support for mastering this emerging field. In the final section of this volume, experts exchange views on a timely and controversial challenge topic, and how they believe multimodal-multisensor interfaces should be designed in the future to most effectively advance human performance.},
	language = {en},
	publisher = {Morgan \& Claypool},
	author = {Oviatt, Sharon and Schuller, Björn and Cohen, Philip and Sonntag, Daniel and Potamianos, Gerasimos},
	month = jun,
	year = {2017},
	note = {Google-Books-ID: iC7XDgAAQBAJ},
	keywords = {Computers / Computer Science, Computers / Human-Computer Interaction (HCI), Computers / User Interfaces}
}

@inproceedings{seifi_end-user_2014,
	title = {End-user customization of affective tactile messages: {A} qualitative examination of tool parameters},
	shorttitle = {End-user customization of affective tactile messages},
	doi = {10.1109/HAPTICS.2014.6775463},
	abstract = {Vibrotactile (VT) signals are found today in many everyday electronic devices (e.g., notification of cellphone messages or calls); but it remains a challenge to design engaging, understandable vibrations to accommodate a broad range of preferences. Here, we examine customization as a way to leverage the affective qualities of vibrations and satisfy diverse tastes; specifically, the desirability and composition of VT customization tools for end-users. A review of existing design and customization tools (haptic and otherwise) yielded five parameters in which such tools can vary: 1) size of design space, 2) granularity of control, 3) provided design framework, 4) facilitated parameter(s), and 5) clarity of design alternatives. We varied these parameters within low-fidelity prototypes of three customization tools, modeled in some respects on existing popular examples. Results of a Wizard-of-Oz study confirm users' general interest in customizing everyday VT signals. Although common in consumer devices, choosing from a list of presets was the least preferred, whereas an option allowing users to balance VT design control with convenience was favored. We report users' opinion of the three tools, and link our findings to the five characterizing parameters for customization tools that we have proposed.},
	booktitle = {2014 {IEEE} {Haptics} {Symposium} ({HAPTICS})},
	author = {Seifi, H. and Anthonypillai, C. and MacLean, K. E.},
	month = feb,
	year = {2014},
	keywords = {Actuators, Aerospace electronics, H.1.2 [User/Machine Systems]: Human factors—Haptic Tools, End-User Customization, Haptic interfaces, Prototypes, Rhythm, Software, VT customization tools, VT design control, Vibrations, affective tactile messages, consumer device, consumer electronics, control granularity, design space, end user customization, haptic interfaces, qualitative tool parameter examination, ubiquitous computing, vibrations, vibrotactile signals},
	pages = {251--256}
}

@inproceedings{schneider_hapturk:_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {{HapTurk}: {Crowdsourcing} {Affective} {Ratings} of {Vibrotactile} {Icons}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {{HapTurk}},
	url = {http://doi.acm.org/10.1145/2858036.2858279},
	doi = {10.1145/2858036.2858279},
	abstract = {Vibrotactile (VT) display is becoming a standard component of informative user experience, where notifications and feedback must convey information eyes-free. However, effective design is hindered by incomplete understanding of relevant perceptual qualities, together with the need for user feedback to be accessed in-situ. To access evaluation streamlining now common in visual design, we introduce proxy modalities as a way to crowdsource VT sensations by reliably communicating high-level features through a crowd-accessible channel. We investigate two proxy modalities to represent a high-fidelity tactor: a new VT visualization, and low-fidelity vibratory translations playable on commodity smartphones. We translated 10 high-fidelity vibrations into both modalities, and in two user studies found that both proxy modalities can communicate affective features, and are consistent when deployed remotely over Mechanical Turk. We analyze fit of features to modalities, and suggest future improvements.},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Schneider, Oliver S. and Seifi, Hasti and Kashani, Salma and Chun, Matthew and MacLean, Karon E.},
	year = {2016},
	note = {event-place: San Jose, California, USA},
	keywords = {crowdsource, design, haptic, mechanical turk, multimodal, user study, vibrotactile, visualization},
	pages = {3248--3260}
}

@misc{noauthor_feel_nodate,
	title = {Feel {Effects}: {Enriching} {Storytelling} with {Haptic} {Feedback}},
	shorttitle = {Feel {Effects}},
	url = {https://www.disneyresearch.com/publication/feel-effects/},
	abstract = {In this paper, we make progress toward both capabilities: we generate a foundational library of usable haptic vocabulary and do so with a methodology that allows ongoing additions to the library in a principled and effective way.},
	language = {en-US},
	urldate = {2019-02-06},
	journal = {Disney Research}
}

@inproceedings{luk_role_2006,
	address = {New York, NY, USA},
	series = {{CHI} '06},
	title = {A {Role} for {Haptics} in {Mobile} {Interaction}: {Initial} {Design} {Using} a {Handheld} {Tactile} {Display} {Prototype}},
	isbn = {978-1-59593-372-0},
	shorttitle = {A {Role} for {Haptics} in {Mobile} {Interaction}},
	url = {http://doi.acm.org/10.1145/1124772.1124800},
	doi = {10.1145/1124772.1124800},
	abstract = {Mobile interaction can potentially be enhanced with well-designed haptic control and display. However, advances have been limited by a vicious cycle whereby inadequate haptic technology obstructs inception of vitalizing applications. We present the first stages of a systematic design effort to break that cycle, beginning with specific usage scenarios and a new handheld display platform based on lateral skin stretch. Results of a perceptual device characterization inform mappings between device capabilities and specific roles in mobile interaction, and the next step of hardware re-engineering.},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Luk, Joseph and Pasquero, Jerome and Little, Shannon and MacLean, Karon and Levesque, Vincent and Hayward, Vincent},
	year = {2006},
	note = {event-place: Montréal, Québec, Canada},
	keywords = {design process, display, handheld interaction, haptic, lateral skin stretch, mobile, multimodal, tactile},
	pages = {171--180}
}

@article{barber_toward_2015-1,
	title = {Toward a {Tactile} {Language} for {Human}–{Robot} {Interaction}: {Two} {Studies} of {Tacton} {Learning} and {Performance}},
	volume = {57},
	issn = {0018-7208},
	shorttitle = {Toward a {Tactile} {Language} for {Human}–{Robot} {Interaction}},
	url = {https://doi.org/10.1177/0018720814548063},
	doi = {10.1177/0018720814548063},
	abstract = {Objective:Two experiments were performed to investigate the feasibility for robot-to-human communication of a tactile language using a lexicon of standardized tactons (tactile icons) within a sentence.Background:Improvements in autonomous systems technology and a growing demand within military operations are spurring interest in communication via vibrotactile displays. Tactile communication may become an important element of human?robot interaction (HRI), but it requires the development of messaging capabilities approaching the communication power of the speech and visual signals used in the military.Method:In Experiment 1 (N = 38), we trained participants to identify sets of directional, dynamic, and static tactons and tested performance and workload following training. In Experiment 2 (N = 76), we introduced an extended training procedure and tested participants? ability to correctly identify two-tacton phrases. We also investigated the impact of multitasking on performance and workload. Individual difference factors were assessed.Results:Experiment 1 showed that participants found dynamic and static tactons difficult to learn, but the enhanced training procedure in Experiment 2 produced competency in performance for all tacton categories. Participants in the latter study also performed well on two-tacton phrases and when multitasking. However, some deficits in performance and elevation of workload were observed. Spatial ability predicted some aspects of performance in both studies.Conclusions:Participants may be trained to identify both single tactons and tacton phrases, demonstrating the feasibility of developing a tactile language for HRI.Application:Tactile communication may be incorporated into multi-modal communication systems for HRI. It also has potential for human?human communication in challenging environments.},
	language = {en},
	number = {3},
	urldate = {2019-02-01},
	journal = {Human Factors},
	author = {Barber, Daniel J. and Reinerman-Jones, Lauren E. and Matthews, Gerald},
	month = may,
	year = {2015},
	pages = {471--490}
}

@article{azadi_evaluating_2014,
	title = {Evaluating {Vibrotactile} {Dimensions} for the {Design} of {Tactons}},
	volume = {7},
	issn = {1939-1412},
	doi = {10.1109/TOH.2013.2296051},
	abstract = {Vibrotactile stimuli are defined in terms of their amplitude, frequency, waveform and temporal profile all of which have been varied to create tactons. A number of approaches have been adopted to design tactons including multidimensional scaling, iterative empirical methods and using perceptual processing models. The objective of the present set of experiments was to create sets of tactons based on the properties of the dimensions of vibrotactile stimuli. An absolute identification paradigm was used in which each of nine tactons was presented eight times using a tactor mounted on either the index finger or forearm. It was found that tactons created by varying the frequency, amplitude and temporal profile of the vibrotactile stimuli were correctly identified on 73-83 percent of the trials, with a mean information transfer of 2.41 bits. The latter metric indicates that for these sets of nine tactons between five and six could be reliably identified. The vibrotactile stimuli delivered in the experiments were identified as consistently on the forearm as the hand and the IT values were similar at the two locations. This suggests that sites other than the hand can be used effectively in tactile communication systems and that it is channel capacity that ultimately determines performance on this type of task.},
	number = {1},
	journal = {IEEE Transactions on Haptics},
	author = {Azadi, M. and Jones, L. A.},
	month = jan,
	year = {2014},
	keywords = {Actuators, Adult, Concept Formation, Frequency measurement, Frequency modulation, Haptic I/O, Humans, Indexes, Male, Skin, Thumb, Touch Perception, Vibration, Young Adult, absolute identification paradigm, amplitude profile, channel capacity, frequency profile, haptic interfaces, human information processing, input devices and strategies, iterative empirical method, iterative methods, multidimensional scaling, perceptual processing model, tactile communication systems, tactile sensors, tactons design, tactor, temporal profile, user centred design, user-centered design, vibrotactile dimension, vibrotactile stimuli},
	pages = {14--23}
}

@inproceedings{menelas_design_2012,
	title = {Design of a serious game for learning vibrotactile messages},
	doi = {10.1109/HAVE.2012.6374446},
	abstract = {To prevent accidental falls, we have designed an augmented shoe aiming at assisting a user when walking. For this, the risk level (low, medium, high and very high) represented by the current situation is conveyed to the user through vibrotactile messages. In this paper, we describe the design of a serious game dedicated to learning of these signals. The game is centered on a virtual maze, whose parts are associated with the four risk levels. To explore this maze, fitted with a pair of the augmented shoes, the user is invited to walk in a room, completely empty, whose dimensions are mapped to those of the virtual maze. When moving, for each area explored the corresponding signal is delivered to the user through the augmented shoes. An initial experiment confirmed the idea that vibrotactile messages can serve for communicating the level of risk.},
	booktitle = {2012 {IEEE} {International} {Workshop} on {Haptic} {Audio} {Visual} {Environments} and {Games} ({HAVE} 2012) {Proceedings}},
	author = {Menelas, B. J. and Otis, M. J.-},
	month = oct,
	year = {2012},
	keywords = {Actuators, Footwear, Games, Haptic interfaces, Legged locomotion, Sensors, Vibrations, accident prevention, accidental falls prevention, augmented reality, augmented shoe, computer games, design, haptic interfaces, learning (artificial intelligence), serious game, vibrotactile messages learning, virtual maze},
	pages = {124--129}
}

@inproceedings{ternes_designing_2008,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Designing {Large} {Sets} of {Haptic} {Icons} with {Rhythm}},
	isbn = {978-3-540-69057-3},
	abstract = {Haptic icons (brief tangible stimuli with associated meanings) are a new way to convey information, but are difficult to design in large quantities due to technological and perceptual constraints. Here, we employ rhythm in combination with frequency and amplitude to systematically produce 84 distinguishable tactile stimuli for use as icons. The set’s large size is made possible by an analysis of how users perceptually organize tactile rhythm. Through our evaluation, we find that the two primary characteristics by which users distinguish its tactile rhythms are note length and unevenness.},
	language = {en},
	booktitle = {Haptics: {Perception}, {Devices} and {Scenarios}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ternes, David and MacLean, Karon E.},
	editor = {Ferre, Manuel},
	year = {2008},
	keywords = {MDS, haptic icons, multidimensional scaling, rhythm, tactile},
	pages = {199--208}
}

@inproceedings{hoggan_new_2007,
	title = {New parameters for tacton design},
	isbn = {978-1-59593-642-4},
	url = {http://dl.acm.org/citation.cfm?id=1240866.1241017},
	doi = {10.1145/1240866.1241017},
	urldate = {2019-02-06},
	publisher = {ACM},
	author = {Hoggan, Eve and Brewster, Stephen and Brewster, Stephen},
	month = apr,
	year = {2007},
	pages = {2417--2422}
}

@article{smith_communicating_2007,
	series = {Evaluating affective interactions},
	title = {Communicating emotion through a haptic link: {Design} space and methodology},
	volume = {65},
	issn = {1071-5819},
	shorttitle = {Communicating emotion through a haptic link},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581906001911},
	doi = {10.1016/j.ijhcs.2006.11.006},
	abstract = {Communication of affect across a distance is not well supported by current technology, despite its importance to interpersonal interaction in modern lifestyles. Touch is a powerful conduit for emotional connectedness, and thus mediating haptic (touch) displays have been proposed to address this deficiency; but suitable evaluative methodology has been elusive. In this paper, we offer a first, structured examination of a design space for haptic support of remote affective communication, by analyzing the space and then comparing haptic models designed to manipulate its key dimensions. In our study, dyads (intimate pairs or strangers) are asked to communicate specified emotions using a purely haptic link that consists of virtual models rendered on simple knobs. These models instantiate both interaction metaphors of varying intimacy, and representations of virtual interpersonal distance. Our integrated objective and subjective observations imply that emotion can indeed be communicated through this medium, and confirm that the factors examined influence emotion communication performance as well as preference, comfort and connectedness. The proposed design space and the study results have implications for future efforts to support affective communication using the haptic modality, and the study approach comprises a first model for systematic evaluation of haptically expressed affect.},
	number = {4},
	urldate = {2019-02-06},
	journal = {International Journal of Human-Computer Studies},
	author = {Smith, Jocelyn and MacLean, Karon},
	month = apr,
	year = {2007},
	keywords = {Affect, Early design, Evaluation methodology, Haptic communication},
	pages = {376--387}
}

@misc{noauthor_maria_nodate,
	title = {Maria {A}. {Pastor}, {MD}, {MSc}, {Ph}.{D}. - {Clínica} {Universidad} de {Navarra}},
	url = {https://studylib.es/doc/4525688/maria-a.-pastor--md--msc--ph.d.---clínica-universidad-de-...},
	abstract = {Biblioteca en línea. Materiales de aprendizaje gratuitos.},
	language = {en},
	urldate = {2019-02-06},
	journal = {studylib.es}
}

@article{mountcastle_frequency_1990,
	title = {Frequency discrimination in the sense of flutter: psychophysical measurements correlated with postcentral events in behaving monkeys},
	volume = {10},
	copyright = {© 1990 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	shorttitle = {Frequency discrimination in the sense of flutter},
	url = {http://www.jneurosci.org/content/10/9/3032},
	doi = {10.1523/JNEUROSCI.10-09-03032.1990},
	abstract = {{\textless}p{\textgreater}The capacities of humans and monkeys to discriminate between the frequencies of mechanical sinusoids delivered to the glabrous skin of the hand have been measured in psychophysical experiments. The 2 primates have similar capacities; they make discriminations with Weber fractions that change little over the frequency range from 20 to 200 Hz. The discriminatory capacities are similar whether stimuli are received passively or acquired actively. Combined experiments have been made in monkeys in which the electrical signs of the activity of quickly adapting (QA) and slowly adapting (SA) neurons of postcentral areas 3b and 1 were recorded, both in the working state as the animal made discriminations and in the irrelevant state in which the stimuli did not guide behavior. The neuronal responses were analyzed in terms of discharge rates, periodicities in the neuronal discharges, and harmonic contents. It was shown that discriminatory capacity depends upon the period lengths in the sets of periodically entrained activity evoked by stimuli readily discriminated, and not upon the small differences in rates of discharge evoked by those stimuli. The periodicities were shown by harmonic analysis to be sharply limited to stimulus frequencies. Low-frequency stimuli evoke periodicities at the second and third harmonics in some neurons, in addition to strongly periodic signals at the fundamental frequency of the stimuli. Their presence does not appear to interfere with frequency discrimination. Neuronal responses recorded in the stimulus-irrelevant state were not distinguishable from those recorded as monkeys made discriminations. The responses of SA neurons, recorded under similar conditions, resembled those of QA neurons in almost every feature, but reasons are given for concluding that the SA system plays no role in frequency discrimination in the sense of flutter.{\textless}/p{\textgreater}},
	language = {en},
	number = {9},
	urldate = {2019-02-06},
	journal = {Journal of Neuroscience},
	author = {Mountcastle, V. B. and Steinmetz, M. A. and Romo, R.},
	month = sep,
	year = {1990},
	pmid = {2118947},
	pages = {3032--3044}
}

@book{boff_handbook_1986,
	address = {Oxford, England},
	series = {Handbook of perception and human performance, {Vol}. 2: {Cognitive} processes and performance},
	title = {Handbook of perception and human performance, {Vol}. 2: {Cognitive} processes and performance},
	isbn = {978-0-471-82956-0 978-0-471-82957-7},
	shorttitle = {Handbook of perception and human performance, {Vol}. 2},
	abstract = {From the outset of this effort, it has been our view that the architecture of a professional-level reference Handbook must be founded on relatively independent, self-contained units of information that provide a detailed treatment of logical elements of the subject area. The benefit of this approach is that it allows for nondisruptive, in-depth treatment of branching issues that are subordinate to the main sequence logic of a chapter.  Volume Two, "Cognitive Processes and Performance," deals with empirical issues in cognitive and human information processing followed by a treatment of factors in complex human performance. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {John Wiley \& Sons},
	editor = {Boff, Kenneth R. and Kaufman, Lloyd and Thomas, James P.},
	year = {1986},
	keywords = {Cognitive Processes, Perception, Performance}
}
@article{mazurek_robust_2014,
	title = {Robust quantification of orientation selectivity and direction selectivity},
	volume = {8},
	issn = {1662-5110},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4123790/},
	doi = {10.3389/fncir.2014.00092},
	abstract = {Neurons in the visual cortex of all examined mammals exhibit orientation or direction tuning. New imaging techniques are allowing the circuit mechanisms underlying orientation and direction selectivity to be studied with clarity that was not possible a decade ago. However, these new techniques bring new challenges: robust quantitative measurements are needed to evaluate the findings from these studies, which can involve thousands of cells of varying response strength. Here we show that traditional measures of selectivity such as the orientation index (OI) and direction index (DI) are poorly suited for quantitative evaluation of orientation and direction tuning. We explore several alternative methods for quantifying tuning and for addressing a variety of questions that arise in studies on orientation- and direction-tuned cells and cell populations. We provide recommendations for which methods are best suited to which applications and we offer tips for avoiding potential pitfalls in applying these methods. Our goal is to supply a solid quantitative foundation for studies involving orientation and direction tuning.},
	urldate = {2019-02-03},
	journal = {Frontiers in Neural Circuits},
	author = {Mazurek, Mark and Kager, Marisa and Van Hooser, Stephen D.},
	month = aug,
	year = {2014},
	pmid = {25147504},
	pmcid = {PMC4123790}
}

@misc{noauthor_notitle_nodate
}

@article{naka_s-potentials_1966,
	title = {S-potentials from luminosity units in the retina of fish ({Cyprinidae})},
	volume = {185},
	issn = {0022-3751},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1395832/},
	abstract = {1. S-potentials were recorded in fish from units which never responded by depolarization. These hyperpolarizing units are the L-units of Svaetichin \& MacNichol (1958)., 2. Figure 5 shows some sets of action spectra from a single unit. For each curve the criterion of action was hyperpolarization to a fixed level, by lights of various wave-lengths. When these lights fell upon zero background (circles) the curves show that two kinds of cone contribute to the action spectrum, one with the 620 nm pigment of Marks and one with the 680 nm pigment of Naka \& Rushton (1966a)., 3. When the lights fell upon (i) a fixed green background (triangles, Fig. 5), or (ii) a fixed red one (squares), the action spectra changed in a way that indicated greater prominence of (i) the 680 nm system (ii) the 540 nm green system that was not conspicuous without adaptation to red., 4. These observations (on the tench Tinca) are contrary to the conclusions of Svaetichin \& McNichol (on Gerridae) that the action spectrum is unaltered in shape by adaptation to coloured lights. The contribution of the green cones, for example, was actually absolutely greater under deep red adaptation., 5. It is concluded that L-units receive signals from 680, 620, 540 nm and possibly also the blue cones, that the quantum catch in all these contribute to the hyperpolarization produced, but their interaction is more complicated than the simple addition of independent cone effects.},
	number = {3},
	urldate = {2019-02-01},
	journal = {The Journal of Physiology},
	author = {Naka, K. I. and Rushton, W. A. H.},
	month = aug,
	year = {1966},
	pmid = {5918060},
	pmcid = {PMC1395832},
	pages = {587--599}
}

@article{kass_spike-train_2001,
	title = {A {Spike}-{Train} {Probability} {Model}},
	volume = {13},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/08997660152469314},
	doi = {10.1162/08997660152469314},
	abstract = {Poisson processes usually provide adequate descriptions of the irregularity in neuron spike times after pooling the data across large numbers of trials, as is done in constructing the peristimulus time histogram. When probabilities are needed to describe the behavior of neurons within individual trials, however, Poisson process models are often inadequate. In principle, an explicit formula gives the probability density of a single spike train in great generality, but without additional assumptions, the firing-rate intensity function appearing in that formula cannot be estimated. We propose a simple solution to this problem, which is to assume that the time at which a neuron fires is determined probabilistically by, and only by, two quantities: the experimental clock time and the elapsed time since the previous spike. We show that this model can be fitted with standard methods and software and that it may used successfully to fit neuronal data.},
	number = {8},
	urldate = {2019-02-02},
	journal = {Neural Computation},
	author = {Kass, Robert E. and Ventura, Valérie},
	month = aug,
	year = {2001},
	pages = {1713--1720}
}

@article{lawlor_linear-nonlinear-time-warp-poisson_2018,
	title = {Linear-{Nonlinear}-{Time}-{Warp}-{Poisson} models of neural activity},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/194498v1},
	doi = {10.1101/194498},
	abstract = {{\textless}p{\textgreater}Prominent models of spike trains assume only one source of variability - stochastic (Poisson) spiking - when stimuli and behavior are fixed. However, spike trains may also reflect variability due to internal processes such as planning. For example, we can plan a movement at one point in time and execute it at some arbitrary later time. Neurons involved in planning may thus share an underlying time-course that is not precisely locked to the actual movement. Here we combine the standard Linear-Nonlinear-Poisson (LNP) model with Dynamic Time Warping (DTW) to account for shared temporal variability. When applied to recordings from macaque premotor cortex, we find that time warping considerably improves predictions of neural activity. We suggest that such temporal variability is a widespread phenomenon in the brain which should be modeled.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-02-02},
	journal = {bioRxiv},
	author = {Lawlor, Patrick N. and Perich, Matthew G. and Miller, Lee E. and Kording, Konrad P.},
	month = jan,
	year = {2018},
	pages = {194498}
}

@book{drongelen_signal_2018,
	title = {Signal {Processing} for {Neuroscientists}},
	isbn = {978-0-12-810483-5},
	abstract = {Signal Processing for Neuroscientists, Second Edition provides an introduction to signal processing and modeling for those with a modest understanding of algebra, trigonometry and calculus. With a robust modeling component, this book describes modeling from the fundamental level of differential equations all the way up to practical applications in neuronal modeling. It features nine new chapters and an exercise section developed by the author. Since the modeling of systems and signal analysis are closely related, integrated presentation of these topics using identical or similar mathematics presents a didactic advantage and a significant resource for neuroscientists with quantitative interest.  Although each of the topics introduced could fill several volumes, this book provides a fundamental and uncluttered background for the non-specialist scientist or engineer to not only get applications started, but also evaluate more advanced literature on signal processing and modeling.Includes an introduction to biomedical signals, noise characteristics, recording techniques, and the more advanced topics of linear, nonlinear and multi-channel systems analysis Features new chapters on the fundamentals of modeling, application to neuronal modeling, Kalman filter, multi-taper power spectrum estimation, and practice exercisesContains the basics and background for more advanced topics in extensive notes and appendicesIncludes practical examples of algorithm development and implementation in MATLABFeatures a companion website with MATLAB scripts, data files, figures and video lectures},
	language = {en},
	publisher = {Academic Press},
	author = {Drongelen, Wim van},
	month = apr,
	year = {2018},
	note = {Google-Books-ID: Em89DwAAQBAJ},
	keywords = {Medical / Neuroscience, Science / Life Sciences / Neuroscience}
}

@misc{noauthor_signal_nodate,
	title = {Signal {Processing} for {Neuroscientists} - {Wim} van {Drongelen} - {Google} {Books}},
	url = {https://books.google.ca/books?hl=en&lr=&id=Em89DwAAQBAJ&oi=fnd&pg=PP1&dq=bootstrap+apporach+poisson+process+neuroscience&ots=PFjANwGY18&sig=bPKgCmixpb3KGTxuDpdPUNfobMc#v=onepage&q&f=false},
	urldate = {2019-02-02}
}

@article{brown_multiple_2004,
	title = {Multiple neural spike train data analysis: state-of-the-art and future challenges},
	volume = {7},
	issn = {1097-6256},
	shorttitle = {Multiple neural spike train data analysis},
	doi = {10.1038/nn1228},
	abstract = {Multiple electrodes are now a standard tool in neuroscience research that make it possible to study the simultaneous activity of several neurons in a given brain region or across different regions. The data from multi-electrode studies present important analysis challenges that must be resolved for optimal use of these neurophysiological measurements to answer questions about how the brain works. Here we review statistical methods for the analysis of multiple neural spike-train data and discuss future challenges for methodology research.},
	language = {eng},
	number = {5},
	journal = {Nature Neuroscience},
	author = {Brown, Emery N. and Kass, Robert E. and Mitra, Partha P.},
	month = may,
	year = {2004},
	pmid = {15114358},
	keywords = {Action Potentials, Animals, Art, Brain Mapping, Electrophysiology, Humans, Models, Neurological, Nerve Net, Neurons, Statistics as Topic, Time Factors},
	pages = {456--461}
}

@article{lashgari_response_2012,
	title = {Response {Properties} of {Local} {Field} {Potentials} and {Neighboring} {Single} {Neurons} in {Awake} {Primary} {Visual} {Cortex}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/3211396-18\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/32/33/11396},
	doi = {10.1523/JNEUROSCI.0429-12.2012},
	abstract = {Recordings from local field potentials (LFPs) are becoming increasingly common in research and clinical applications, but we still have a poor understanding of how LFP stimulus selectivity originates from the combined activity of single neurons. Here, we systematically compared the stimulus selectivity of LFP and neighboring single-unit activity (SUA) recorded in area primary visual cortex (V1) of awake primates. We demonstrate that LFP and SUA have similar stimulus preferences for orientation, direction of motion, contrast, size, temporal frequency, and even spatial phase. However, the average SUA had 50 times better signal-to-noise, 20\% higher contrast sensitivity, 45\% higher direction selectivity, and 15\% more tuning depth than the average LFP. Low LFP frequencies ({\textless}30 Hz) were most strongly correlated with the spiking frequencies of neurons with nonlinear spatial summation and poor orientation/direction selectivity that were located near cortical current sinks (negative LFPs). In contrast, LFP gamma frequencies ({\textgreater}30 Hz) were correlated with a more diverse group of neurons located near cortical sources (positive LFPs). In summary, our results indicate that low- and high-frequency LFP pool signals from V1 neurons with similar stimulus preferences but different response properties and cortical depths.},
	language = {en},
	number = {33},
	urldate = {2019-02-02},
	journal = {Journal of Neuroscience},
	author = {Lashgari, Reza and Li, Xiaobing and Chen, Yao and Kremkow, Jens and Bereshpolova, Yulia and Swadlow, Harvey A. and Alonso, Jose-Manuel},
	month = aug,
	year = {2012},
	pmid = {22895722},
	pages = {11396--11413}
}

@article{bergh_receptive-field_2010,
	title = {Receptive-field properties of {V1} and {V2} neurons in mice and macaque monkeys},
	volume = {518},
	copyright = {Copyright © 2010 Wiley‐Liss, Inc.},
	issn = {1096-9861},
	url = {https://www.onlinelibrary.wiley.com/doi/abs/10.1002/cne.22321},
	doi = {10.1002/cne.22321},
	abstract = {We report the results of extracellular single-unit recording experiments where we quantitatively analyzed the receptive-field (RF) properties of neurons in V1 and an adjacent extrastriate visual area (V2L) of anesthetized mice with emphasis on the RF center-surround organization. We compared the results with the RF center-surround organization of V1 and V2 neurons in macaque monkeys. If species differences in spatial scale are taken into consideration, mouse V1 and V2L neurons had remarkably fine stimulus selectivity, and the majority of response properties in V2L were not different from those in V1. The RF center-surround organization of mouse V1 neurons was qualitatively similar to that for macaque monkeys (i.e., the RF center is surrounded by extended suppressive regions). However, unlike in monkey V2, a significant proportion of cortical neurons, largely complex cells in V2L, did not exhibit quantifiable RF surround suppression. Simple cells had smaller RF centers than complex cells, and the prevalence and strength of surround suppression were greater in simple cells than in complex cells. These findings, particularly on the RF center-surround organization of visual cortical neurons, give new insights into the principles governing cortical circuits in the mouse visual cortex and should provide further impetus for the use of mice in studies on the genetic and molecular basis of RF development and synaptic plasticity. J. Comp. Neurol. 518:2051–2070, 2010. © 2010 Wiley-Liss, Inc.},
	language = {en},
	number = {11},
	urldate = {2019-02-02},
	journal = {Journal of Comparative Neurology},
	author = {Bergh, Gert Van den and Zhang, Bin and Arckens, Lutgarde and Chino, Yuzo M.},
	year = {2010},
	keywords = {center-surround organization, macaque monkey, mouse, receptive field, surround suppression, visual cortex},
	pages = {2051--2070}
}

@article{burr_dependency_2001,
	title = {Dependency of reaction times to motion onset on luminance and chromatic contrast},
	volume = {41},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698901000190},
	doi = {10.1016/S0042-6989(01)00019-0},
	abstract = {We measured reaction times for detecting the onset of motion of sinusoidal gratings of 1 c/deg, modulated in either luminance or chromatic contrast, caused to move abruptly at speeds ranging from 0.25 to 10 deg/s (0.25–10 Hz). At any given luminance or chromatic contrast, RTs varied linearly with temporal periodicity (r2≅0.97), yielding a Weber fraction of period. The value of the Weber fraction varied inversely with contrast, differently for luminance and chromatic contrast. The results were well simulated with a simple model that accumulated change in contrast over time until a critical threshold had been reached. Two crucial aspects of the model are a second-stage temporal integration mechanism, capable of accumulating information for periods of up to 2 s, and contrast gain control, different for luminance than for chromatic stimuli. The contrast response for luminance shows very low semi-saturating contrasts and high gain, similar to LGN M-cells and cells in MT; that for colour shows high semi-saturating contrasts and low gain, similar to LGN P-cells. The results suggest that motion onset for luminance and chromatic gratings are detected by different mechanisms, probably by the magno- and parvo-cellular systems.},
	number = {8},
	urldate = {2019-02-02},
	journal = {Vision Research},
	author = {Burr, David C. and Corsale, Beatrice},
	month = apr,
	year = {2001},
	keywords = {Colour, Gain control, M- and P- cells, Reaction times, Visual motion},
	pages = {1039--1048}
}

@article{hua_perceptual_2010,
	title = {Perceptual {Learning} {Improves} {Contrast} {Sensitivity} of {V1} {Neurons} in {Cats}},
	volume = {20},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982210004410},
	doi = {10.1016/j.cub.2010.03.066},
	abstract = {Summary
Background
Perceptual learning has been documented in adult humans over a wide range of tasks. Although the often-observed specificity of learning is generally interpreted as evidence for training-induced plasticity in early cortical areas, physiological evidence for training-induced changes in early visual cortical areas is modest, despite reports of learning-induced changes of cortical activities in fMRI studies. To reveal the physiological bases of perceptual learning, we combined psychophysical measurements with extracellular single-unit recording under anesthetized preparations and examined the effects of training in grating orientation identification on both perceptual and neuronal contrast sensitivity functions of cats.
Results
We have found that training significantly improved perceptual contrast sensitivity of the cats to gratings with spatial frequencies near the “trained” spatial frequency, with stronger effects in the trained eye. Consistent with behavioral assessments, the mean contrast sensitivity of neurons recorded from V1 of the trained cats was significantly higher than that of neurons recorded from the untrained cats. Furthermore, in the trained cats, the contrast sensitivity of V1 neurons responding preferentially to stimuli presented via the trained eyes was significantly greater than that of neurons responding preferentially to stimuli presented via the “untrained” eyes. The effect was confined to the trained spatial frequencies. In both trained and untrained cats, the neuronal contrast sensitivity functions derived from the contrast sensitivity of the individual neurons were highly correlated with behaviorally determined perceptual contrast sensitivity functions.
Conclusions
We suggest that training-induced neuronal contrast gain in area V1 underlies behaviorally determined perceptual contrast sensitivity improvements.},
	number = {10},
	urldate = {2019-02-02},
	journal = {Current Biology},
	author = {Hua, Tianmiao and Bao, Pinglei and Huang, Chang-Bing and Wang, Zhenhua and Xu, Jinwang and Zhou, Yifeng and Lu, Zhong-Lin},
	month = may,
	year = {2010},
	keywords = {SYSNEURO},
	pages = {887--894}
}

@article{albrecht_striate_1982,
	title = {Striate cortex of monkey and cat: contrast response function},
	volume = {48},
	issn = {0022-3077},
	shorttitle = {Striate cortex of monkey and cat},
	doi = {10.1152/jn.1982.48.1.217},
	language = {eng},
	number = {1},
	journal = {Journal of Neurophysiology},
	author = {Albrecht, D. G. and Hamilton, D. B.},
	month = jul,
	year = {1982},
	pmid = {7119846},
	keywords = {Animals, Cats, Macaca fascicularis, Mathematics, Neurons, Photic Stimulation, Visual Cortex},
	pages = {217--237}
}

@misc{noauthor_contrast_nodate,
	title = {Contrast gain control and cortical {TrkB} signaling shape visual acuity. - {PubMed} - {NCBI}},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/20400960},
	urldate = {2019-02-02}
}

@article{schwartz_natural_2001,
	title = {Natural signal statistics and sensory gain control},
	volume = {4},
	copyright = {2001 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn0801_819},
	doi = {10.1038/90526},
	abstract = {We describe a form of nonlinear decomposition that is well-suited for efficient encoding of natural signals. Signals are initially decomposed using a bank of linear filters. Each filter response is then rectified and divided by a weighted sum of rectified responses of neighboring filters. We show that this decomposition, with parameters optimized for the statistics of a generic ensemble of natural images or sounds, provides a good characterization of the nonlinear response properties of typical neurons in primary visual cortex or auditory nerve, respectively. These results suggest that nonlinear response properties of sensory neurons are not an accident of biological implementation, but have an important functional role.},
	language = {en},
	number = {8},
	urldate = {2019-02-02},
	journal = {Nature Neuroscience},
	author = {Schwartz, Odelia and Simoncelli, Eero P.},
	month = aug,
	year = {2001},
	pages = {819--825}
}

@article{peirce_potential_2007,
	title = {The potential importance of saturating and supersaturating contrast response functions in visual cortex},
	volume = {7},
	issn = {1534-7362},
	url = {https://jov.arvojournals.org/article.aspx?articleid=2193085},
	doi = {10.1167/7.6.13},
	language = {en},
	number = {6},
	urldate = {2019-02-02},
	journal = {Journal of Vision},
	author = {Peirce, Jonathan W.},
	month = apr,
	year = {2007},
	pages = {13--13}
}

@article{nachmias_grating_1974,
	title = {Grating contrast: {Discrimination} may be better than detection},
	volume = {14},
	issn = {0042-6989},
	shorttitle = {Grating contrast},
	url = {http://www.sciencedirect.com/science/article/pii/0042698974901758},
	doi = {10.1016/0042-6989(74)90175-8},
	number = {10},
	urldate = {2019-02-02},
	journal = {Vision Research},
	author = {Nachmias, Jacob and Sansbury, Richard V.},
	month = oct,
	year = {1974},
	pages = {1039--1042}
}

@article{boynton_neuronal_1999,
	title = {Neuronal basis of contrast discrimination},
	volume = {39},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698998001138},
	doi = {10.1016/S0042-6989(98)00113-8},
	abstract = {Psychophysical contrast increment thresholds were compared with neuronal responses, inferred from functional magnetic resonance imaging (fMRI) to test the hypothesis that contrast discrimination judgements are limited by neuronal signals in early visual cortical areas. FMRI was used to measure human brain activity as a function of stimulus contrast, in each of several identifiable visual cortical areas. Contrast increment thresholds were measured for the same stimuli across a range of baseline contrasts using a temporal 2AFC paradigm. FMRI responses and psychophysical measurements were compared by assuming that: (1) fMRI responses are proportional to local average neuronal activity; (2) subjects choose the stimulus interval that evoked the greater average neuronal activity; and (3) variability in the observer’s psychophysical judgements was due to additive (IID) noise. With these assumptions, FMRI responses in visual areas V1, V2d, V3d and V3A were found to be consistent with the psychophysical judgements, i.e. a contrast increment was detected when the fMRI responses in each of these brain areas increased by a criterion amount. Thus, the pooled activity of large numbers of neurons can reasonably well predict behavioral performance. The data also suggest that contrast gain in early visual cortex depends systematically on spatial frequency.},
	number = {2},
	urldate = {2019-02-02},
	journal = {Vision Research},
	author = {Boynton, Geoffrey M. and Demb, Jonathan B. and Glover, Gary H. and Heeger, David J.},
	month = jan,
	year = {1999},
	keywords = {Contrast, FMRI, Masking, Primary visual cortex, Psychophysics},
	pages = {257--269}
}

@article{morrone_color_2002,
	title = {Color and {Luminance} {Contrasts} {Attract} {Independent} {Attention}},
	volume = {12},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982202009211},
	doi = {10.1016/S0960-9822(02)00921-1},
	abstract = {Paying attention can improve vision in many ways, including some very basic functions such as contrast discrimination 1, 2, a task that probably reflects very early levels of visual processing. Electrophysiological 3, 4, psychophysical 1, 5, and imaging 6, 7, 8, 9 studies on humans as well as single recordings in monkey 10, 11, 12, 13 show that attention can modulate the neuronal response at an early stage of visual processing, probably by acting on the response gain. Here, we measure incremental contrast thresholds for luminance and color stimuli to derive the contrast response of early neural mechanisms 14, 15, 16 and their modulation by attention. We show that, for both cases, attention improves contrast discrimination, probably by multiplicatively increasing the gain of the neuronal response to contrast. However, the effects of attention are highly specific to the visual modality: concurrent attention to a competing luminance, but not chromatic pattern, greatly impedes luminance contrast discrimination; and attending to a competing chromatic, but not luminance, task impedes color contrast discrimination. Thus, the effects of attention are highly modality specific, implying separate attentional resources for different fundamental visual attributes at early stages of visual processing.},
	number = {13},
	urldate = {2019-02-02},
	journal = {Current Biology},
	author = {Morrone, Maria Concetta and Denti, Valentina and Spinelli, Donatella},
	month = jul,
	year = {2002},
	pages = {1134--1137}
}

@inproceedings{wu_computer-assisted_1983,
	series = {Documenta {Ophthalmologica} {Proceedings} {Series}},
	title = {Computer-{Assisted} {Analysis} of {Clinical} {Electroretinographic} {Intensity}-{Response} {Functions}},
	isbn = {978-94-009-7275-9},
	abstract = {The amplitude of the human dark-adapted electroretinogram, measured from the trough of the a-wave to the peak of the b-wave as a function of stimulus intensity can be described nominally by the Naka-Rushton equation which has three independent parameters: Rmax, K, and n. Rmax is the asymptotic value of the ERG amplitude as a function of intensity, K is the intensity that produces an ERG amplitude that is one-half Rmax and n is a dimensionless constant that controls the slope of the function. The advantage of using the Naka-Rushton equation is that the three empirical parameters can be interpreted clinically. For example, changes in Rmax may correspond to response compression owing to retinal ‘gain’ changes or to regional losses of retinal function; changes in K correspond to changes in retinal sensitivity or to changes in pre-retinal light absorption; and changes in n may be interpreted in terms of heterogeneous losses of retinal sensitivity. ERG intensity-response functions were obtained from normal subjects and retinal disease patients, and maximum likelihood values were computed for Rmax, K, and n for each individual’s data. The present paper describes these data and the computer system and analysis algorithm for recording and analyzing the ERG intensity-response function.},
	language = {en},
	booktitle = {Slow {Potentials} and {Microprocessor} {Applications}},
	publisher = {Springer Netherlands},
	author = {Wu, L. and Massof, R. W. and Starr, S. J.},
	editor = {Kolder, Hansjoerg E. J. W.},
	year = {1983},
	keywords = {Cone Dystrophy, Neuronal Ceroid Lipofuscinosis, Normal 95th Percentile, Retinal Sensitivity, Stimulus Luminance},
	pages = {231--239}
}

@article{massof_properties_1984,
	title = {Properties of electroretinographic intensity-response functions in retinitis pigmentosa},
	volume = {57},
	issn = {1573-2622},
	url = {https://doi.org/10.1007/BF00143087},
	doi = {10.1007/BF00143087},
	abstract = {Dark-adapted electroretinogram (ERG) b-wave amplitudes and implicit times were recorded as a function of stimulus luminance for 15 retinitis pigmentosa (RP) patients and 15 normal subjects. B-wave amplitude as a function of log stimulus luminance was fit by non-linear regression with the Naka-Rushton equation, which has 3 independent parameters: The maximum response (Rmax), slope (n) and half-saturation constant (K). B-wave implicit-time as a function of log stimulus luminance was fit by linear regression. Compared to normal, the RP Rmax values were markedly reduced, suggesting response compression; the RP K values were elevated by an average of 0.76 log unit, suggesting relatively small losses in retinal sensitivity. There was no correspondence between Rmax and visual field area for the RP patients (coefficient of correlation = -0.02). All but 2 of the 15 RP patients had normal or shallower-than-normal implicit-time intensity-response functions, indicating that over most of the dynamic range of the ERG, the implicit-times were either normal or faster-than-normal. These results are discussed in terms of possible RP disease mechanisms.},
	language = {en},
	number = {3},
	urldate = {2019-02-02},
	journal = {Documenta Ophthalmologica},
	author = {Massof, R. W. and Wu, L. and Finkelstein, D. and Perry, C. and Starr, S. J. and Johnson, M. A.},
	month = may,
	year = {1984},
	keywords = {electroretinogram, inherited retinal degenerations, retinitis pigmentosa, rod monochromat},
	pages = {279--296}
}

@article{miyamoto_age-related_2017,
	title = {Age-related changes in the spatiotemporal responses to electrical stimulation in the visual cortex of rats with progressive vision loss},
	volume = {7},
	copyright = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-14303-1},
	doi = {10.1038/s41598-017-14303-1},
	abstract = {The Royal College of Surgeons (RCS) rat gradually loses vision due to retinal degeneration. Previous physiological studies have depicted the progressive loss of optical responses in the visual pathway, including the primary visual cortex (V1), over the course of retinal degeneration in the RCS rat. However, little is known about how the excitability of the V1 circuit changes during over the course of the gradual loss of visual signal input from the retina. We elucidated the properties of responses to electrical stimulations directly applied to V1 at different stages of vision input loss in the RCS rat in reference to those of the Long-Evans (LE) rat, using in vivo voltage-sensitive dye imaging. The V1 neuronal network of the RCS rat exhibited an excitatory response comparable to the LE rat. The excitatory response was maintained even long after total loss of the visual signal input from the retina. However, the response time-course suggested that the suppressive response was somewhat debilitated in the RCS rat. This is the first experiment demonstrating the long-term effect of retinal degeneration on cortical activities. Our findings provide the physiological fundamentals to enhance the preclinical research of cortical prostheses with the use of the RCS rat.},
	language = {En},
	number = {1},
	urldate = {2019-02-02},
	journal = {Scientific Reports},
	author = {Miyamoto, Soshi and Suematsu, Naofumi and Umehira, Yuichi and Hayashida, Yuki and Yagi, Tetsuya},
	month = oct,
	year = {2017},
	pages = {14165}
}

@misc{noauthor_simple_nodate,
	title = {A simple method of fitting the {Naka}-{Rushton} equation},
	url = {https://www.researchgate.net/publication/292522350_A_simple_method_of_fitting_the_Naka-Rushton_equation},
	abstract = {Download Citation on ResearchGate {\textbar} A simple method of fitting the Naka-Rushton equation {\textbar} A simple way of fitting the Naka-Rushton equation to experimental data is described. The method makes use of linear regression on transformed data following estimation of V(max), and may be rapidly performed using simple calculating devices. The technique should be of value...},
	language = {en},
	urldate = {2019-02-02},
	journal = {ResearchGate}
}

@article{gangadhar_naka-rushton_1989,
	title = {Naka-{Rushton} equation parameters in electroretinogram analysis of daunomycin effects on retinal function},
	volume = {72},
	issn = {1573-2622},
	url = {https://doi.org/10.1007/BF00155215},
	doi = {10.1007/BF00155215},
	abstract = {Intraocular daunomycin may inhibit intravitreal cellular proliferation in proliferative vitreoretinopathy after rhegmatogenous retinal detachments and retinal reattachment surgery. Doses of 15 nmol or more have shown histological retinal toxicity when injected into the intact vitreous of rabbit eyes. We injected 30, 20, 10 and 0 nmol doses of daunomycin into rabbit eyes with gas-compressed vitreous to better simulate the clinical conditions in which it would be used. We then evaluated effects on retinal function by examining scotopic b-wave amplitudes, measured for a four log unit set of intensities. We used the three independent parameters Rmax, log K, and n of the Naka-Rushton equation to measure changes in retinal function. All three doses of daunomycin failed to measurably depress retinal function (i.e., there were no dose-related losses of Rmax, log K or n) in this experimental model. We used this approach to monitor alterations in retinal function since it can show selective changes in each parameter. This selectivity is an advantage over monitoring retinal function with single intensities or comparisons limited solely to electroretinogram amplitudes.},
	language = {en},
	number = {1},
	urldate = {2019-02-02},
	journal = {Documenta Ophthalmologica},
	author = {Gangadhar, Dasa V. and Wolf, Bruce M. and Tanenbaum, Howard L.},
	month = may,
	year = {1989},
	keywords = {Naka-Rushton function, daunomycin, electroretinography, proliferative vitreoretinopathy},
	pages = {61--70}
}

@misc{noauthor_methodological_nodate,
	title = {Methodological {Aspects} of the {Application} of the {Naka}-{Rushton} {Equation} to {Clinical} {Electroretinogram} - {Abstract} - {Ophthalmic} {Research} 1993, {Vol}. 25, {No}. 3 - {Karger} {Publishers}},
	url = {https://www.karger.com/Article/Abstract/267283},
	urldate = {2019-02-02}
}

@article{evans_comparison_1993,
	title = {Comparison of three methods of estimating the parameters of the {Naka}-{Rushton} equation},
	volume = {84},
	issn = {0012-4486, 1573-2622},
	url = {https://link.springer.com/article/10.1007/BF01203279},
	doi = {10.1007/BF01203279},
	abstract = {The Naka-Rushton equation empirically describes the amplitude R of the darkadapted electroretinogram b-wave, as a function of stimulus luminance L, as R/Rmax = L n/(L n + K n). Estimating the three...},
	language = {en},
	number = {1},
	urldate = {2019-02-01},
	journal = {Documenta Ophthalmologica},
	author = {Evans, Lawrence S. and Peachey, Neal S. and Marchese, Anthony L.},
	month = mar,
	year = {1993},
	keywords = {Dark-adapted electroretinogram, Naka-Rushton equation, Stimulus luminance, b-wave},
	pages = {19--30}
}

@article{severns_care_1993,
	title = {The care and fitting of {Naka}-{Rushton} functions to electroretinographic intensity-response data},
	volume = {85},
	issn = {1573-2622},
	url = {https://doi.org/10.1007/BF01371129},
	doi = {10.1007/BF01371129},
	abstract = {We developed an automated system to estimate parameters of the Naka-Rushton function based on a heuristic model of the electroretinogram intensity-response series. Data from a population of patients with central retinal vein occlusion were used to examine the ability of the derived parameters to predict the development of neovascularization of the iris. The predictive performance of this automated system in central retinal vein occlusion is comparable to that of a human expert.},
	language = {en},
	number = {2},
	urldate = {2019-02-02},
	journal = {Documenta Ophthalmologica},
	author = {Severns, Matthew L. and Johnson, Mary A.},
	month = feb,
	year = {1993},
	keywords = {Central retinal vein occlusion, Electroretinogram, Intensity response, Naka-Rushton function, Parameter estimation},
	pages = {135--150}
}

@inproceedings{luzhnica_personalising_2017,
	address = {New York, NY, USA},
	series = {{ISWC} '17},
	title = {Personalising {Vibrotactile} {Displays} {Through} {Perceptual} {Sensitivity} {Adjustment}},
	isbn = {978-1-4503-5188-1},
	url = {http://doi.acm.org/10.1145/3123021.3123029},
	doi = {10.1145/3123021.3123029},
	abstract = {Haptic displays are commonly limited to transmitting a discrete set of tactile motives. In this paper, we explore the transmission of real-valued information through vibrotactile displays. We simulate spatial continuity with three perceptual models commonly used to create phantom sensations: the linear, logarithmic and power model. We show that these generic models lead to limited decoding precision, and propose a method for model personalization adjusting to idiosyncratic and spatial variations in perceptual sensitivity. We evaluate this approach using two haptic display layouts: circular, worn around the wrist and the upper arm, and straight, worn along the forearm. Results of a user study measuring continuous value decoding precision show that users were able to decode continuous values with relatively high accuracy (4.4\% mean error), circular layouts performed particularly well, and personalisation through sensitivity adjustment increased decoding precision.},
	urldate = {2019-02-01},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Luzhnica, Granit and Stein, Sebastian and Veas, Eduardo and Pammer, Viktoria and Williamson, John and Smith, Roderick Murray},
	year = {2017},
	keywords = {HCI, encoding information, haptic display, haptic feedback, phantom sensation, tactile feedback, user study, wearable},
	pages = {66--73}
}